"""
Prometheus Metrics Exporter for Kaizen
=====================================

Exposes Kaizen performance metrics via a FastAPI endpoint for Prometheus scraping.
"""

from fastapi import FastAPI, APIRouter
from prometheus_client import Counter, Gauge, Histogram, generate_latest, CONTENT_TYPE_LATEST
from fastapi.responses import Response
import asyncio
from typing import Optional
import logging

logger = logging.getLogger(__name__)

# Define Prometheus metrics
kaizen_insights_total = Counter(
    'kaizen_insights_total',
    'Total number of insights generated by Kaizen',
    ['insight_type']
)

kaizen_insights_applied = Counter(
    'kaizen_insights_applied',
    'Total number of insights successfully applied',
    ['insight_type']
)

kaizen_gapfill_triggers = Counter(
    'kaizen_gapfill_triggers',
    'Number of times gap-fill search was triggered'
)

kaizen_analysis_cycles = Counter(
    'kaizen_analysis_cycles',
    'Total number of analysis cycles completed'
)

kaizen_avg_response_time = Gauge(
    'kaizen_avg_response_time_seconds',
    'Average response time tracked by Kaizen'
)

kaizen_error_rate = Gauge(
    'kaizen_error_rate',
    'Current error rate as percentage'
)

kaizen_consciousness_level = Gauge(
    'kaizen_consciousness_level',
    'Average consciousness level'
)

kaizen_knowledge_base_size = Gauge(
    'kaizen_knowledge_base_size',
    'Number of entries in knowledge base'
)

kaizen_active_insights = Gauge(
    'kaizen_active_insights',
    'Number of insights not yet applied'
)

kaizen_analysis_duration = Histogram(
    'kaizen_analysis_duration_seconds',
    'Time taken for analysis cycles',
    buckets=(0.1, 0.5, 1.0, 2.0, 5.0, 10.0, 30.0, 60.0)
)

# Create metrics router
metrics_router = APIRouter(prefix="/kaizen", tags=["metrics"])

class KaizenMetricsExporter:
    """Bridges Kaizen engine with Prometheus metrics"""
    
    def __init__(self, kaizen_engine=None):
        self.kaizen_engine = kaizen_engine
        self._update_task = None
        self._running = False
        
    def set_kaizen_engine(self, engine):
        """Set or update the Kaizen engine reference"""
        self.kaizen_engine = engine
        
    async def start_metrics_collection(self, update_interval: int = 30):
        """Start periodic metrics collection"""
        if self._running:
            logger.warning("Metrics collection already running")
            return
            
        self._running = True
        self._update_task = asyncio.create_task(self._update_metrics_loop(update_interval))
        logger.info(f"Started Kaizen metrics collection (interval: {update_interval}s)")
        
    async def stop_metrics_collection(self):
        """Stop metrics collection"""
        self._running = False
        if self._update_task:
            self._update_task.cancel()
            try:
                await self._update_task
            except asyncio.CancelledError:
                pass
        logger.info("Stopped Kaizen metrics collection")
        
    async def _update_metrics_loop(self, interval: int):
        """Periodically update Prometheus metrics from Kaizen state"""
        while self._running:
            try:
                await self._update_metrics()
                await asyncio.sleep(interval)
            except asyncio.CancelledError:
                break
            except Exception as e:
                logger.error(f"Error updating Kaizen metrics: {e}")
                await asyncio.sleep(interval)
                
    async def _update_metrics(self):
        """Update all Prometheus metrics from current Kaizen state"""
        if not self.kaizen_engine:
            logger.warning("No Kaizen engine set for metrics export")
            return
            
        try:
            # Update response time
            avg_response_time = self.kaizen_engine.metrics.get_average_response_time()
            kaizen_avg_response_time.set(avg_response_time)
            
            # Update error rate
            error_rate = self.kaizen_engine.metrics.get_error_rate()
            kaizen_error_rate.set(error_rate * 100)  # As percentage
            
            # Update consciousness level
            if self.kaizen_engine.metrics.consciousness_levels:
                import statistics
                avg_consciousness = statistics.mean(self.kaizen_engine.metrics.consciousness_levels)
                kaizen_consciousness_level.set(avg_consciousness)
            
            # Update knowledge base size
            kb_size = len(self.kaizen_engine.knowledge_base)
            kaizen_knowledge_base_size.set(kb_size)
            
            # Update active insights
            async with self.kaizen_engine._insight_lock:
                total_insights = len(self.kaizen_engine.insights)
                applied_insights = sum(1 for i in self.kaizen_engine.insights if i.applied)
                active_insights = total_insights - applied_insights
                kaizen_active_insights.set(active_insights)
                
            logger.debug(f"Updated Kaizen metrics: response_time={avg_response_time:.2f}s, "
                        f"error_rate={error_rate:.2%}, kb_size={kb_size}")
                        
        except Exception as e:
            logger.error(f"Failed to update metrics: {e}")
            
    def record_insight_generated(self, insight_type: str):
        """Record that an insight was generated"""
        kaizen_insights_total.labels(insight_type=insight_type).inc()
        
    def record_insight_applied(self, insight_type: str):
        """Record that an insight was applied"""
        kaizen_insights_applied.labels(insight_type=insight_type).inc()
        
    def record_gapfill_trigger(self):
        """Record a gap-fill search trigger"""
        kaizen_gapfill_triggers.inc()
        
    def record_analysis_cycle(self, duration_seconds: float):
        """Record completion of an analysis cycle"""
        kaizen_analysis_cycles.inc()
        kaizen_analysis_duration.observe(duration_seconds)

# Global exporter instance
metrics_exporter = KaizenMetricsExporter()

@metrics_router.get("/metrics", response_class=Response)
async def get_metrics():
    """Prometheus metrics endpoint"""
    # Force update before serving metrics
    await metrics_exporter._update_metrics()
    
    # Generate Prometheus format metrics
    metrics_data = generate_latest()
    return Response(
        content=metrics_data,
        media_type=CONTENT_TYPE_LATEST
    )

@metrics_router.get("/health")
async def health_check():
    """Health check endpoint"""
    if not metrics_exporter.kaizen_engine:
        return {"status": "unhealthy", "reason": "No Kaizen engine connected"}
        
    return {
        "status": "healthy",
        "kaizen_running": metrics_exporter.kaizen_engine.is_running,
        "metrics_collection": metrics_exporter._running,
        "insights_count": len(metrics_exporter.kaizen_engine.insights)
    }

def create_metrics_app(kaizen_engine=None) -> FastAPI:
    """Create FastAPI app with metrics endpoints"""
    app = FastAPI(title="Kaizen Metrics", version="1.0.0")
    
    # Include metrics router
    app.include_router(metrics_router)
    
    # Set Kaizen engine if provided
    if kaizen_engine:
        metrics_exporter.set_kaizen_engine(kaizen_engine)
    
    @app.on_event("startup")
    async def startup_event():
        """Start metrics collection on app startup"""
        if kaizen_engine:
            await metrics_exporter.start_metrics_collection()
            logger.info("Kaizen metrics exporter started")
    
    @app.on_event("shutdown")
    async def shutdown_event():
        """Stop metrics collection on shutdown"""
        await metrics_exporter.stop_metrics_collection()
        logger.info("Kaizen metrics exporter stopped")
    
    return app

# Export for use in Kaizen module
__all__ = [
    'metrics_exporter',
    'create_metrics_app',
    'metrics_router',
    'KaizenMetricsExporter'
]
