\"\"\"End-to-End Test Suite for TORI Document Intelligence System\"\"\"\n\nimport asyncio\nimport json\nimport time\nfrom pathlib import Path\nfrom typing import Dict, Any, List\n\nimport pytest\nimport httpx\nfrom faker import Faker\n\nfake = Faker()\n\nclass TestEndToEndPipeline:\n    \"\"\"Comprehensive E2E tests for upload â†’ process â†’ chat pipeline\"\"\"\n\n    @pytest.mark.e2e\n    @pytest.mark.upload\n    async def test_pdf_upload_with_sse_progress(self, http_client, test_pdf_quantum, progress_tracker_factory, unique_progress_id):\n        \"\"\"Test 1: Upload PDF and track SSE progress to 100%\"\"\"\n        print(f\"\\nğŸ§ª [TEST] Starting PDF upload with progress tracking...\")\n        \n        # Create progress tracker\n        tracker = progress_tracker_factory(unique_progress_id)\n        \n        # Start progress tracking in background\n        progress_task = asyncio.create_task(\n            tracker.track_progress(timeout=60.0)\n        )\n        \n        # Give SSE a moment to start listening\n        await asyncio.sleep(0.5)\n        \n        # Upload PDF\n        with open(test_pdf_quantum, \"rb\") as pdf_file:\n            files = {\"file\": (\"quantum_physics_test.pdf\", pdf_file, \"application/pdf\")}\n            response = await http_client.post(\n                f\"/api/upload?progress_id={unique_progress_id}\",\n                files=files\n            )\n        \n        # Verify upload response\n        assert response.status_code == 200, f\"Upload failed: {response.status_code} - {response.text}\"\n        upload_data = response.json()\n        \n        assert upload_data[\"success\"] is True\n        assert \"document\" in upload_data\n        assert upload_data[\"document\"][\"filename\"] == \"quantum_physics_test.pdf\"\n        \n        print(f\"âœ… Upload successful: {upload_data['document']['concept_count']} concepts extracted\")\n        \n        # Wait for progress tracking to complete\n        progress_result = await progress_task\n        \n        # Verify SSE progress tracking\n        assert progress_result[\"success\"] is True, f\"SSE tracking failed: {progress_result.get('error')}\">\n        assert len(progress_result[\"events\"]) > 0, \"No SSE events received\"\n        \n        # Verify progress sequence\n        final_event = progress_result[\"final_data\"]\n        assert final_event[\"stage\"] == \"complete\"\n        assert final_event[\"percentage\"] == 100\n        \n        print(f\"âœ… SSE Progress: {len(progress_result['events'])} events, completed in {progress_result['duration']:.2f}s\")\n        \n        # Verify all expected progress stages\n        stages = [event.get(\"stage\") for event in progress_result[\"events\"]]\n        expected_stages = [\"starting\", \"validating\", \"preparing\", \"saving\", \"processing\", \"extracting\", \"finishing\", \"finalizing\", \"complete\"]\n        \n        for stage in expected_stages:\n            if stage in stages:\n                print(f\"  âœ… Stage: {stage}\")\n            else:\n                print(f\"  âš ï¸ Missing stage: {stage}\")\n        \n        return upload_data[\"document\"]\n\n    @pytest.mark.e2e\n    @pytest.mark.chat\n    async def test_document_grounded_chat_response(self, http_client, test_pdf_quantum, progress_tracker_factory, unique_progress_id):\n        \"\"\"Test 2: Chat query validation with document grounding\"\"\"\n        print(f\"\\nğŸ§ª [TEST] Testing document-grounded chat responses...\")\n        \n        # First upload the document\n        tracker = progress_tracker_factory(unique_progress_id)\n        progress_task = asyncio.create_task(tracker.track_progress())\n        await asyncio.sleep(0.5)\n        \n        with open(test_pdf_quantum, \"rb\") as pdf_file:\n            files = {\"file\": (\"quantum_physics_test.pdf\", pdf_file, \"application/pdf\")}\n            upload_response = await http_client.post(\n                f\"/api/upload?progress_id={unique_progress_id}\",\n                files=files\n            )\n        \n        await progress_task  # Wait for upload to complete\n        \n        # Wait a moment for ConceptMesh to be updated\n        await asyncio.sleep(1.0)\n        \n        # Test document-grounded chat\n        chat_queries = [\n            {\n                \"query\": \"What is electron spin?\",\n                \"expected_keywords\": [\"electron\", \"spin\", \"quantum\", \"angular momentum\"],\n                \"expected_source\": \"quantum_physics_test.pdf\"\n            },\n            {\n                \"query\": \"What are the applications of electron spin?\",\n                \"expected_keywords\": [\"MRI\", \"quantum computing\", \"spintronics\"],\n                \"expected_source\": \"quantum_physics_test.pdf\"\n            },\n            {\n                \"query\": \"Who discovered electron spin?\",\n                \"expected_keywords\": [\"Uhlenbeck\", \"Goudsmit\", \"1925\"],\n                \"expected_source\": \"quantum_physics_test.pdf\"\n            }\n        ]\n        \n        for i, test_case in enumerate(chat_queries, 1):\n            print(f\"\\nğŸ” Test Query {i}: {test_case['query']}\")\n            \n            # Send chat request\n            chat_response = await http_client.post(\n                \"/api/answer\",\n                json={\n                    \"user_query\": test_case[\"query\"],\n                    \"persona\": {\"name\": \"TestUser\"}\n                }\n            )\n            \n            assert chat_response.status_code == 200, f\"Chat request failed: {chat_response.status_code}\"\n            chat_data = chat_response.json()\n            \n            # Verify response structure\n            assert \"answer\" in chat_data\n            assert \"sources\" in chat_data\n            assert \"context_used\" in chat_data\n            assert \"documents_consulted\" in chat_data\n            \n            # Verify document grounding\n            assert chat_data[\"context_used\"] == \"document_grounded\", \"Response should be document-grounded\"\n            assert chat_data[\"documents_consulted\"] > 0, \"Should consult at least one document\"\n            \n            # Verify source attribution\n            sources = chat_data[\"sources\"]\n            assert len(sources) > 0, \"Should have source attribution\"\n            \n            # Check if our test document is in sources (flexible matching)\n            source_found = any(\n                \"quantum\" in source.lower() or \"test\" in source.lower() \n                for source in sources\n            )\n            if source_found:\n                print(f\"  âœ… Source attribution: {sources}\")\n            else:\n                print(f\"  âš ï¸ Expected source not found in: {sources}\")\n            \n            # Verify answer contains relevant keywords\n            answer_lower = chat_data[\"answer\"].lower()\n            found_keywords = [\n                keyword for keyword in test_case[\"expected_keywords\"]\n                if keyword.lower() in answer_lower\n            ]\n            \n            print(f\"  âœ… Answer length: {len(chat_data['answer'])} chars\")\n            print(f\"  âœ… Keywords found: {found_keywords}\")\n            print(f\"  âœ… Processing time: {chat_data['processing_time']:.2f}s\")\n            print(f\"  âœ… Confidence: {chat_data['confidence']:.2f}\")\n            \n            # Performance assertions\n            assert chat_data[\"processing_time\"] < 10.0, \"Response should be generated within 10 seconds\"\n            assert len(chat_data[\"answer\"]) > 50, \"Answer should be substantial\"\n            \n    @pytest.mark.e2e\n    @pytest.mark.stress\n    @pytest.mark.slow\n    async def test_concurrent_upload_stress(self, http_client, test_pdf_ml, progress_tracker_factory, test_config):\n        \"\"\"Test 3: Stress test with concurrent uploads and chat queries\"\"\"\n        print(f\"\\nğŸ§ª [STRESS TEST] Testing {test_config['stress_test_workers']} concurrent operations...\")\n        \n        start_time = time.time()\n        results = {\n            \"uploads\": {\"success\": 0, \"failed\": 0, \"times\": []},\n            \"chats\": {\"success\": 0, \"failed\": 0, \"times\": []}\n        }\n        \n        async def upload_worker(worker_id: int) -> Dict[str, Any]:\n            \"\"\"Single upload worker\"\"\"\n            worker_start = time.time()\n            progress_id = f\"stress_{worker_id}_{int(time.time())}\"\n            \n            try:\n                # Track progress\n                tracker = progress_tracker_factory(progress_id)\n                progress_task = asyncio.create_task(tracker.track_progress(timeout=30.0))\n                await asyncio.sleep(0.1)  # Stagger requests slightly\n                \n                # Upload\n                with open(test_pdf_ml, \"rb\") as pdf_file:\n                    files = {\"file\": (f\"ml_test_{worker_id}.pdf\", pdf_file, \"application/pdf\")}\n                    response = await http_client.post(\n                        f\"/api/upload?progress_id={progress_id}\",\n                        files=files\n                    )\n                \n                # Wait for completion\n                progress_result = await progress_task\n                duration = time.time() - worker_start\n                \n                if response.status_code == 200 and progress_result[\"success\"]:\n                    return {\"success\": True, \"duration\": duration, \"worker_id\": worker_id}\n                else:\n                    return {\"success\": False, \"duration\": duration, \"worker_id\": worker_id, \n                           \"error\": f\"HTTP {response.status_code} or SSE failed\"}\n                    \n            except Exception as e:\n                duration = time.time() - worker_start\n                return {\"success\": False, \"duration\": duration, \"worker_id\": worker_id, \"error\": str(e)}\n        \n        async def chat_worker(worker_id: int) -> Dict[str, Any]:\n            \"\"\"Single chat worker\"\"\"\n            worker_start = time.time()\n            \n            try:\n                response = await http_client.post(\n                    \"/api/answer\",\n                    json={\n                        \"user_query\": f\"What are neural networks? (Query {worker_id})\",\n                        \"persona\": {\"name\": f\"StressTestUser{worker_id}\"}\n                    }\n                )\n                \n                duration = time.time() - worker_start\n                \n                if response.status_code == 200:\n                    data = response.json()\n                    return {\n                        \"success\": True, \n                        \"duration\": duration, \n                        \"worker_id\": worker_id,\n                        \"answer_length\": len(data.get(\"answer\", \"\"))\n                    }\n                else:\n                    return {\"success\": False, \"duration\": duration, \"worker_id\": worker_id, \n                           \"error\": f\"HTTP {response.status_code}\"}\n                    \n            except Exception as e:\n                duration = time.time() - worker_start\n                return {\"success\": False, \"duration\": duration, \"worker_id\": worker_id, \"error\": str(e)}\n        \n        # Create worker tasks\n        num_workers = min(test_config[\"stress_test_workers\"], 20)  # Limit for CI\n        \n        upload_tasks = [upload_worker(i) for i in range(num_workers // 2)]\n        chat_tasks = [chat_worker(i) for i in range(num_workers // 2)]\n        \n        # Run all tasks concurrently\n        print(f\"ğŸš€ Starting {len(upload_tasks)} upload + {len(chat_tasks)} chat workers...\")\n        \n        upload_results = await asyncio.gather(*upload_tasks, return_exceptions=True)\n        chat_results = await asyncio.gather(*chat_tasks, return_exceptions=True)\n        \n        # Process results\n        for result in upload_results:\n            if isinstance(result, dict):\n                if result[\"success\"]:\n                    results[\"uploads\"][\"success\"] += 1\n                    results[\"uploads\"][\"times\"].append(result[\"duration\"])\n                else:\n                    results[\"uploads\"][\"failed\"] += 1\n                    print(f\"  âŒ Upload worker {result.get('worker_id')} failed: {result.get('error')}\")\n        \n        for result in chat_results:\n            if isinstance(result, dict):\n                if result[\"success\"]:\n                    results[\"chats\"][\"success\"] += 1\n                    results[\"chats\"][\"times\"].append(result[\"duration\"])\n                else:\n                    results[\"chats\"][\"failed\"] += 1\n                    print(f\"  âŒ Chat worker {result.get('worker_id')} failed: {result.get('error')}\")\n        \n        total_time = time.time() - start_time\n        \n        # Calculate statistics\n        upload_times = results[\"uploads\"][\"times\"]\n        chat_times = results[\"chats\"][\"times\"]\n        \n        upload_avg = sum(upload_times) / len(upload_times) if upload_times else 0\n        chat_avg = sum(chat_times) / len(chat_times) if chat_times else 0\n        \n        upload_success_rate = results[\"uploads\"][\"success\"] / (results[\"uploads\"][\"success\"] + results[\"uploads\"][\"failed\"]) * 100\n        chat_success_rate = results[\"chats\"][\"success\"] / (results[\"chats\"][\"success\"] + results[\"chats\"][\"failed\"]) * 100\n        \n        print(f\"\\nğŸ“Š STRESS TEST RESULTS ({total_time:.2f}s total):\")\n        print(f\"  ğŸ“¤ Uploads: {results['uploads']['success']}/{results['uploads']['success'] + results['uploads']['failed']} success ({upload_success_rate:.1f}%)\")\n        print(f\"  ğŸ’¬ Chats: {results['chats']['success']}/{results['chats']['success'] + results['chats']['failed']} success ({chat_success_rate:.1f}%)\")\n        print(f\"  â±ï¸ Avg Upload Time: {upload_avg:.2f}s\")\n        print(f\"  â±ï¸ Avg Chat Time: {chat_avg:.2f}s\")\n        \n        # Performance assertions\n        assert upload_success_rate >= 90, f\"Upload success rate too low: {upload_success_rate:.1f}%\"\n        assert chat_success_rate >= 95, f\"Chat success rate too low: {chat_success_rate:.1f}%\"\n        assert upload_avg < 15.0, f\"Average upload time too high: {upload_avg:.2f}s\"\n        assert chat_avg < 5.0, f\"Average chat time too high: {chat_avg:.2f}s\"\n        \n        print(\"âœ… Stress test passed all performance criteria!\")\n\n    @pytest.mark.e2e\n    async def test_system_validation_endpoints(self, http_client):\n        \"\"\"Test 4: Validate system monitoring endpoints\"\"\"\n        print(f\"\\nğŸ§ª [TEST] Testing system validation endpoints...\")\n        \n        endpoints = [\n            \"/api/system/validate\",\n            \"/api/system/performance\", \n            \"/api/system/stress-test\",\n            \"/api/system/debug\",\n            \"/api/health\"\n        ]\n        \n        for endpoint in endpoints:\n            print(f\"ğŸ” Testing {endpoint}...\")\n            response = await http_client.get(endpoint)\n            \n            assert response.status_code == 200, f\"{endpoint} failed: {response.status_code}\"\n            data = response.json()\n            \n            # Basic structure validation\n            assert isinstance(data, dict), f\"{endpoint} should return dict\"\n            \n            if endpoint == \"/api/system/validate\":\n                assert \"overall_status\" in data\n                assert \"system_components\" in data\n                print(f\"  âœ… System status: {data['overall_status']}\")\n            \n            elif endpoint == \"/api/system/performance\":\n                assert \"performance_metrics\" in data\n                assert \"optimization_insights\" in data\n                print(f\"  âœ… Performance metrics available\")\n            \n            elif endpoint == \"/api/health\":\n                assert data[\"status\"] == \"healthy\"\n                print(f\"  âœ… Health status: {data['status']}\")\n        \n        print(\"âœ… All system endpoints operational!\")\n\n@pytest.mark.e2e\nasync def test_complete_pipeline_integration(http_client, test_pdf_quantum, progress_tracker_factory, unique_progress_id):\n    \"\"\"Test 5: Complete pipeline - Upload â†’ Process â†’ Chat â†’ Validate\"\"\"\n    print(f\"\\nğŸ§ª [INTEGRATION TEST] Complete pipeline validation...\")\n    \n    pipeline_start = time.time()\n    \n    # Step 1: Upload with progress tracking\n    print(\"ğŸ“¤ Step 1: Uploading document...\")\n    tracker = progress_tracker_factory(unique_progress_id)\n    progress_task = asyncio.create_task(tracker.track_progress())\n    await asyncio.sleep(0.5)\n    \n    with open(test_pdf_quantum, \"rb\") as pdf_file:\n        files = {\"file\": (\"integration_test.pdf\", pdf_file, \"application/pdf\")}\n        upload_response = await http_client.post(\n            f\"/api/upload?progress_id={unique_progress_id}\",\n            files=files\n        )\n    \n    progress_result = await progress_task\n    upload_data = upload_response.json()\n    \n    assert upload_response.status_code == 200\n    assert progress_result[\"success\"]\n    assert upload_data[\"success\"]\n    \n    print(f\"  âœ… Upload completed: {upload_data['document']['concept_count']} concepts\")\n    \n    # Step 2: Wait for mesh integration\n    await asyncio.sleep(2.0)\n    \n    # Step 3: Test document-grounded chat\n    print(\"ğŸ’¬ Step 2: Testing document-grounded chat...\")\n    chat_response = await http_client.post(\n        \"/api/answer\",\n        json={\n            \"user_query\": \"Explain electron spin and its applications\",\n            \"persona\": {\"name\": \"IntegrationTester\"}\n        }\n    )\n    \n    assert chat_response.status_code == 200\n    chat_data = chat_response.json()\n    \n    assert chat_data[\"context_used\"] == \"document_grounded\"\n    assert len(chat_data[\"answer\"]) > 100\n    assert chat_data[\"documents_consulted\"] > 0\n    \n    print(f\"  âœ… Chat response: {len(chat_data['answer'])} chars, {chat_data['documents_consulted']} docs\")\n    \n    # Step 4: Validate system health\n    print(\"ğŸ” Step 3: Validating system health...\")\n    health_response = await http_client.get(\"/api/system/validate\")\n    assert health_response.status_code == 200\n    \n    health_data = health_response.json()\n    assert health_data[\"overall_status\"] in [\"optimal\", \"functional_with_warnings\"]\n    \n    total_time = time.time() - pipeline_start\n    print(f\"\\nâœ… INTEGRATION TEST COMPLETE ({total_time:.2f}s)\")\n    print(f\"  ğŸ“Š System Status: {health_data['overall_status']}\")\n    print(f\"  ğŸ¯ Pipeline Performance: Uploadâ†’Chat in {total_time:.2f}s\")\n    \n    # Performance validation\n    assert total_time < 30.0, f\"Complete pipeline too slow: {total_time:.2f}s\"\n    \nif __name__ == \"__main__\":\n    # Run tests directly\n    pytest.main([__file__, \"-v\", \"--tb=short\"])\n