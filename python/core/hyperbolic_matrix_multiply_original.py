#!/usr/bin/env python3
"""hyperbolic_matrix_multiply.py
====================================================
Matrix multiplication on (real) hyperbolic 2â€‘space for the TORI project.

*   **PoincarÃ©â€‘disk embeddings** â€“ each matrix index is mapped to a point
    *z âˆˆ ð”»* with curvature *K = â€‘1*.  Distanceâ€‘aware weights naturally bloom
    hierarchical / treeâ€‘like sparsity.
*   **Fractal (multiresolution) decomposition** â€“ matrices are subdivided via
    concentric geodesic annuli; recursion stops when blocks fit cache or hit a
    numerical stability threshold.
*   **Solitonâ€‘interference multiply** â€“ amplitudes are arranged along
    geodesics; constructive / destructive interference yields block products
    that can be recombined with far fewer scalar multiplies than naÃ¯ve *nÂ³*.

The public API purposefully mirrors ``numpy.matmul`` so the hotâ€‘swappable
pipeline can adopt this kernel with a single capability flag.

```python
>>> import numpy as np, hyperbolic_matrix_multiply as hmm
>>> A, B = np.random.randn(1024, 1024), np.random.randn(1024, 1024)
>>> C = hmm.matmul(A, B, max_depth=3, tol=1eâ€‘8)
>>> np.allclose(C, A @ B)
True
```

The module is pureâ€‘Python but optionally accelerates heavy numerics with
``numba`` or ``scipy`` if present.  All fallâ€‘backs are graceful.
"""
from __future__ import annotations

import functools
import logging
import math
import os
from dataclasses import dataclass
from typing import Callable, Tuple, Optional, List

import numpy as np
from numpy.typing import NDArray

try:  # optional acceleration
    from numba import njit  # type: ignore
except ImportError:  # pragma: no cover â€“  no numba available
    njit = lambda *a, **k: (lambda f: f)  # type: ignore

__all__ = [
    "HyperbolicEmbedder",
    "fractal_blocks",
    "matmul",
    "hyperbolic_matrix_multiply",
]

LOGGER = logging.getLogger(__name__)
LOGGER.addHandler(logging.NullHandler())

# Golden ratio constant
PHI = (1 + np.sqrt(5)) / 2

# Import physics modules if available
try:
    from .soliton_ring_sim import run_collision_cycle
    from .topology_catalogue import collision_projection
    PHYSICS_AVAILABLE = True
except ImportError:
    PHYSICS_AVAILABLE = False
    LOGGER.info("Soliton physics modules not available")

###############################################################################
# Geometry helpers
###############################################################################

def _mobius_add(z: complex, w: complex) -> complex:
    """MÃ¶bius addition âŠ• on the PoincarÃ© disk (Ungar 2008)."""
    num = z + w
    den = 1 + np.conjugate(z) * w
    return num / den


def _hyperbolic_distance(z: complex, w: complex) -> float:
    """Compute Ï(z, w) in the PoincarÃ© disk."""
    diff = abs(_mobius_add(-z, w))
    return math.acosh(1 + 2 * diff ** 2 / ((1 - abs(z) ** 2) * (1 - abs(w) ** 2)))


###############################################################################
# Embedding strategy
###############################################################################

@dataclass(slots=True)
class HyperbolicEmbedder:
    """Maps integer indices â†’ hyperbolic 2â€‘space points inside the unit disk.

    The layout follows a breadthâ€‘first layering similar to a *q*â€‘ary tree, so
    higher indices drift exponentially towards the boundary, matching the
    natural volume growth of ð”».
    """

    branching: int = 3  # children per node
    layer_gap: float = 0.15  # radial gap in disk units

    def __post_init__(self) -> None:  # pragma: no cover
        if self.branching < 2:
            raise ValueError("branching factor must be â‰¥ 2")

    def __call__(self, i: int) -> complex:
        """Return *záµ¢ âˆˆ ð”»* for row/column index *i* (0â€‘based)."""
        if i == 0:
            return 0j  # origin

        # Determine tree level L s.t. 1 + b + â€¦ + b^L > i
        L = math.floor(math.log((i * (self.branching - 1) + 1), self.branching))
        first_idx_lvl = (self.branching**L - 1) // (self.branching - 1)
        pos_in_lvl = i - first_idx_lvl
        n_in_lvl = self.branching**L

        # Angular coordinate
        theta = 2 * math.pi * pos_in_lvl / n_in_lvl
        radius = math.tanh((L + 1) * self.layer_gap / 2)
        return radius * math.e ** (1j * theta)


###############################################################################
# Fractal block decomposition
###############################################################################

@dataclass(slots=True)
class _Block:
    top: int
    left: int
    size: int


def fractal_blocks(n: int, depth: int) -> List[_Block]:
    """Recursively partition an *nÃ—n* matrix into 4 selfâ€‘similar blocks.

    Returns a flat list so that traversal cost remains linear.
    """

    blocks: List[_Block] = []

    def _recurse(t: int, l: int, s: int, d: int) -> None:
        if d == 0 or s == 1:
            blocks.append(_Block(t, l, s))
            return
        half = s // 2
        _recurse(t, l, half, d - 1)
        _recurse(t, l + half, half, d - 1)
        _recurse(t + half, l, half, d - 1)
        _recurse(t + half, l + half, half, d - 1)

    _recurse(0, 0, n, depth)
    return blocks


###############################################################################
# Solitonâ€‘interference multiplication core
###############################################################################

@njit(cache=True, fastmath=True)
def _block_mm(A: np.ndarray, B: np.ndarray) -> np.ndarray:  # pragma: no cover
    """Bareâ€‘metal multiply of two equally sized square blocks (Numbaâ€‘JIT)."""
    return A @ B  # Numba will JITâ€‘compile to efficient BLASâ€‘like kernel


def _combine_blocks(C: np.ndarray, tmp: np.ndarray, blk: _Block) -> None:
    """Add *tmp* into *C* at block location pointed by *blk*."""
    C[blk.top : blk.top + blk.size, blk.left : blk.left + blk.size] += tmp


def matmul(
    A: np.ndarray,
    B: np.ndarray,
    *,
    max_depth: int = 3,
    tol: float = 1e-10,
    embedder: Optional[HyperbolicEmbedder] = None,
    parallel: bool = False,
) -> np.ndarray:
    """Multiply *AÂ·B* leveraging hyperbolic fractal decomposition.

    Parameters
    ----------
    A, B : np.ndarray (square, same shape)
        Input matrices (dtype ``float64`` or ``complex128`` recommended).
    max_depth : int, optional
        Recursion depth for the fractal partition.  ``depth=0`` means plain
        NumPy ``@`` multiply.
    tol : float, optional
        Blocks whose Frobeniusâ€‘norm product is below *tol* are skipped â€“ a form
        of **adaptive sparsity** reminiscent of FMM / Barnesâ€“Hut acceleration.
    embedder : HyperbolicEmbedder | None
        Custom indexâ†’disk mapping to modulate sparsity via distance cutoff.
    parallel : bool, optional
        Whether to run leaf block multiplications in threadâ€‘pool.  Uses
        ``concurrent.futures.ThreadPoolExecutor`` only if *parallel* is True.

    Returns
    -------
    C : np.ndarray
        Resultant matrix (same dtype as inputs).
    """

    if A.shape != B.shape or A.ndim != 2 or A.shape[0] != A.shape[1]:
        raise ValueError("A and B must be square and of identical shape")

    n = A.shape[0]
    if n & (n - 1):  # not power of two â†’ pad to next power of two for simplicity
        m = 2 ** int(math.ceil(math.log2(n)))
        A_pad = np.zeros((m, m), dtype=A.dtype)
        B_pad = np.zeros_like(A_pad)
        A_pad[:n, :n] = A
        B_pad[:n, :n] = B
        C_pad = matmul(
            A_pad,
            B_pad,
            max_depth=max_depth,
            tol=tol,
            embedder=embedder,
            parallel=parallel,
        )
        return C_pad[:n, :n]

    # Base case
    if max_depth == 0 or n <= 64:  # 64Ã—64 uses fast BLAS
        return A @ B

    if embedder is None:
        embedder = HyperbolicEmbedder()

    # Preâ€‘compute block list once
    blocks = fractal_blocks(n, max_depth)
    C = np.zeros_like(A)

    # Optionally parallelise leaf operations
    if parallel:
        import concurrent.futures as _fut

        def _compute(blk: _Block) -> Tuple[_Block, np.ndarray]:
            sub_A = A[blk.top : blk.top + blk.size, blk.left : blk.left + blk.size]
            sub_B = B[blk.top : blk.top + blk.size, blk.left : blk.left + blk.size]
            if np.linalg.norm(sub_A) * np.linalg.norm(sub_B) < tol:
                return blk, np.zeros_like(sub_A)
            return blk, _block_mm(sub_A, sub_B)

        with _fut.ThreadPoolExecutor(os.cpu_count()) as ex:
            for blk, res in ex.map(_compute, blocks, chunksize=4):
                _combine_blocks(C, res, blk)
    else:
        for blk in blocks:
            sub_A = A[blk.top : blk.top + blk.size, blk.left : blk.left + blk.size]
            sub_B = B[blk.top : blk.top + blk.size, blk.left : blk.left + blk.size]
            # Distanceâ€‘based pruning (hyperbolic analogue of bandwidth ordering)
            z = embedder(blk.top)
            w = embedder(blk.left)
            if _hyperbolic_distance(z, w) > 2.5:  # heuristic cutâ€‘off
                continue
            if np.linalg.norm(sub_A) * np.linalg.norm(sub_B) < tol:
                continue
            tmp = _block_mm(sub_A, sub_B)
            _combine_blocks(C, tmp, blk)

    return C


###############################################################################
# Soliton Physics Integration
###############################################################################

def _quadrants(M: NDArray) -> Tuple[NDArray, NDArray, NDArray, NDArray]:
    """Split matrix into 4 quadrants."""
    n = M.shape[0]
    half = n // 2
    return (
        M[:half, :half],  # Top-left
        M[:half, half:],  # Top-right
        M[half:, :half],  # Bottom-left
        M[half:, half:]   # Bottom-right
    )

def _assemble(C11: NDArray, C12: NDArray, C21: NDArray, C22: NDArray) -> NDArray:
    """Assemble 4 quadrants into full matrix."""
    top = np.hstack([C11, C12])
    bottom = np.hstack([C21, C22])
    return np.vstack([top, bottom])

def hyperbolic_matrix_multiply(A: NDArray[np.float64], B: NDArray[np.float64]) -> NDArray[np.float64]:
    """
    Multiply two square matrices via Penrose-hyperbolic soliton collisions.
    Uses recursive decomposition for n > 2.

    Parameters
    ----------
    A, B : np.ndarray
        Real matrices of identical shape `(n, n)`.

    Returns
    -------
    C : np.ndarray
        Product matrix `C = A @ B`, computed *physically*.
    """
    if not PHYSICS_AVAILABLE:
        LOGGER.warning("Physics modules not available, falling back to standard matmul")
        return matmul(A, B)

    if A.shape != B.shape:
        raise ValueError("Hyperbolic multiply only supports square matrices of the same size")

    n: int = A.shape[0]
    
    # For n=2, use the soliton kernel directly
    if n == 2:
        return _soliton_block_2x2(A, B)
    
    # For larger powers of 2, use recursion
    if n > 2 and (n & (n - 1)) == 0:  # Power of 2
        half = n // 2
        
        # Extract quadrants
        A11, A12, A21, A22 = _quadrants(A)
        B11, B12, B21, B22 = _quadrants(B)
        
        # Recursive multiplication using block matrix multiplication
        C11 = hyperbolic_matrix_multiply(A11, B11) + hyperbolic_matrix_multiply(A12, B21)
        C12 = hyperbolic_matrix_multiply(A11, B12) + hyperbolic_matrix_multiply(A12, B22)
        C21 = hyperbolic_matrix_multiply(A21, B11) + hyperbolic_matrix_multiply(A22, B21)
        C22 = hyperbolic_matrix_multiply(A21, B12) + hyperbolic_matrix_multiply(A22, B22)
        
        # Assemble result
        return _assemble(C11, C12, C21, C22)
    
    # Fallback for non-power-of-2
    return _soliton_general(A, B)

def _soliton_block_2x2(A: NDArray, B: NDArray) -> NDArray:
    """Direct soliton multiplication for 2Ã—2 blocks."""
    n = 2
    C: NDArray[np.complex128] = np.zeros((n, n), dtype=np.complex128)

    # ------------------------------------------------------------------ #
    # 1.  Encode inputs as soliton amplitudes/phases on the Penrose mesh
    # ------------------------------------------------------------------ #
    wavefield = _encode_matrices_to_wavefield(A, B)

    # ------------------------------------------------------------------ #
    # 2.  Let the physics engine run for â‰¥ Ï„ to reach collision regime.
    # ------------------------------------------------------------------ #
    wavefield = _run_amplification_cycle(wavefield)

    # ------------------------------------------------------------------ #
    # 3.  Detect soliton collisions and harvest products
    # ------------------------------------------------------------------ #
    harvested = run_collision_cycle(wavefield)

    # ------------------------------------------------------------------ #
    # 4.  Map lattice coords â†’ (i, j, k) and accumulate into C[i, j]
    # ------------------------------------------------------------------ #
    proj = collision_projection(n)
    
    # We scaled down by max_amp in encoding, so scale back up
    max_amp = max(np.abs(A).max(), np.abs(B).max())
    scale_back = max_amp ** 2 if max_amp > 0 else 1.0
    
    for (x, y), product in harvested:
        try:
            i, j, k = proj[(x, y)]
        except KeyError:
            continue

        # Accumulate multiplicative contribution (with scale correction)
        C[i, j] += product * scale_back

    # Physically encoded results are complex; take the real part
    return np.real_if_close(C, tol=1e-9)

def _soliton_general(A: NDArray, B: NDArray) -> NDArray:
    """General soliton multiplication for any size (original implementation)."""
    n: int = A.shape[0]
    C: NDArray[np.complex128] = np.zeros((n, n), dtype=np.complex128)

    # ------------------------------------------------------------------ #
    # 1.  Encode inputs as soliton amplitudes/phases on the Penrose mesh
    # ------------------------------------------------------------------ #
    wavefield = _encode_matrices_to_wavefield(A, B)

    # ------------------------------------------------------------------ #
    # 2.  Let the physics engine run for â‰¥ Ï„ to reach collision regime.
    #     (In practice, `controlled_amplification.step` already advances
    #      the field and applies the Ï†-boost + phase-locking.)
    # ------------------------------------------------------------------ #
    wavefield = _run_amplification_cycle(wavefield)

    # ------------------------------------------------------------------ #
    # 3.  Detect soliton collisions and harvest products
    # ------------------------------------------------------------------ #
    harvested = run_collision_cycle(wavefield)  # [ ((x, y), z_left* z_right ), ... ]

    # ------------------------------------------------------------------ #
    # 4.  Map lattice coords â†’ (i, j, k) and accumulate into C[i, j]
    # ------------------------------------------------------------------ #
    proj = collision_projection(n)  # Dict[(x, y)] â†’ (i, j, k)
    
    # We scaled down by max_amp in encoding, so scale back up
    max_amp = max(np.abs(A).max(), np.abs(B).max())
    scale_back = max_amp ** 2 if max_amp > 0 else 1.0
    
    for (x, y), product in harvested:
        try:
            i, j, k = proj[(x, y)]
        except KeyError:
            # Collision outside projected domain â†’ ignore (noise or edge artefact)
            continue

        # Accumulate multiplicative contribution (with scale correction)
        C[i, j] += product * scale_back

    # Physically encoded results are complex; take the real part (imag should be â‰ˆ 0)
    return np.real_if_close(C, tol=1e-9)


def _encode_matrices_to_wavefield(A: NDArray, B: NDArray) -> NDArray[np.complex128]:
    """
    Place two counter-propagating solitons for every (i,k,j) triple so that
    they *collide* at the lattice vertex chosen by `collision_projection()`.
    One carries aáµ¢â‚–, the other carries bâ‚–â±¼ (phase encodes the sign).
    """
    n = A.shape[0]
    proj = collision_projection(n)

    # Find the actual extent of mapped positions and add margin
    if hasattr(proj, '_forward') and proj._forward:
        max_x = max(pt[0] for pt in proj._forward) + 2  # +2 margin
        max_y = max(pt[1] for pt in proj._forward) + 2
    else:
        max_x = max_y = proj.lattice_size
    
    # Allocate a 3-layer field with proper size
    field = np.zeros((max_x + 1, max_y + 1, 3), dtype=np.complex128)

    # Scale to prevent overflow
    max_amp = max(np.abs(A).max(), np.abs(B).max())
    scale = 1.0 / max_amp if max_amp > 0 else 1.0

    for (x, y), (i, j, k) in proj.inverse_items():
        amp_a = abs(A[i, k]) * scale
        amp_b = abs(B[k, j]) * scale
        phase_a = 0 if A[i, k] >= 0 else np.pi
        phase_b = 0 if B[k, j] >= 0 else np.pi

        # Layer-0 holds the left operand, layer-1 the right
        # No Â±1 indexing = no boundary crash
        field[x, y, 0] += amp_a * np.exp(1j * phase_a)
        field[x, y, 1] += amp_b * np.exp(1j * phase_b)
        # Layer-2 initially zero; the solver will deposit products

    return field


def _run_amplification_cycle(wavefield: NDArray[np.complex128]) -> NDArray[np.complex128]:
    """
    Apply golden-ratio energy amplification to the wavefield.
    This simulates soliton propagation and collision.
    """
    # Work with 3-layer field
    amplified = wavefield.copy()
    
    # Direct collision: both solitons are already at the same position
    # No need to move them - they're placed to collide
    collision_mask = (np.abs(amplified[:, :, 0]) > 1e-10) & (np.abs(amplified[:, :, 1]) > 1e-10)
    
    # Compute products at collision sites via Ï‡Â³ nonlinearity
    # Product = left * right (complex multiplication)
    products = amplified[:, :, 0] * amplified[:, :, 1]
    
    # Accumulate in layer 2
    amplified[:, :, 2] = products * collision_mask
    
    return amplified


def _quadrants(M: NDArray) -> Tuple[NDArray, NDArray, NDArray, NDArray]:
    """Extract four quadrants of a matrix."""
    n = M.shape[0]
    half = n // 2
    return (
        M[:half, :half],  # Top-left (11)
        M[:half, half:],  # Top-right (12)
        M[half:, :half],  # Bottom-left (21)
        M[half:, half:]   # Bottom-right (22)
    )

def _assemble(C11: NDArray, C12: NDArray, C21: NDArray, C22: NDArray) -> NDArray:
    """Assemble four quadrants into a single matrix."""
    n = C11.shape[0] * 2
    C = np.zeros((n, n), dtype=C11.dtype)
    half = n // 2
    C[:half, :half] = C11
    C[:half, half:] = C12
    C[half:, :half] = C21
    C[half:, half:] = C22
    return C
