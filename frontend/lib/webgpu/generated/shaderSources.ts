/**
 * Auto-generated shader bundle
 * Generated: 2025-08-14T18:25:02.464Z
 * Total shaders: 30
 * 
 * DO NOT EDIT - This file is auto-generated by scripts/bundleShaders.mjs
 */

// Shader: adaptive_optics_correction.wgsl
// Purpose: No description
export const adaptive_optics_correction_wgsl = "// adaptive_optics_correction.wgsl\n// Zernike-based aberration correction with user controls\n// Supports defocus + astigmatism + coma; controlled from UI sliders (no EEG, no external tracker)\n\nstruct Params {\n    width: u32,\n    height: u32,\n    pupil_radius_px: f32,   // map screen coords to pupil\n    // Zernike coefficients (user-controlled via sliders)\n    c_defocus: f32,         // Z4: Defocus\n    c_astig0: f32,          // Z5: Astigmatism 0°\n    c_astig45: f32,         // Z6: Astigmatism 45°\n    c_coma_x: f32,          // Z7: Coma X\n    c_coma_y: f32,          // Z8: Coma Y\n    c_spherical: f32,       // Z11: Spherical aberration\n    c_trefoil_x: f32,       // Z9: Trefoil X\n    c_trefoil_y: f32,       // Z10: Trefoil Y\n    phase_scale: f32,       // 2π/λ\n}\n\n@group(0) @binding(0) var<uniform> p: Params;\n@group(0) @binding(1) var<storage, read_write> field: array<vec2<f32>>;\n\n// Complex multiplication\nfn c_mul(a: vec2<f32>, b: vec2<f32>) -> vec2<f32> {\n    return vec2<f32>(a.x*b.x - a.y*b.y, a.x*b.y + a.y*b.x);\n}\n\n// Complex from phase\nfn c_from_phase(phi: f32) -> vec2<f32> { \n    return vec2<f32>(cos(phi), sin(phi)); \n}\n\n@compute @workgroup_size(8, 8, 1)\nfn main(@builtin(global_invocation_id) gid: vec3<u32>) {\n    if (gid.x >= p.width || gid.y >= p.height) { \n        return; \n    }\n    let idx = gid.y * p.width + gid.x;\n    \n    // Convert to normalized pupil coordinates\n    let cx = f32(p.width) * 0.5;\n    let cy = f32(p.height) * 0.5;\n    let x = (f32(gid.x) - cx) / p.pupil_radius_px;\n    let y = (f32(gid.y) - cy) / p.pupil_radius_px;\n    let r = sqrt(x*x + y*y);\n    let r2 = r * r;\n    let r3 = r2 * r;\n    let r4 = r2 * r2;\n    \n    // Outside pupil → unchanged\n    if (r > 1.0) { \n        return; \n    }\n    \n    let theta = atan2(y, x);\n    let cos_theta = cos(theta);\n    let sin_theta = sin(theta);\n    let cos_2theta = cos(2.0 * theta);\n    let sin_2theta = sin(2.0 * theta);\n    let cos_3theta = cos(3.0 * theta);\n    let sin_3theta = sin(3.0 * theta);\n    \n    // Zernike polynomials (ANSI standard ordering)\n    var phase = 0.0;\n    \n    // Z4: Defocus (2r² - 1)\n    phase += p.c_defocus * (2.0 * r2 - 1.0);\n    \n    // Z5-Z6: Astigmatism\n    phase += p.c_astig0 * r2 * cos_2theta;  // 0° astigmatism\n    phase += p.c_astig45 * r2 * sin_2theta; // 45° astigmatism\n    \n    // Z7-Z8: Coma\n    phase += p.c_coma_x * (3.0*r3 - 2.0*r) * cos_theta;\n    phase += p.c_coma_y * (3.0*r3 - 2.0*r) * sin_theta;\n    \n    // Z9-Z10: Trefoil\n    phase += p.c_trefoil_x * r3 * cos_3theta;\n    phase += p.c_trefoil_y * r3 * sin_3theta;\n    \n    // Z11: Spherical aberration\n    phase += p.c_spherical * (6.0*r4 - 6.0*r2 + 1.0);\n    \n    // Apply phase correction (negative to pre-correct)\n    let phi = -p.phase_scale * phase;\n    \n    // Apply to field\n    if (idx < arrayLength(&field)) {\n        field[idx] = c_mul(field[idx], c_from_phase(phi));\n    }\n}\n\n// Advanced: Shack-Hartmann-inspired wavefront sensing\n@compute @workgroup_size(8, 8, 1)\nfn measure_aberrations(@builtin(global_invocation_id) gid: vec3<u32>) {\n    // This would measure the actual aberrations from the wavefront\n    // For now, it's a placeholder for future auto-correction\n    // Could use spot patterns or phase diversity to estimate Zernike coeffs\n}";

// Shader: avatarShader.wgsl
// Purpose: No description
export const avatarShader_wgsl = "// avatarShader.wgsl\n// Avatar rendering shader with animation support\n\nstruct AvatarParams {\n    modelMatrix: mat4x4<f32>,\n    viewMatrix: mat4x4<f32>,\n    projectionMatrix: mat4x4<f32>,\n    time: f32,\n    jawOpen: f32,\n    glowIntensity: f32,\n    _padding: f32,  // For 16-byte alignment\n}\n\n@group(0) @binding(0) var<uniform> params: AvatarParams;\n\nstruct VertexInput {\n    @location(0) position: vec3<f32>,\n    @location(1) normal: vec3<f32>,\n    @location(2) uv: vec2<f32>,\n}\n\nstruct VertexOutput {\n    @builtin(position) position: vec4<f32>,\n    @location(0) worldPosition: vec3<f32>,\n    @location(1) normal: vec3<f32>,\n    @location(2) uv: vec2<f32>,\n}\n\n@vertex\nfn vs_main(input: VertexInput) -> VertexOutput {\n    var output: VertexOutput;\n    \n    // Apply jaw animation\n    var animatedPosition = input.position;\n    let jawMovement = sin(params.time * 15.0) * 0.03 * params.jawOpen;\n    animatedPosition.y += jawMovement;\n    \n    // Apply breathing animation\n    let breathingScale = 1.0 + sin(params.time * 1.5) * 0.002;\n    animatedPosition *= breathingScale;\n    \n    // Transform position\n    let worldPos = params.modelMatrix * vec4<f32>(animatedPosition, 1.0);\n    let viewPos = params.viewMatrix * worldPos;\n    output.position = params.projectionMatrix * viewPos;\n    \n    output.worldPosition = worldPos.xyz;\n    output.normal = (params.modelMatrix * vec4<f32>(input.normal, 0.0)).xyz;\n    output.uv = input.uv;\n    \n    return output;\n}\n\n@fragment\nfn fs_main(input: VertexOutput) -> @location(0) vec4<f32> {\n    // Calculate glow with pulsing effect\n    let glowPulse = 0.5 + 0.5 * sin(params.time * 2.0);\n    let talkingBoost = 1.0 + params.jawOpen * 0.5;\n    let baseIntensity = params.glowIntensity * glowPulse * talkingBoost;\n    \n    // Color calculation\n    let redChannel = baseIntensity * (1.0 + params.jawOpen * 0.2);\n    let greenChannel = 0.2 + params.jawOpen * 0.1;\n    let blueChannel = 0.8 - params.jawOpen * 0.1;\n    \n    var color = vec3<f32>(redChannel, greenChannel, blueChannel);\n    \n    // Apply simple lighting\n    let lightDir = normalize(vec3<f32>(0.5, 1.0, 0.5));\n    let ndotl = max(dot(normalize(input.normal), lightDir), 0.0);\n    color *= 0.5 + 0.5 * ndotl;\n    \n    return vec4<f32>(color, 1.0);\n}\n\n// Compute shader variant for avatar processing\n@compute @workgroup_size(8, 8, 1)\nfn compute_main(@builtin(global_invocation_id) gid: vec3<u32>) {\n    // Placeholder compute shader functionality\n    // Could be used for avatar mesh deformation, particle effects, etc.\n    let index = gid.x + gid.y * 8u;\n}\n";

// Shader: bitReversal.wgsl
// Purpose: No description
export const bitReversal_wgsl = "// File: frontend/shaders/bitReversal.wgsl\n// Bit-reversal permutation for FFT with precomputed lookup table\n\n// -------------------------------\n// Struct Definitions\n// -------------------------------\nstruct FFTUniforms {\n    size: u32,             // FFT size (e.g., 1024)\n    log_size: u32,         // log2(size)\n    batch_size: u32,       // Number of parallel batches\n    normalization: f32,    // Normalization factor\n    dimensions: u32,       // 1D or 2D FFT\n    direction: u32,        // Forward or inverse\n    stage: u32,            // FFT stage\n    _padding: u32          // Padding for 16-byte alignment\n}\n\n// -------------------------------\n// Bindings\n// -------------------------------\n@group(0) @binding(0) var<uniform> uniforms: FFTUniforms;\n@group(0) @binding(1) var<storage, read> bit_reversal: array<u32>;\n@group(0) @binding(2) var<storage, read> input: array<vec2<f32>>;\n@group(0) @binding(3) var<storage, read_write> output: array<vec2<f32>>;\n\n// -------------------------------\n// Constants\n// -------------------------------\n@id(0) override workgroup_size_x: u32 = 256u;\n@id(1) override normalization_mode: u32 = 0u;  // Add the missing constant\n\n// -------------------------------\n// Entry Point\n// -------------------------------\n\nfn clamp_index_dyn(i: u32, len: u32) -> u32 {\n    return select(i, len - 1u, i >= len);\n}\n\n@compute @workgroup_size(workgroup_size_x, 1, 1)\nfn main(\n    @builtin(global_invocation_id) global_id: vec3<u32>,\n    @builtin(num_workgroups) num_workgroups: vec3<u32>\n) {\n    let idx = global_id.x;\n    let fft_size = uniforms.size;\n    let total = fft_size * uniforms.batch_size;\n\n    // Defensive bound check\n    if (idx >= total) {\n        return;\n    }\n\n    // Batch and element index\n    let batch = idx / fft_size;\n    let i = idx % fft_size;\n    let offset = batch * fft_size;\n\n    // Bit-reversal lookup with bounds checking\n    let j = bit_reversal[clamp_index_dyn(i, arrayLength(&bit_reversal))];\n\n    // Perform the copy with bounds checking\n    output[clamp_index_dyn(offset + j, arrayLength(&output))] = input[clamp_index_dyn(offset + i, arrayLength(&input))];\n}\n";

// Shader: butterflyStage.wgsl
// Purpose: No description
export const butterflyStage_wgsl = "// butterflyStage.wgsl\n// Radix-2 butterfly computation for FFT stages with optimizations\n// Processes one stage of the FFT using Cooley-Tukey algorithm\n\nstruct FFTUniforms {\n    size: u32,\n    log_size: u32,\n    batch_size: u32,\n    normalization: f32,\n    dimensions: u32,\n    direction: u32,\n    stage: u32,\n    twiddle_offset: u32  // Precomputed offset for this stage\n}\n\n@group(0) @binding(0) var<uniform> uniforms: FFTUniforms;\n@group(0) @binding(1) var<storage, read> twiddles: array<vec2<f32>>;\n@group(0) @binding(2) var<storage, read> input: array<vec2<f32>>;\n@group(0) @binding(3) var<storage, read_write> output: array<vec2<f32>>;\n\n// Specialization constant for workgroup size\nconst workgroup_size_x: u32 = 256u;\n\n// Optimized complex multiplication using FMA (fused multiply-add)\n\nfn clamp_index_dyn(i: u32, len: u32) -> u32 {\n    return select(i, len - 1u, i >= len);\n}\n\nfn complex_multiply_fma(a: vec2<f32>, b: vec2<f32>) -> vec2<f32> {\n    return vec2<f32>(\n        fma(a.x, b.x, -a.y * b.y),  // a.x * b.x - a.y * b.y\n        fma(a.x, b.y,  a.y * b.x)   // a.x * b.y + a.y * b.x\n    );\n}\n\n// Alternative complex multiply for when FMA is not available\nfn complex_multiply(a: vec2<f32>, b: vec2<f32>) -> vec2<f32> {\n    return vec2<f32>(\n        a.x * b.x - a.y * b.y,\n        a.x * b.y + a.y * b.x\n    );\n}\n\n@compute @workgroup_size(workgroup_size_x, 1, 1)\nfn main(\n    @builtin(global_invocation_id) global_id: vec3<u32>,\n    @builtin(local_invocation_id) local_id: vec3<u32>\n) {\n    let thread_id = global_id.x;\n    let stage = uniforms.stage;\n    let half_size = uniforms.size >> 1u;\n    let total_butterflies = half_size * uniforms.batch_size;\n    \n    // Bounds check\n    if (thread_id >= total_butterflies) { \n        return; \n    }\n    \n    // Calculate batch and butterfly indices\n    let batch_idx = thread_id / half_size;\n    let butterfly_idx = thread_id % half_size;\n    let batch_offset = batch_idx * uniforms.size;\n    \n    // Calculate indices for butterfly operation\n    let stage_size = 1u << (stage + 1u);\n    let half_stage = stage_size >> 1u;\n    let group = butterfly_idx / half_stage;\n    let pair = butterfly_idx % half_stage;\n    \n    let idx_a = batch_offset + group * stage_size + pair;\n    let idx_b = idx_a + half_stage;\n    \n    // Get twiddle factor using precomputed offset with bounds checking\n    let twiddle_idx = uniforms.twiddle_offset + pair;\n    let twiddle = twiddles[clamp_index_dyn(twiddle_idx, arrayLength(&twiddles))];\n    \n    // Load values with bounds checking\n    let a = input[clamp_index_dyn(idx_a, arrayLength(&input))];\n    let b = input[clamp_index_dyn(idx_b, arrayLength(&input))];\n    \n    // Butterfly operation with FMA optimization\n    let b_twiddle = complex_multiply_fma(b, twiddle);\n    \n    // Store results with bounds checking\n    output[clamp_index_dyn(idx_a, arrayLength(&output))] = a + b_twiddle;\n    output[clamp_index_dyn(idx_b, arrayLength(&output))] = a - b_twiddle;\n}\n\n// Shared memory variant for better cache utilization\n// Use when butterfly pairs fit in shared memory\nconst BUTTERFLIES_PER_WORKGROUP: u32 = 128u;\nvar<workgroup> shared_data: array<vec2<f32>, BUTTERFLIES_PER_WORKGROUP * 2u>;\n\n@compute @workgroup_size(BUTTERFLIES_PER_WORKGROUP, 1, 1)\nfn main_shared(\n    @builtin(global_invocation_id) global_id: vec3<u32>,\n    @builtin(local_invocation_id) local_id: vec3<u32>,\n    @builtin(workgroup_id) workgroup_id: vec3<u32>\n) {\n    let stage = uniforms.stage;\n    let stage_size = 1u << (stage + 1u);\n    let half_stage = stage_size >> 1u;\n    \n    // Calculate global butterfly index\n    let butterfly_idx = workgroup_id.x * BUTTERFLIES_PER_WORKGROUP + local_id.x;\n    let batch_idx = butterfly_idx / (uniforms.size >> 1u);\n    \n    if (batch_idx >= uniforms.batch_size) {\n        return;\n    }\n    \n    // Load data into shared memory\n    let local_idx = local_id.x;\n    let group = (butterfly_idx % (uniforms.size >> 1u)) / half_stage;\n    let pair = (butterfly_idx % (uniforms.size >> 1u)) % half_stage;\n    \n    let batch_offset = batch_idx * uniforms.size;\n    let idx_a = batch_offset + group * stage_size + pair;\n    let idx_b = idx_a + half_stage;\n    \n    // Shared memory accesses with bounds checking\n    let shared_idx_a = local_idx * 2u;\n    let shared_idx_b = local_idx * 2u + 1u;\n    \n    if (shared_idx_a < BUTTERFLIES_PER_WORKGROUP * 2u) {\n        shared_data[shared_idx_a] = input[clamp_index_dyn(idx_a, arrayLength(&input))];\n    }\n    if (shared_idx_b < BUTTERFLIES_PER_WORKGROUP * 2u) {\n        shared_data[shared_idx_b] = input[clamp_index_dyn(idx_b, arrayLength(&input))];\n    }\n    \n    workgroupBarrier();\n    \n    // Perform butterfly operation with bounds checking\n    var a = vec2<f32>(0.0, 0.0);\n    var b = vec2<f32>(0.0, 0.0);\n    \n    if (shared_idx_a < BUTTERFLIES_PER_WORKGROUP * 2u) {\n        a = shared_data[shared_idx_a];\n    }\n    if (shared_idx_b < BUTTERFLIES_PER_WORKGROUP * 2u) {\n        b = shared_data[shared_idx_b];\n    }\n    \n    let twiddle_idx = uniforms.twiddle_offset + pair;\n    let twiddle = twiddles[clamp_index_dyn(twiddle_idx, arrayLength(&twiddles))];\n    let b_twiddle = complex_multiply_fma(b, twiddle);\n    \n    // Write results with bounds checking\n    output[clamp_index_dyn(idx_a, arrayLength(&output))] = a + b_twiddle;\n    output[clamp_index_dyn(idx_b, arrayLength(&output))] = a - b_twiddle;\n}\n\n// Documentation:\n// - Stage 0: butterflies span 2 elements (groups of 2)\n// - Stage 1: butterflies span 4 elements (groups of 4)\n// - Stage n: butterflies span 2^(n+1) elements\n// Twiddle factors are precomputed and stored consecutively per stage\n";

// Shader: fftShift.wgsl
// Purpose: No description
export const fftShift_wgsl = "// fftShift.wgsl ÃƒÆ’Ã†â€™Ãƒâ€šÃ‚Â¢ÃƒÆ’Ã‚Â¢ÃƒÂ¢Ã¢â€šÂ¬Ã…Â¡Ãƒâ€šÃ‚Â¬ÃƒÆ’Ã‚Â¢ÃƒÂ¢Ã¢â‚¬Å¡Ã‚Â¬Ãƒâ€šÃ‚Â Fixed for bundling\r\nstruct FFTUniforms {\r\n    size: u32,\r\n    log_size: u32,\r\n    batch_size: u32,\r\n    normalization: f32,\r\n    dimensions: u32,\r\n    direction: u32,\r\n    stage: u32,\r\n    _padding: u32\r\n}\r\n\r\n@group(0) @binding(0) var<uniform> uniforms: FFTUniforms;\r\n@group(0) @binding(2) var<storage, read> input: array<vec2<f32>>;\r\n@group(0) @binding(3) var<storage, read_write> output: array<vec2<f32>>;\r\n\r\nconst workgroup_size_x: u32 = 256u;\r\n\r\n\nfn clamp_index_dyn(i: u32, len: u32) -> u32 {\n    return select(i, len - 1u, i >= len);\n}\n\nfn fft_shift_2d(idx: u32) {\r\n    let N = uniforms.size;\r\n    let N2 = N * N;\r\n    let b = uniforms.batch_size;\r\n    if (idx >= N2 * b) { return; }\r\n\r\n    let batch = idx / N2;\r\n    let i = idx % N2;\r\n\r\n    let x = i % N;\r\n    let y = i / N;\r\n    let hx = x ^ (N >> 1u);\r\n    let hy = y ^ (N >> 1u);\r\n    let j = hy * N + hx;\r\n\r\n    output[clamp_index_dyn(batch * N2 + j, arrayLength(&output))] = input[clamp_index_dyn(batch * N2 + i, arrayLength(&input))];\r\n}\r\n\r\n@compute @workgroup_size(workgroup_size_x, 1, 1)\r\nfn main(@builtin(global_invocation_id) id: vec3<u32>) {\r\n    let i = id.x;\r\n\r\n    switch uniforms.dimensions {\r\n        case 2u { fft_shift_2d(i); }\r\n        default { return; }\r\n    }\r\n}\r\n";

// Shader: hybridWavefieldBlend.wgsl
// Purpose: No description
export const hybridWavefieldBlend_wgsl = "// hybridWavefieldBlend.wgsl\n// TORI-GAEA Hybrid Holographic Core - Wavefield Blending Shader\n// TODO: Restore proper implementation\n\nstruct VertexOutput {\n    @builtin(position) position: vec4<f32>,\n    @location(0) uv: vec2<f32>,\n}\n\n@vertex\nfn vs_main(@builtin(vertex_index) vertex_index: u32) -> VertexOutput {\n    var output: VertexOutput;\n    let x = f32((vertex_index << 1u) & 2u);\n    let y = f32(vertex_index & 2u);\n    output.position = vec4<f32>(x * 2.0 - 1.0, y * 2.0 - 1.0, 0.0, 1.0);\n    output.uv = vec2<f32>(x, 1.0 - y);\n    return output;\n}\n\n@fragment\nfn fs_main(input: VertexOutput) -> @location(0) vec4<f32> {\n    return vec4<f32>(input.uv, 0.0, 1.0);\n}";

// Shader: learned_wave_operator.wgsl
// Purpose: No description
export const learned_wave_operator_wgsl = "// learned_wave_operator.wgsl\n// Neural operator stub - will be replaced with ONNX model later\n// For now, implements sophisticated convolution-based wave propagation\n\nstruct Params { \n    width: u32,\n    height: u32,\n    kernel_size: u32,      // 3, 5, or 7\n    num_layers: u32,        // Number of conv layers to apply\n    nonlinearity: u32,      // 0: None, 1: ReLU, 2: Tanh, 3: GELU\n}\n\n@group(0) @binding(0) var<uniform> p: Params;\n@group(0) @binding(1) var<storage, read> inField: array<vec2<f32>>;\n@group(0) @binding(2) var<storage, read> kernel: array<vec2<f32>>;    // Complex kernels, flattened\n@group(0) @binding(3) var<storage, read_write> outField: array<vec2<f32>>;\n// Additional kernels for multi-layer network\n@group(0) @binding(4) var<storage, read> kernel2: array<vec2<f32>>;   // Second layer kernel\n@group(0) @binding(5) var<storage, read> bias: array<vec2<f32>>;      // Complex bias terms\n\n// Safe array access\nfn at(buf: ptr<storage, array<vec2<f32>>, read>, x: i32, y: i32) -> vec2<f32> {\n    let xi = clamp(x, 0, i32(p.width) - 1);\n    let yi = clamp(y, 0, i32(p.height) - 1);\n    let idx = u32(yi) * p.width + u32(xi);\n    if (idx < arrayLength(buf)) {\n        return (*buf)[idx];\n    }\n    return vec2<f32>(0.0, 0.0);\n}\n\n// Complex multiplication\nfn c_mul(a: vec2<f32>, b: vec2<f32>) -> vec2<f32> {\n    return vec2<f32>(a.x*b.x - a.y*b.y, a.x*b.y + a.y*b.x);\n}\n\n// GELU activation for complex numbers (applied to magnitude)\nfn c_gelu(z: vec2<f32>) -> vec2<f32> {\n    let mag = length(z);\n    let phase = atan2(z.y, z.x);\n    \n    // GELU(x) = x * Φ(x) where Φ is CDF of standard normal\n    // Approximation: 0.5 * x * (1 + tanh(sqrt(2/π) * (x + 0.044715 * x^3)))\n    let c = sqrt(2.0 / 3.14159265359);\n    let gelu_mag = 0.5 * mag * (1.0 + tanh(c * (mag + 0.044715 * mag * mag * mag)));\n    \n    return vec2<f32>(gelu_mag * cos(phase), gelu_mag * sin(phase));\n}\n\n// Apply nonlinearity\nfn apply_activation(z: vec2<f32>, activation_type: u32) -> vec2<f32> {\n    switch (activation_type) {\n        case 0u: { return z; }                    // Linear\n        case 1u: {                                 // ReLU (on magnitude)\n            let mag = max(0.0, length(z));\n            let phase = atan2(z.y, z.x);\n            return vec2<f32>(mag * cos(phase), mag * sin(phase));\n        }\n        case 2u: {                                 // Tanh (on real and imag separately)\n            return vec2<f32>(tanh(z.x), tanh(z.y));\n        }\n        case 3u: { return c_gelu(z); }             // GELU\n        default: { return z; }\n    }\n}\n\n@compute @workgroup_size(8, 8, 1)\nfn main(@builtin(global_invocation_id) gid: vec3<u32>) {\n    if (gid.x >= p.width || gid.y >= p.height) { \n        return; \n    }\n    let x = i32(gid.x);\n    let y = i32(gid.y);\n    let idx = gid.y * p.width + gid.x;\n    \n    var acc = vec2<f32>(0.0, 0.0);\n    let half_kernel = i32(p.kernel_size) / 2;\n    \n    // First convolution layer\n    var k_idx = 0u;\n    for (var j = -half_kernel; j <= half_kernel; j = j + 1) {\n        for (var i = -half_kernel; i <= half_kernel; i = i + 1) {\n            if (k_idx < arrayLength(&kernel)) {\n                let field_val = at(&inField, x + i, y + j);\n                let kernel_val = kernel[k_idx];\n                acc = acc + c_mul(field_val, kernel_val);\n            }\n            k_idx = k_idx + 1u;\n        }\n    }\n    \n    // Add bias if available\n    if (idx < arrayLength(&bias)) {\n        acc = acc + bias[idx];\n    }\n    \n    // Apply activation\n    acc = apply_activation(acc, p.nonlinearity);\n    \n    // Second layer if requested (residual connection)\n    if (p.num_layers > 1u && arrayLength(&kernel2) > 0u) {\n        var acc2 = vec2<f32>(0.0, 0.0);\n        k_idx = 0u;\n        \n        for (var j = -half_kernel; j <= half_kernel; j = j + 1) {\n            for (var i = -half_kernel; i <= half_kernel; i = i + 1) {\n                if (k_idx < arrayLength(&kernel2)) {\n                    // Use acc as input to second layer\n                    let neighbor_idx = clamp(\n                        u32(clamp(y + j, 0, i32(p.height) - 1)) * p.width + \n                        u32(clamp(x + i, 0, i32(p.width) - 1)),\n                        0u,\n                        p.width * p.height - 1u\n                    );\n                    // This is simplified - in reality we'd need intermediate storage\n                    let field_val = at(&inField, x + i, y + j); // Using original for now\n                    let kernel_val = kernel2[k_idx];\n                    acc2 = acc2 + c_mul(field_val, kernel_val);\n                }\n                k_idx = k_idx + 1u;\n            }\n        }\n        \n        // Residual connection\n        acc = acc + acc2 * 0.5;\n    }\n    \n    outField[idx] = acc;\n}\n\n// Fourier Neural Operator (FNO) inspired kernel\n@compute @workgroup_size(8, 8, 1)\nfn fno_layer(@builtin(global_invocation_id) gid: vec3<u32>) {\n    // This would implement spectral convolution in Fourier space\n    // For now, it's a placeholder for the full FNO implementation\n    // The idea: \n    // 1. FFT the input\n    // 2. Multiply by learned spectral weights\n    // 3. IFFT back\n    // This learns the Green's function of the PDE!\n    \n    if (gid.x >= p.width || gid.y >= p.height) { \n        return; \n    }\n    let idx = gid.y * p.width + gid.x;\n    \n    // Placeholder: just copy through with phase shift\n    if (idx < arrayLength(&inField)) {\n        let phase_shift = vec2<f32>(0.9659, 0.2588); // cos(15°), sin(15°)\n        outField[idx] = c_mul(inField[idx], phase_shift);\n    }\n}";

// Shader: lenticularInterlace.wgsl
// Purpose: No description
export const lenticularInterlace_wgsl = "// ${IRIS_ROOT}\\frontend\\shaders\\lenticularInterlace.wgsl\r\n// Production-optimized lenticular interlacing shader for Looking Glass displays\r\n// Addresses all performance and correctness feedback\r\n\r\n// ===== Consolidated Uniform Structures =====\r\n// Packed into 256-byte blocks for GPU efficiency\r\n\r\nstruct CoreUniforms {\r\n    // Display parameters (16 floats)\r\n    screen_width: f32,\r\n    screen_height: f32,\r\n    inv_screen_width: f32,      // Precomputed 1.0 / screen_width\r\n    inv_screen_height: f32,      // Precomputed 1.0 / screen_height\r\n    \r\n    // Lens parameters (16 floats)\r\n    pitch: f32,\r\n    inv_pitch: f32,              // Precomputed 1.0 / pitch\r\n    cos_tilt: f32,               // Precomputed cos(tilt)\r\n    sin_tilt: f32,               // Precomputed sin(tilt)\r\n    center: f32,\r\n    subp: f32,\r\n    ri: f32,                     // Refractive index\r\n    bi: f32,                     // Base thickness\r\n    \r\n    // View parameters (8 floats)\r\n    num_views: f32,\r\n    inv_num_views: f32,          // Precomputed 1.0 / num_views\r\n    view_cone: f32,\r\n    lens_curve: f32,\r\n    \r\n    // Calibration basics (8 floats)\r\n    gamma: f32,\r\n    exposure: f32,\r\n    black_level: f32,\r\n    white_point: f32,\r\n    \r\n    // Flags and modes (8 floats)\r\n    flip_x: f32,\r\n    flip_y: f32,\r\n    aa_samples: f32,             // Anti-aliasing sample count\r\n    interpolation_mode: f32,     // 0: nearest, 1: linear, 2: cubic\r\n    \r\n    // Padding to 64 floats (256 bytes)\r\n    _padding: array<vec4<f32>, 2>\r\n}\r\n\r\nstruct QuiltUniforms {\r\n    // Quilt layout (16 floats)\r\n    cols: f32,\r\n    rows: f32,\r\n    inv_cols: f32,               // Precomputed 1.0 / cols\r\n    inv_rows: f32,               // Precomputed 1.0 / rows\r\n    tile_width: f32,\r\n    tile_height: f32,\r\n    inv_tile_width: f32,         // Precomputed 1.0 / tile_width\r\n    inv_tile_height: f32,        // Precomputed 1.0 / tile_height\r\n    quilt_width: f32,\r\n    quilt_height: f32,\r\n    inv_quilt_width: f32,        // Precomputed 1.0 / quilt_width\r\n    inv_quilt_height: f32,       // Precomputed 1.0 / quilt_height\r\n    total_views: f32,\r\n    edge_enhancement: f32,\r\n    temporal_blend: f32,\r\n    display_type: f32,           // 0: Standard, 1: Portrait, 2: 8K, 3: Custom\r\n}\r\n\r\nstruct AdvancedUniforms {\r\n    // Optical corrections (16 floats)\r\n    dispersion_r: f32,           // Precomputed chromatic dispersion for R\r\n    dispersion_g: f32,           // Precomputed chromatic dispersion for G\r\n    dispersion_b: f32,           // Precomputed chromatic dispersion for B\r\n    field_curvature: f32,\r\n    coma: f32,\r\n    astigmatism: f32,\r\n    vignette_strength: f32,\r\n    vignette_radius: f32,\r\n    \r\n    // Color correction (8 floats)\r\n    color_temp_r: f32,           // Precomputed color temperature scale R\r\n    color_temp_b: f32,           // Precomputed color temperature scale B\r\n    contrast: f32,\r\n    saturation: f32,\r\n    \r\n    // Quality settings (4 floats)\r\n    aa_strength: f32,\r\n    view_blend_curve: f32,\r\n    debug_mode: f32,             // 0: off, 1: lens vis, 2: view vis\r\n    quality_preset: f32,         // 0: performance, 1: balanced, 2: quality\r\n}\r\n\r\n// ===== Vertex Shader =====\r\nstruct VertexOutput {\r\n    @builtin(position) position: vec4<f32>,\r\n    @location(0) uv: vec2<f32>\r\n}\r\n\r\n@vertex\r\nfn vs_main(@builtin(vertex_index) vertex_index: u32) -> VertexOutput {\r\n    var output: VertexOutput;\r\n    // Full-screen triangle\r\n    let x = f32((vertex_index << 1u) & 2u);\r\n    let y = f32(vertex_index & 2u);\r\n    output.position = vec4<f32>(x * 2.0 - 1.0, 1.0 - y * 2.0, 0.0, 1.0);\r\n    output.uv = vec2<f32>(x, y);\r\n    return output;\r\n}\r\n\r\n// ===== Resource Bindings =====\r\n@group(0) @binding(0) var<uniform> core: CoreUniforms;\r\n@group(0) @binding(1) var<uniform> quilt: QuiltUniforms;\r\n@group(0) @binding(2) var<uniform> advanced: AdvancedUniforms;\r\n\r\n// Textures - separate group for better batching\r\n@group(1) @binding(0) var quilt_texture: texture_2d<f32>;\r\n@group(1) @binding(1) var quilt_sampler: sampler;\r\n@group(1) @binding(2) var previous_frame: texture_2d<f32>;\r\n@group(1) @binding(3) var<storage, read> trig_lut: array<vec4<f32>>; // cos,sin pairs packed\r\n\r\n// Compute shader outputs\r\n@group(2) @binding(0) var output_texture: texture_storage_2d<rgba8unorm, write>;\r\n@group(2) @binding(1) var temp_buffer: texture_storage_2d<rgba16float, read_write>;\r\n\r\n// Constants\r\nconst PI: f32 = 3.14159265359;\r\nconst INV_255: f32 = 0.00392156863;\r\nconst WORKGROUP_SIZE: u32 = 16u;\r\n\r\n// Specialization constants for build-time optimization\r\n@id(0) override ENABLE_DEBUG: bool = false;\r\n@id(1) override ENABLE_TEMPORAL: bool = true;\r\n@id(2) override MAX_AA_SAMPLES: u32 = 4u;\r\n\r\n// ===== Optimized View Calculation =====\r\nfn get_view_for_pixel_fast(screen_coord: vec2<f32>, subpixel_offset: f32) -> f32 {\r\n    // Use precomputed trig values from uniforms\r\n    let rotated_x = screen_coord.x * core.cos_tilt - screen_coord.y * core.sin_tilt + subpixel_offset;\r\n    \r\n    // Single computation with precomputed inverse\r\n    let lens_x = (rotated_x + core.center * core.screen_width) * core.inv_pitch + core.subp;\r\n    \r\n    // Get fractional position with lens curvature\r\n    var lens_frac = fract(lens_x);\r\n    \r\n    // Apply lens curvature only if significant\r\n    if (core.lens_curve > 0.001) {\r\n        let dist = abs(lens_frac - 0.5);\r\n        let curve = 1.0 + core.lens_curve * dist * dist;\r\n        lens_frac = 0.5 + (lens_frac - 0.5) * curve;\r\n    }\r\n    \r\n    // Non-linear view distribution\r\n    if (advanced.view_blend_curve != 1.0) {\r\n        lens_frac = pow(lens_frac, advanced.view_blend_curve);\r\n    }\r\n    \r\n    return lens_frac * core.num_views;\r\n}\r\n\r\n// ===== Cubic Interpolation with Bounds Checking =====\r\nfn cubic_interpolate_safe(v0: vec4<f32>, v1: vec4<f32>, v2: vec4<f32>, v3: vec4<f32>, t: f32) -> vec4<f32> {\r\n    // Catmull-Rom spline coefficients\r\n    let t2 = t * t;\r\n    let t3 = t2 * t;\r\n    \r\n    return v1 + 0.5 * t * (v2 - v0 + \r\n           t * (2.0 * v0 - 5.0 * v1 + 4.0 * v2 - v3 + \r\n           t * (3.0 * (v1 - v2) + v3 - v0)));\r\n}\r\n\r\n// ===== Optimized Quilt Sampling =====\r\nfn sample_quilt_view_fast(view_index: f32, uv: vec2<f32>) -> vec4<f32> {\r\n    // Wrap view index with single modulo\r\n    let wrapped_view = view_index - floor(view_index * quilt.inv_cols) * quilt.total_views;\r\n    \r\n    // Tile calculation with precomputed inverses\r\n    let tile_idx = floor(wrapped_view);\r\n    let tile_x = tile_idx - floor(tile_idx * quilt.inv_cols) * quilt.cols;\r\n    let tile_y = floor(tile_idx * quilt.inv_cols);\r\n    \r\n    // UV calculation with precomputed scales\r\n    var tile_uv = vec2<f32>(\r\n        (tile_x + uv.x) * quilt.inv_cols,\r\n        (tile_y + uv.y) * quilt.inv_rows\r\n    );\r\n    \r\n    // Apply flipping\r\n    if (core.flip_x > 0.5) { tile_uv.x = 1.0 - tile_uv.x; }\r\n    if (core.flip_y > 0.5) { tile_uv.y = 1.0 - tile_uv.y; }\r\n    \r\n    return textureSampleLevel(quilt_texture, quilt_sampler, tile_uv, 0.0);\r\n}\r\n\r\n// ===== Optimized Multi-View Sampling =====\r\nfn sample_views_interpolated(view_index: f32, uv: vec2<f32>) -> vec4<f32> {\r\n    let mode = u32(core.interpolation_mode);\r\n    \r\n    if (mode == 0u) { // Nearest\r\n        return sample_quilt_view_fast(round(view_index), uv);\r\n    }\r\n    \r\n    let base_view = floor(view_index);\r\n    let frac = view_index - base_view;\r\n    \r\n    if (mode == 1u) { // Linear\r\n        let v0 = sample_quilt_view_fast(base_view, uv);\r\n        let v1 = sample_quilt_view_fast(base_view + 1.0, uv);\r\n        return mix(v0, v1, frac); // True linear, no smoothstep\r\n    }\r\n    \r\n    // Cubic with proper bounds handling\r\n    let total = quilt.total_views;\r\n    let vm1 = select(base_view - 1.0, base_view - 1.0 + total, base_view > 0.0);\r\n    let vp1 = select(base_view + 1.0, base_view + 1.0 - total, base_view + 1.0 < total);\r\n    let vp2 = select(base_view + 2.0, base_view + 2.0 - total, base_view + 2.0 < total);\r\n    \r\n    let v0 = sample_quilt_view_fast(vm1, uv);\r\n    let v1 = sample_quilt_view_fast(base_view, uv);\r\n    let v2 = sample_quilt_view_fast(vp1, uv);\r\n    let v3 = sample_quilt_view_fast(vp2, uv);\r\n    \r\n    return cubic_interpolate_safe(v0, v1, v2, v3, frac);\r\n}\r\n\r\n// ===== Efficient Subpixel Sampling =====\r\nfn sample_subpixel_optimized(screen_coord: vec2<f32>, uv: vec2<f32>) -> vec4<f32> {\r\n    let aa_samples = min(u32(core.aa_samples), MAX_AA_SAMPLES);\r\n    \r\n    if (aa_samples <= 1u) {\r\n        // No AA - single sample\r\n        let view = get_view_for_pixel_fast(screen_coord, 0.0);\r\n        return sample_views_interpolated(view, uv);\r\n    }\r\n    \r\n    // Precomputed chromatic offsets\r\n    const subpixel_width = 1.0 / 3.0;\r\n    let r_offset = -subpixel_width + advanced.dispersion_r;\r\n    let b_offset = subpixel_width + advanced.dispersion_b;\r\n    \r\n    // AA sample accumulation\r\n    var accum_r = 0.0;\r\n    var accum_g = 0.0;\r\n    var accum_b = 0.0;\r\n    \r\n    let aa_step = advanced.aa_strength / f32(aa_samples);\r\n    for (var i = 0u; i < aa_samples; i++) {\r\n        let offset = (f32(i) - f32(aa_samples - 1u) * 0.5) * aa_step;\r\n        \r\n        // Sample each subpixel\r\n        let view_r = get_view_for_pixel_fast(screen_coord, r_offset + offset);\r\n        let view_g = get_view_for_pixel_fast(screen_coord, offset);\r\n        let view_b = get_view_for_pixel_fast(screen_coord, b_offset + offset);\r\n        \r\n        let sample_r = sample_views_interpolated(view_r, uv);\r\n        let sample_g = sample_views_interpolated(view_g, uv);\r\n        let sample_b = sample_views_interpolated(view_b, uv);\r\n        \r\n        accum_r += sample_r.r;\r\n        accum_g += sample_g.g;\r\n        accum_b += sample_b.b;\r\n    }\r\n    \r\n    let inv_samples = 1.0 / f32(aa_samples);\r\n    return vec4<f32>(accum_r * inv_samples, accum_g * inv_samples, accum_b * inv_samples, 1.0);\r\n}\r\n\r\n// ===== Fast Calibration =====\r\nfn apply_calibration_fast(color: vec3<f32>) -> vec3<f32> {\r\n    // Black level and white point with single division\r\n    let range = core.white_point - core.black_level;\r\n    var calibrated = saturate((color - core.black_level) / range);\r\n    \r\n    // Combined gamma and exposure\r\n    calibrated = pow(calibrated * core.exposure, vec3<f32>(1.0 / core.gamma));\r\n    \r\n    // Pre-computed color temperature\r\n    calibrated.r *= advanced.color_temp_r;\r\n    calibrated.b *= advanced.color_temp_b;\r\n    \r\n    // Simple contrast without branches\r\n    calibrated = mix(vec3<f32>(0.5), calibrated, advanced.contrast);\r\n    \r\n    return calibrated;\r\n}\r\n\r\n// ===== Main Fragment Shader =====\r\n@fragment\r\nfn fs_main(input: VertexOutput) -> @location(0) vec4<f32> {\r\n    let screen_coord = input.uv * vec2<f32>(core.screen_width, core.screen_height);\r\n    \r\n    // Main sampling\r\n    var color = sample_subpixel_optimized(screen_coord, input.uv);\r\n    \r\n    // Temporal blending only if enabled\r\n    if (ENABLE_TEMPORAL && quilt.temporal_blend > 0.0) {\r\n        let prev = textureSampleLevel(previous_frame, quilt_sampler, input.uv, 0.0);\r\n        color = mix(color, prev, quilt.temporal_blend);\r\n    }\r\n    \r\n    // Calibration\r\n    let calibrated = apply_calibration_fast(color.rgb);\r\n    color.r = calibrated.r;\r\n    color.g = calibrated.g;\r\n    color.b = calibrated.b;\r\n    \r\n    // Debug visualization only if enabled\r\n    if (ENABLE_DEBUG && advanced.debug_mode > 0.0) {\r\n        let mixed = mix(color.rgb, debug_visualization(screen_coord, input.uv), 0.5);\r\n        color.r = mixed.r;\r\n        color.g = mixed.g;\r\n        color.b = mixed.b;\r\n    }\r\n    \r\n    return vec4<f32>(saturate(color.rgb), 1.0);\r\n}\r\n\r\n// ===== Compute Shader with TextureLoad =====\r\n@compute @workgroup_size(WORKGROUP_SIZE, WORKGROUP_SIZE, 1)\r\nfn cs_main(@builtin(global_invocation_id) global_id: vec3<u32>) {\r\n    let coord = global_id.xy;\r\n    let dims = vec2<u32>(u32(core.screen_width), u32(core.screen_height));\r\n    \r\n    if (any(coord >= dims)) {\r\n        return;\r\n    }\r\n    \r\n    let uv = vec2<f32>(coord) * vec2<f32>(core.inv_screen_width, core.inv_screen_height);\r\n    let screen_coord = vec2<f32>(coord);\r\n    \r\n    // Direct sampling without sampler overhead\r\n    var color = sample_subpixel_compute(coord, screen_coord, uv);\r\n    \r\n    // Apply calibration\r\n    let calibrated = apply_calibration_fast(color.rgb);\r\n    color.r = calibrated.r;\r\n    color.g = calibrated.g;\r\n    color.b = calibrated.b;\r\n    \r\n    // Write to output\r\n    textureStore(output_texture, coord, vec4<f32>(saturate(color.rgb), 1.0));\r\n}\r\n\r\n// Compute-specific sampling using textureLoad\r\nfn sample_subpixel_compute(pixel_coord: vec2<u32>, screen_coord: vec2<f32>, uv: vec2<f32>) -> vec4<f32> {\r\n    // Similar to sample_subpixel_optimized but uses textureLoad\r\n    let view = get_view_for_pixel_fast(screen_coord, 0.0);\r\n    \r\n    // Calculate quilt coordinates\r\n    let view_idx = u32(view);\r\n    let tile_x = view_idx % u32(quilt.cols);\r\n    let tile_y = view_idx / u32(quilt.cols);\r\n    \r\n    // Direct texel fetch\r\n    let quilt_coord = vec2<u32>(\r\n        tile_x * u32(quilt.tile_width) + u32(uv.x * quilt.tile_width),\r\n        tile_y * u32(quilt.tile_height) + u32(uv.y * quilt.tile_height)\r\n    );\r\n    \r\n    return textureLoad(quilt_texture, quilt_coord, 0);\r\n}\r\n\r\n// ===== Edge Enhancement on Final Output =====\r\n@compute @workgroup_size(WORKGROUP_SIZE, WORKGROUP_SIZE, 1)\r\nfn cs_edge_enhance(@builtin(global_invocation_id) global_id: vec3<u32>) {\r\n    let coord = vec2<i32>(global_id.xy);\r\n    let dims = vec2<i32>(i32(core.screen_width), i32(core.screen_height));\r\n    \r\n    if (any(coord >= dims)) {\r\n        return;\r\n    }\r\n    \r\n    // Load from temp buffer\r\n    let center = textureLoad(temp_buffer, coord).rgb;\r\n    \r\n    if (quilt.edge_enhancement > 0.0) {\r\n        // 3x3 edge detection on final image\r\n        var laplacian = vec3<f32>(0.0);\r\n        for (var dy = -1; dy <= 1; dy++) {\r\n            for (var dx = -1; dx <= 1; dx++) {\r\n                let sample_coord = clamp(coord + vec2<i32>(dx, dy), vec2<i32>(0), dims - 1);\r\n                let sample = textureLoad(temp_buffer, sample_coord).rgb;\r\n                \r\n                if (dx == 0 && dy == 0) {\r\n                    laplacian += sample * 8.0;\r\n                } else {\r\n                    laplacian -= sample;\r\n                }\r\n            }\r\n        }\r\n        \r\n        let enhanced = center + laplacian * quilt.edge_enhancement * 0.125;\r\n        textureStore(output_texture, coord, vec4<f32>(saturate(enhanced), 1.0));\r\n    } else {\r\n        textureStore(output_texture, coord, vec4<f32>(center, 1.0));\r\n    }\r\n}\r\n\r\n// ===== Debug Visualization (only compiled if ENABLE_DEBUG) =====\r\nfn debug_visualization(screen_coord: vec2<f32>, uv: vec2<f32>) -> vec3<f32> {\r\n    if (!ENABLE_DEBUG) { return vec3<f32>(0.0); }\r\n    \r\n    let mode = u32(advanced.debug_mode);\r\n    \r\n    if (mode == 1u) { // Lens boundaries\r\n        let rotated_x = screen_coord.x * core.cos_tilt - screen_coord.y * core.sin_tilt;\r\n        let lens_x = rotated_x * core.inv_pitch;\r\n        let lens_frac = fract(lens_x);\r\n        \r\n        if (lens_frac < 0.02 || lens_frac > 0.98) {\r\n            return vec3<f32>(1.0, 0.0, 0.0);\r\n        }\r\n    } else if (mode == 2u) { // View distribution\r\n        let view = get_view_for_pixel_fast(screen_coord, 0.0);\r\n        let hue = view * core.inv_num_views;\r\n        return hsv_to_rgb(vec3<f32>(hue, 0.8, 0.6));\r\n    }\r\n    \r\n    return vec3<f32>(0.0);\r\n}\r\n\r\n// Simple HSV to RGB\r\nfn hsv_to_rgb(hsv: vec3<f32>) -> vec3<f32> {\r\n    let h = hsv.x * 6.0;\r\n    let s = hsv.y;\r\n    let v = hsv.z;\r\n    let i = floor(h);\r\n    let f = h - i;\r\n    let p = v * (1.0 - s);\r\n    let q = v * (1.0 - s * f);\r\n    let t = v * (1.0 - s * (1.0 - f));\r\n    \r\n    let idx = u32(i) % 6u;\r\n    if (idx == 0u) { return vec3<f32>(v, t, p); }\r\n    if (idx == 1u) { return vec3<f32>(q, v, p); }\r\n    if (idx == 2u) { return vec3<f32>(p, v, t); }\r\n    if (idx == 3u) { return vec3<f32>(p, q, v); }\r\n    if (idx == 4u) { return vec3<f32>(t, p, v); }\r\n    return vec3<f32>(v, p, q);\r\n}\r\n\r\n// ===== Portrait Mode Entry Point =====\r\n@fragment\r\nfn fs_portrait(input: VertexOutput) -> @location(0) vec4<f32> {\r\n    // Rotate coordinates for portrait orientation\r\n    let screen_coord = vec2<f32>(\r\n        input.uv.y * core.screen_height,\r\n        (1.0 - input.uv.x) * core.screen_width\r\n    );\r\n    let rotated_uv = vec2<f32>(input.uv.y, 1.0 - input.uv.x);\r\n    \r\n    var color = sample_subpixel_optimized(screen_coord, rotated_uv);\r\n    let calibrated = apply_calibration_fast(color.rgb);\r\n    color.r = calibrated.r;\r\n    color.g = calibrated.g;\r\n    color.b = calibrated.b;\r\n    \r\n    return vec4<f32>(saturate(color.rgb), 1.0);\r\n}\r\n";

// Shader: lightFieldComposer.wgsl
// Purpose: No description
export const lightFieldComposer_wgsl = "/* \n LightFieldComposer.wgsl\n\n This WebGPU shader composes multiple view images into various output formats for light field displays.\n It assembles outputs from multiDepthWaveSynth (base images at multiple depths/views) and phaseOcclusion (occlusion masks)\n into either a quilt (tiled multi-view image), stacked depth layers, or a stereo pair.\n\n Modes:\n    0 = Quilt (tile images in a grid),\n    1 = Depth Layers (all views in one row or column),\n    2 = Stereo (two views side-by-side).\n\n Inputs (bound to group(0)):\n    binding(0) : baseTex (texture_2d_array<f32>) - Base color/intensity textures for each view (array layer = view index).\n    binding(1) : occTex (texture_2d_array<f32>) - Occlusion mask textures for each view (same layering as baseTex).\n    binding(2) : outputTex (texture_storage_2d<rgba8unorm, write>) - Output texture to write the composed image into.\n    binding(3) : Uniforms (Params) - see struct Params below.\n\n The shader expects each view image to be of size (width x height) given in Params.\n For quilt mode, tileCountX and tileCountY specify the grid dimensions.\n For depth layers mode, tileCountX or tileCountY can be set such that all views line up in one row or column.\n Stereo mode uses the first and last view as left and right images (assuming views are sorted left-to-right).\n\n Workgroup: 8x8 threads. The compute shader will cover the entire output image by appropriately sized dispatch.\n */\n\nstruct Params {\n    width: u32,         // Width of each single view image\n    height: u32,        // Height of each single view image\n    viewCount: u32,     // Total number of views (layers in the input textures)\n    tileCountX: u32,    // Number of tiles horizontally (for quilt or layer arrangement)\n    tileCountY: u32,    // Number of tiles vertically\n    mode: u32,          // Output mode (0=quilt, 1=depth layers, 2=stereo)\n}\n\n@group(0) @binding(0) var baseTex: texture_2d_array<f32>;\n@group(0) @binding(1) var occTex: texture_2d_array<f32>;\n@group(0) @binding(2) var outputTex: texture_storage_2d<rgba8unorm, write>;\n@group(0) @binding(3) var<uniform> params: Params;\n\n@compute @workgroup_size(8, 8, 1)\nfn main(@builtin(global_invocation_id) GlobalId: vec3<u32>) {\n    let out_x: u32 = GlobalId.x;\n    let out_y: u32 = GlobalId.y;\n    // Calculate total output dimensions from tile counts\n    let totalWidth: u32 = params.width * params.tileCountX;\n    let totalHeight: u32 = params.height * params.tileCountY;\n    // Ensure we don't write outside the intended output (in case dispatch is larger)\n    if (out_x >= totalWidth || out_y >= totalHeight) {\n        return;\n    }\n    var outColor: vec4<f32>;\n    if (params.mode == 2u) {\n        // Stereo mode: left view on left half, right view on right half of output\n        var viewIndex: u32;\n        var local_x: u32;\n        if (out_x < params.width) {\n            // Left half of output -> left-eye view (use first view, index 0)\n            viewIndex = 0u;\n            local_x = out_x;\n        } else {\n            // Right half -> right-eye view (use last view, index = viewCount-1)\n            viewIndex = max(params.viewCount, 1u) - 1u;\n            local_x = out_x - params.width;\n        }\n        let local_y: u32 = out_y;\n        if (viewIndex < params.viewCount) {\n            // Sample base color and occlusion\n            let coords: vec2<i32> = vec2<i32>(i32(local_x), i32(local_y));\n            let baseColor: vec4<f32> = textureLoad(baseTex, coords, i32(viewIndex), 0);\n            let occVal: vec4<f32> = textureLoad(occTex, coords, i32(viewIndex), 0);\n            let occ: f32 = occVal.r; // assume occlusion is stored in red channel (grayscale mask)\n            outColor = vec4<f32>(baseColor.rgb * occ, 1.0);\n        } else {\n            // In case viewIndex is out of range (should not happen here)\n            outColor = vec4<f32>(0.0, 0.0, 0.0, 1.0);\n        }\n    } else {\n        // Quilt or Depth-layers mode: arrange views in a grid defined by tileCountX x tileCountY\n        let tile_x: u32 = out_x / params.width;\n        let tile_y: u32 = out_y / params.height;\n        let viewIndex: u32 = tile_y * params.tileCountX + tile_x;\n        let local_x: u32 = out_x - tile_x * params.width;\n        let local_y: u32 = out_y - tile_y * params.height;\n        if (viewIndex < params.viewCount) {\n            let coords: vec2<i32> = vec2<i32>(i32(local_x), i32(local_y));\n            let baseColor: vec4<f32> = textureLoad(baseTex, coords, i32(viewIndex), 0);\n            let occVal: vec4<f32> = textureLoad(occTex, coords, i32(viewIndex), 0);\n            let occ: f32 = occVal.r;\n            outColor = vec4<f32>(baseColor.rgb * occ, 1.0);\n        } else {\n            // If there are more tile slots than actual views, output black for extra slots\n            outColor = vec4<f32>(0.0, 0.0, 0.0, 1.0);\n        }\n    }\n    // Write the composed color to the output texture\n    textureStore(outputTex, vec2<i32>(i32(out_x), i32(out_y)), outColor);\n}\n";

// Shader: multiDepthWaveSynth.wgsl
// Purpose: No description
export const multiDepthWaveSynth_wgsl = "// multiDepthWaveSynth.wgsl - Compute shader for multi-depth wavefield synthesis\nconst MAX_LAYERS: u32 = 8;  // maximum layers supported\n@group(0) @binding(0) var<storage, read> inputWave: array<vec2<f32>>;    // Input complex wave (after occlusion)\n@group(0) @binding(1) var<storage, read_write> outputWave: array<vec2<f32>>; // Output combined wave\nstruct ParamsData {\n    width: u32,\n    height: u32,\n    numLayers: u32,\n    _pad: u32,                       // padding (unused)\n    depths: array<f32, MAX_LAYERS>,  // Depth values for each layer (e.g., in meters or normalized units)\n    emotion: f32,    // User emotional intensity (0 = calm, 1 = excited)\n    proximity: f32,  // User proximity factor (0 = far, 1 = very close) - can be used to adjust focus dynamically\n    gazeX: f32,      // Horizontal gaze direction factor (relative to center)\n    gazeY: f32,      // Vertical gaze direction factor \n    personaPhaseSeed: f32, // Seed derived from persona embedding for random phase offsets\n    // (padding to 16-byte alignment, if needed)\n}\n\n@group(0) @binding(2) var<storage, read> params: ParamsData;\n\n\nfn clamp_index_dyn(i: u32, len: u32) -> u32 {\n    return select(i, len - 1u, i >= len);\n}\n\nfn rand01(x: f32) -> f32 {\n    // Simple deterministic hash to get a pseudorandom 0-1 value from input x\n    return fract(sin(x) * 43758.5453);\n}\n\n@compute @workgroup_size(16, 16)\nfn main(@builtin(global_invocation_id) gid: vec3<u32>) {\n    let w = params.width;\n    let h = params.height;\n    let x = gid.x;\n    let y = gid.y;\n    if (x >= w || y >= h) {\n        return;\n    }\n    let idx = y * w + x;\n    // Center coordinates for phase calculations\n    let cx = f32(w) * 0.5;\n    let cy = f32(h) * 0.5;\n    let xf = f32(x) - cx;\n    let yf = f32(y) - cy;\n    // Read input wave at (x,y) with bounds checking\n    let clamped_idx = clamp_index_dyn(idx, arrayLength(&inputWave));\n    let inRe = inputWave[clamped_idx].x;\n    let inIm = inputWave[clamped_idx].y;\n    // Initialize output accumulation\n    var accRe: f32 = 0.0;\n    var accIm: f32 = 0.0;\n    // Calculate viewing angle phase tilt based on gaze\n    let gx = params.gazeX;\n    let gy = params.gazeY;\n    // Introduce a linear phase gradient for parallax: one full 2pi phase shift across the entire width for gaze factor = 1\n    let tiltPhase = (gx * xf + gy * yf) * (2.0 * 3.141592653589793 / f32(w));\n    // Coherence factor based on emotion\n    let coherence = max(0.0, 1.0 - params.emotion);\n    // Loop over each depth layer\n    for (var i: u32 = 0u; i < params.numLayers; i = i + 1u) {\n        if (i >= params.numLayers) { break; }\n        // Access depths array with bounds checking (static array, so clamp to MAX_LAYERS)\n        let depth_idx = clamp_index_dyn(i, MAX_LAYERS);\n        let z = params.depths[depth_idx];\n        // Compute quadratic phase for focusing at depth z:\n        // Using Fresnel approximation: phase_curvature = (pi/(lambda*z)) * (x^2 + y^2). Here we pick lambda ~ 0.000633 (633nm) in simulation.\n        const lambda = 0.000633;\n        let invZ = 1.0 / (z + 1e-6);\n        let phaseCurv = 3.1415927 * invZ / lambda * (xf*xf + yf*yf);\n        // Compute a random phase offset for this layer (for decoherence) based on persona seed and layer index\n        let randPhase = rand01(params.personaPhaseSeed + f32(i) * 13.37) * 2.0 * 3.1415927;\n        let offsetPhase = (1.0 - coherence) * randPhase;\n        // Total phase for this layer = focus phase + viewpoint tilt + offset\n        let totalPhase = phaseCurv + tiltPhase + offsetPhase;\n        let cosP = cos(totalPhase);\n        let sinP = sin(totalPhase);\n        // Rotate input wave by totalPhase and accumulate\n        let contribRe = inRe * cosP - inIm * sinP;\n        let contribIm = inRe * sinP + inIm * cosP;\n        accRe = accRe + contribRe;\n        accIm = accIm + contribIm;\n    }\n    // Write accumulated wave to output with bounds checking\n    outputWave[clamp_index_dyn(idx, arrayLength(&outputWave))] = vec2<f32>(accRe, accIm);\n}\n";

// Shader: multiViewSynthesis.wgsl
// Purpose: No description
export const multiViewSynthesis_wgsl = "// ${IRIS_ROOT}\\frontend\\shaders\\multiViewSynthesis.wgsl\r\n// Production-ready multi-view synthesis for holographic quilt generation\r\n// Optimized for real-time performance with proper phase-based view synthesis\r\n\r\nstruct ViewParams {\r\n    num_views: u32,              // Total number of views\r\n    current_view: u32,           // Current view being rendered (single-view mode)\r\n    view_cone: f32,              // Total viewing angle in radians\r\n    convergence_distance: f32,   // Distance to convergence plane in mm\r\n    eye_separation: f32,         // Inter-ocular distance in mm\r\n    tile_width: u32,             // Width of each view tile\r\n    tile_height: u32,            // Height of each view tile\r\n    view_blend_width: f32,       // Width of blending region between views\r\n    // Precomputed values for optimization\r\n    inv_tile_width: f32,         // 1.0 / tile_width\r\n    inv_tile_height: f32,        // 1.0 / tile_height\r\n    inv_num_views: f32,          // 1.0 / (num_views - 1)\r\n    pixel_size: f32,             // Physical pixel size in mm\r\n    // Advanced parameters\r\n    aberration_strength: f32,     // Chromatic aberration correction\r\n    depth_of_field: f32,         // DoF blur strength\r\n    focal_distance: f32,         // Focus distance for DoF\r\n    mapping_mode: u32,           // 0: standard quilt, 1: single view, 2: debug\r\n}\r\n\r\nstruct QuiltParams {\r\n    cols: u32,                   // Number of columns in quilt\r\n    rows: u32,                   // Number of rows in quilt\r\n    quilt_width: u32,            // Total quilt texture width\r\n    quilt_height: u32,           // Total quilt texture height\r\n    // Precomputed optimization values\r\n    inv_cols: f32,               // 1.0 / cols\r\n    inv_rows: f32,               // 1.0 / rows\r\n    aspect_ratio: f32,           // Display aspect ratio\r\n    debug_mode: u32,             // 0: normal, 1: tile colors, 2: view angles\r\n}\r\n\r\nstruct RenderingParams {\r\n    wavelength_r: f32,           // Red wavelength in mm (0.000633)\r\n    wavelength_g: f32,           // Green wavelength in mm (0.000532)\r\n    wavelength_b: f32,           // Blue wavelength in mm (0.000465)\r\n    gamma: f32,                  // Gamma correction value (2.2)\r\n    exposure: f32,               // Exposure adjustment\r\n    contrast: f32,               // Contrast enhancement\r\n    saturation: f32,             // Color saturation\r\n    tone_mapping_mode: u32,      // 0: linear, 1: reinhard, 2: ACES\r\n}\r\n\r\n// Primary bindings - propagated wavefield and output\r\n@group(0) @binding(0) var wavefield_r: texture_2d<f32>;        // Complex field R (rg32float)\r\n@group(0) @binding(1) var wavefield_g: texture_2d<f32>;        // Complex field G (rg32float)\r\n@group(0) @binding(2) var wavefield_b: texture_2d<f32>;        // Complex field B (rg32float)\r\n@group(0) @binding(3) var quilt_output: texture_storage_2d<rgba8unorm, write>;\r\n@group(0) @binding(4) var hdr_output: texture_storage_2d<rgba16float, write>; // Optional HDR\r\n\r\n// Uniforms\r\n@group(1) @binding(0) var<uniform> view_params: ViewParams;\r\n@group(1) @binding(1) var<uniform> quilt_params: QuiltParams;\r\n@group(1) @binding(2) var<uniform> render_params: RenderingParams;\r\n\r\n// Additional resources\r\n@group(2) @binding(0) var depth_texture: texture_2d<f32>;      // Scene depth\r\n@group(2) @binding(1) var field_sampler: sampler;              // Linear sampler\r\n@group(2) @binding(2) var<storage, read> lut_phase_tilt: array<vec4<f32>>; // Precomputed phase tilts packed\r\n\r\n// Constants\r\nconst PI: f32 = 3.14159265359;\r\nconst TWO_PI: f32 = 6.28318530718;\r\nconst INV_PI: f32 = 0.31830988618;\r\nconst WORKGROUP_SIZE: u32 = 16u;\r\nconst TILE_BORDER: u32 = 2u; // For shared memory padding\r\nconst SHARED_SIZE: u32 = 400u; // (16+4)^2 = 400\r\n\r\n// Shared memory for wavefield caching\r\nvar<workgroup> shared_field_r: array<vec4<f32>, SHARED_SIZE>;\r\nvar<workgroup> shared_field_g: array<vec4<f32>, SHARED_SIZE>;\r\nvar<workgroup> shared_field_b: array<vec4<f32>, SHARED_SIZE>;\r\n\r\n// Complex operations\r\n\r\nfn clamp_index_dyn(i: u32, len: u32) -> u32 {\r\n    return select(i, len - 1u, i >= len);\r\n}\r\n\r\nfn complex_multiply(a: vec2<f32>, b: vec2<f32>) -> vec2<f32> {\r\n    return vec2<f32>(\r\n        a.x * b.x - a.y * b.y,\r\n        a.x * b.y + a.y * b.x\r\n    );\r\n}\r\n\r\nfn complex_magnitude_squared(c: vec2<f32>) -> f32 {\r\n    return c.x * c.x + c.y * c.y;\r\n}\r\n\r\nfn complex_exp(phase: f32) -> vec2<f32> {\r\n    return vec2<f32>(cos(phase), sin(phase));\r\n}\r\n\r\n// Optimized coordinate calculations using precomputed reciprocals\r\nfn get_tile_indices(coord: vec2<u32>) -> vec2<u32> {\r\n    // Use multiplication instead of division\r\n    let tile_x = u32(f32(coord.x) * view_params.inv_tile_width);\r\n    let tile_y = u32(f32(coord.y) * view_params.inv_tile_height);\r\n    return vec2<u32>(tile_x, tile_y);\r\n}\r\n\r\nfn get_local_coords(coord: vec2<u32>) -> vec2<u32> {\r\n    // Optimized modulus using multiplication\r\n    let tile_indices = get_tile_indices(coord);\r\n    let local_x = coord.x - tile_indices.x * view_params.tile_width;\r\n    let local_y = coord.y - tile_indices.y * view_params.tile_height;\r\n    return vec2<u32>(local_x, local_y);\r\n}\r\n\r\n// Calculate view index based on mapping mode\r\nfn calculate_view_index(coord: vec2<u32>) -> f32 {\r\n    switch (view_params.mapping_mode) {\r\n        case 0u: { // Standard quilt mapping\r\n            let tile_indices = get_tile_indices(coord);\r\n            let tile_idx = tile_indices.y * quilt_params.cols + tile_indices.x;\r\n            return f32(min(tile_idx, view_params.num_views - 1u));\r\n        }\r\n        case 1u: { // Single view preview\r\n            return f32(view_params.current_view);\r\n        }\r\n        case 2u: { // Debug: continuous view across width\r\n            return f32(coord.x) * f32(view_params.num_views) / f32(quilt_params.quilt_width);\r\n        }\r\n        default: {\r\n            return 0.0;\r\n        }\r\n    }\r\n}\r\n\r\n// Load wavefield into shared memory with borders\r\nfn load_shared_wavefield(local_id: vec3<u32>, workgroup_id: vec3<u32>) {\r\n    let shared_size = WORKGROUP_SIZE + 2u * TILE_BORDER;\r\n    let threads_per_workgroup = WORKGROUP_SIZE * WORKGROUP_SIZE;\r\n    let values_per_thread = (shared_size * shared_size + threads_per_workgroup - 1u) / threads_per_workgroup;\r\n    \r\n    let thread_idx = local_id.y * WORKGROUP_SIZE + local_id.x;\r\n    let workgroup_offset = vec2<i32>(workgroup_id.xy) * i32(WORKGROUP_SIZE) - i32(TILE_BORDER);\r\n    \r\n    for (var i = 0u; i < values_per_thread; i++) {\r\n        let shared_idx = thread_idx * values_per_thread + i;\r\n        if (shared_idx < shared_size * shared_size && shared_idx < SHARED_SIZE) {\r\n            let shared_x = shared_idx % shared_size;\r\n            let shared_y = shared_idx / shared_size;\r\n            let global_coord = workgroup_offset + vec2<i32>(i32(shared_x), i32(shared_y));\r\n            \r\n            // Clamp to texture bounds\r\n            let tex_dims = textureDimensions(wavefield_g, 0);\r\n            let clamped_coord = clamp(global_coord, vec2<i32>(0), vec2<i32>(tex_dims) - 1);\r\n            \r\n            // Load all three channels with bounds checking\r\n            let clamped_shared_idx = clamp_index_dyn(shared_idx, SHARED_SIZE);\r\n            shared_field_r[clamped_shared_idx] = textureLoad(wavefield_r, clamped_coord, 0);\r\n            shared_field_g[clamped_shared_idx] = textureLoad(wavefield_g, clamped_coord, 0);\r\n            shared_field_b[clamped_shared_idx] = textureLoad(wavefield_b, clamped_coord, 0);\r\n        }\r\n    }\r\n    \r\n    workgroupBarrier();\r\n}\r\n\r\n// Core view synthesis function with phase-based transformation\r\nfn blend_views(uv: vec2<f32>, view_index: f32) -> vec3<f32> {\r\n    // Calculate normalized view position\r\n    let view_normalized = view_index * view_params.inv_num_views;\r\n    let view_offset = view_normalized - 0.5;\r\n    let view_angle = view_offset * view_params.view_cone;\r\n    \r\n    // Phase tilt for angular view transformation\r\n    let k = TWO_PI / render_params.wavelength_g; // Use green as reference\r\n    let phase_tilt_x = k * sin(view_angle);\r\n    const phase_tilt_y = 0.0; // No vertical tilt for horizontal parallax only\r\n    \r\n    // Physical coordinate offset for parallax\r\n    let parallax_offset = tan(view_angle) * view_params.convergence_distance / view_params.pixel_size;\r\n    \r\n    // Sample depth for depth-dependent effects\r\n    let depth = textureSampleLevel(depth_texture, field_sampler, uv, 0.0).r;\r\n    let depth_factor = (depth - 0.5) * 2.0; // Normalize to [-1, 1]\r\n    \r\n    // Apply chromatic aberration per channel\r\n    let aberration_r = view_offset * view_params.aberration_strength * \r\n                      (render_params.wavelength_r / render_params.wavelength_g - 1.0);\r\n    let aberration_b = view_offset * view_params.aberration_strength * \r\n                      (render_params.wavelength_b / render_params.wavelength_g - 1.0);\r\n    \r\n    // Sample positions with parallax and aberration\r\n    let sample_uv_r = uv + vec2<f32>(parallax_offset + aberration_r, 0.0) * depth_factor;\r\n    let sample_uv_g = uv + vec2<f32>(parallax_offset, 0.0) * depth_factor;\r\n    let sample_uv_b = uv + vec2<f32>(parallax_offset + aberration_b, 0.0) * depth_factor;\r\n    \r\n    // Sample complex fields\r\n    var field_r = textureSampleLevel(wavefield_r, field_sampler, sample_uv_r, 0.0).xy;\r\n    var field_g = textureSampleLevel(wavefield_g, field_sampler, sample_uv_g, 0.0).xy;\r\n    var field_b = textureSampleLevel(wavefield_b, field_sampler, sample_uv_b, 0.0).xy;\r\n    \r\n    // Apply phase tilts for view angle\r\n    let phase_shift = vec2<f32>(phase_tilt_x * uv.x * f32(view_params.tile_width), \r\n                                phase_tilt_y * uv.y * f32(view_params.tile_height));\r\n    let phase_factor = complex_exp(phase_shift.x + phase_shift.y);\r\n    \r\n    field_r = complex_multiply(field_r, phase_factor);\r\n    field_g = complex_multiply(field_g, phase_factor);\r\n    field_b = complex_multiply(field_b, phase_factor);\r\n    \r\n    // Apply depth of field if enabled\r\n    if (view_params.depth_of_field > 0.0) {\r\n        let defocus = abs(depth - view_params.focal_distance) * view_params.depth_of_field;\r\n        if (defocus > 0.001) {\r\n            // Simple defocus by phase randomization\r\n            let defocus_phase = defocus * PI;\r\n            let defocus_kernel = complex_exp(-defocus_phase);\r\n            field_r = complex_multiply(field_r, defocus_kernel);\r\n            field_g = complex_multiply(field_g, defocus_kernel);\r\n            field_b = complex_multiply(field_b, defocus_kernel);\r\n        }\r\n    }\r\n    \r\n    // Convert complex field to intensity\r\n    let intensity_r = sqrt(complex_magnitude_squared(field_r));\r\n    let intensity_g = sqrt(complex_magnitude_squared(field_g));\r\n    let intensity_b = sqrt(complex_magnitude_squared(field_b));\r\n    \r\n    return vec3<f32>(intensity_r, intensity_g, intensity_b);\r\n}\r\n\r\n// Post-processing pipeline\r\nfn apply_post_processing(color: vec3<f32>) -> vec3<f32> {\r\n    var processed = color;\r\n    \r\n    // Exposure adjustment\r\n    processed *= render_params.exposure;\r\n    \r\n    // Tone mapping\r\n    switch (render_params.tone_mapping_mode) {\r\n        case 1u: { // Reinhard\r\n            processed = processed / (processed + vec3<f32>(1.0));\r\n        }\r\n        case 2u: { // ACES approximation\r\n            const a = 2.51;\r\n            const b = 0.03;\r\n            const c = 2.43;\r\n            const d = 0.59;\r\n            const e = 0.14;\r\n            processed = saturate((processed * (a * processed + b)) / \r\n                                (processed * (c * processed + d) + e));\r\n        }\r\n        default: {} // Linear (no tone mapping)\r\n    }\r\n    \r\n    // Contrast adjustment using S-curve\r\n    let midpoint = vec3<f32>(0.5);\r\n    processed = mix(midpoint, processed, render_params.contrast);\r\n    \r\n    // Saturation adjustment\r\n    let luminance = dot(processed, vec3<f32>(0.2126, 0.7152, 0.0722));\r\n    processed = mix(vec3<f32>(luminance), processed, render_params.saturation);\r\n    \r\n    // Gamma correction\r\n    processed = pow(max(processed, vec3<f32>(0.0)), vec3<f32>(1.0 / render_params.gamma));\r\n    \r\n    return saturate(processed);\r\n}\r\n\r\n// Debug visualization modes\r\nfn debug_color(view_index: f32, coord: vec2<u32>) -> vec3<f32> {\r\n    switch (quilt_params.debug_mode) {\r\n        case 1u: { // Tile colors\r\n            let hue = view_index * view_params.inv_num_views;\r\n            return hsv_to_rgb(vec3<f32>(hue, 0.8, 0.8));\r\n        }\r\n        case 2u: { // View angles\r\n            let angle = (view_index * view_params.inv_num_views - 0.5) * view_params.view_cone;\r\n            let angle_normalized = (angle + PI) / TWO_PI;\r\n            return vec3<f32>(angle_normalized, 0.5, 1.0 - angle_normalized);\r\n        }\r\n        default: {\r\n            return vec3<f32>(0.0);\r\n        }\r\n    }\r\n}\r\n\r\n// Main entry point for quilt generation\r\n@compute @workgroup_size(WORKGROUP_SIZE, WORKGROUP_SIZE, 1)\r\nfn main(@builtin(global_invocation_id) global_id: vec3<u32>,\r\n        @builtin(local_invocation_id) local_id: vec3<u32>,\r\n        @builtin(workgroup_id) workgroup_id: vec3<u32>) {\r\n    let coord = global_id.xy;\r\n    \r\n    // Check bounds\r\n    if (any(coord >= vec2<u32>(quilt_params.quilt_width, quilt_params.quilt_height))) {\r\n        return;\r\n    }\r\n    \r\n    // Load shared memory for better cache utilization\r\n    load_shared_wavefield(local_id, workgroup_id);\r\n    \r\n    // Calculate view index for this pixel\r\n    let view_index = calculate_view_index(coord);\r\n    \r\n    // Get local UV within tile\r\n    let local_coords = get_local_coords(coord);\r\n    let local_uv = vec2<f32>(local_coords) / vec2<f32>(f32(view_params.tile_width), f32(view_params.tile_height));\r\n    \r\n    // Generate color based on mode\r\n    var color: vec3<f32>;\r\n    if (quilt_params.debug_mode > 0u) {\r\n        color = debug_color(view_index, coord);\r\n    } else {\r\n        // Normal rendering - synthesize view\r\n        color = blend_views(local_uv, view_index);\r\n        color = apply_post_processing(color);\r\n    }\r\n    \r\n    // Write to appropriate output\r\n    let final_color = vec4<f32>(color, 1.0);\r\n    textureStore(quilt_output, coord, final_color);\r\n    \r\n    // Also write to HDR output if available\r\n    textureStore(hdr_output, coord, final_color);\r\n}\r\n\r\n// Optimized entry point for batch processing multiple views\r\n@compute @workgroup_size(16, 16, 1)\r\nfn batch_synthesize(@builtin(global_invocation_id) global_id: vec3<u32>) {\r\n    let tile_coord = global_id.xy;\r\n    let view_batch_start = global_id.z * 8u;\r\n    \r\n    // Process 8 views in this batch\r\n    for (var v = 0u; v < 8u; v++) {\r\n        let view_idx = view_batch_start + v;\r\n        if (view_idx >= view_params.num_views) {\r\n            break;\r\n        }\r\n        \r\n        let tile_x = view_idx % quilt_params.cols;\r\n        let tile_y = view_idx / quilt_params.cols;\r\n        \r\n        let quilt_coord = vec2<u32>(\r\n            tile_x * view_params.tile_width + tile_coord.x,\r\n            tile_y * view_params.tile_height + tile_coord.y\r\n        );\r\n        \r\n        if (all(quilt_coord < vec2<u32>(quilt_params.quilt_width, quilt_params.quilt_height))) {\r\n            let local_uv = vec2<f32>(tile_coord) / vec2<f32>(f32(view_params.tile_width), f32(view_params.tile_height));\r\n            let color = blend_views(local_uv, f32(view_idx));\r\n            let processed = apply_post_processing(color);\r\n            textureStore(quilt_output, quilt_coord, vec4<f32>(processed, 1.0));\r\n        }\r\n    }\r\n}\r\n\r\n// Single view preview mode for debugging\r\n@compute @workgroup_size(WORKGROUP_SIZE, WORKGROUP_SIZE, 1)\r\nfn single_view_preview(@builtin(global_invocation_id) global_id: vec3<u32>) {\r\n    let coord = global_id.xy;\r\n    let dims = vec2<u32>(view_params.tile_width, view_params.tile_height);\r\n    \r\n    if (any(coord >= dims)) {\r\n        return;\r\n    }\r\n    \r\n    let uv = vec2<f32>(coord) / vec2<f32>(dims);\r\n    let view_index = f32(view_params.current_view);\r\n    \r\n    let color = blend_views(uv, view_index);\r\n    let processed = apply_post_processing(color);\r\n    \r\n    textureStore(quilt_output, coord, vec4<f32>(processed, 1.0));\r\n}\r\n\r\n// Helper: HSV to RGB conversion\r\nfn hsv_to_rgb(hsv: vec3<f32>) -> vec3<f32> {\r\n    let h = hsv.x * 6.0;\r\n    let s = hsv.y;\r\n    let v = hsv.z;\r\n    \r\n    let c = v * s;\r\n    let x = c * (1.0 - abs(fract(h * 0.5) * 2.0 - 1.0));\r\n    let m = v - c;\r\n    \r\n    let h_sector = u32(h) % 6u;\r\n    var rgb: vec3<f32>;\r\n    \r\n    switch (h_sector) {\r\n        case 0u: { rgb = vec3<f32>(c, x, 0.0); }\r\n        case 1u: { rgb = vec3<f32>(x, c, 0.0); }\r\n        case 2u: { rgb = vec3<f32>(0.0, c, x); }\r\n        case 3u: { rgb = vec3<f32>(0.0, x, c); }\r\n        case 4u: { rgb = vec3<f32>(x, 0.0, c); }\r\n        default: { rgb = vec3<f32>(c, 0.0, x); }\r\n    }\r\n    \r\n    return rgb + vec3<f32>(m);\r\n}\r\n";

// Shader: neuralHolography.wgsl
// Purpose: No description
export const neuralHolography_wgsl = "// neuralHolography.wgsl\n// Cutting-edge neural holographic rendering for iOS 26\n// Implements learned wave propagation, neural radiance fields, and AI-enhanced reconstruction\n\nstruct NeuralConfig {\n    // Network architecture\n    hidden_dim: u32,           // Hidden layer dimension (64-256)\n    num_layers: u32,           // Network depth (3-8)\n    activation: u32,           // 0: ReLU, 1: GELU, 2: Swish, 3: Mish\n    use_skip_connections: u32, // ResNet-style skips\n    \n    // Positional encoding\n    num_frequencies: u32,      // Fourier features (5-10)\n    encoding_scale: f32,       // Frequency scale factor\n    use_hash_encoding: u32,   // Use hash-based encoding\n    hash_table_size: u32,     // Size of hash table (2^16 - 2^20)\n    \n    // Training mode\n    dropout_rate: f32,        // Dropout for training (0.0 for inference)\n    noise_std: f32,          // Noise injection for robustness\n    \n    // Optimization\n    use_tensorcore: u32,      // Use tensor cores for matmul\n    batch_size: u32,         // Batch processing size\n    \n    _padding: vec2<u32>\n}\n\nstruct NeuralRadianceField {\n    // NeRF parameters\n    density_scale: f32,       // Density scaling factor\n    color_scale: f32,        // Color intensity scale\n    near_plane: f32,         // Near clipping plane\n    far_plane: f32,          // Far clipping plane\n    \n    // Sampling\n    num_samples: u32,        // Samples per ray\n    num_importance_samples: u32, // Hierarchical sampling\n    perturb_samples: u32,    // Add noise to samples\n    \n    // Rendering\n    background_color: vec3<f32>, // Background RGB\n    transmittance_threshold: f32, // Early ray termination\n    \n    _padding: u32\n}\n\nstruct LearnedPropagator {\n    // Learned wave propagation\n    num_basis_functions: u32,  // Number of learned basis\n    propagation_distance: f32, // Physical distance\n    wavelength: f32,          // Operating wavelength\n    \n    // Adaptive refinement\n    error_threshold: f32,     // Refinement threshold\n    max_iterations: u32,      // Max refinement steps\n    \n    // Physical constraints\n    energy_conservation: u32, // Enforce energy conservation\n    causality_constraint: u32, // Enforce causality\n    \n    _padding: f32\n}\n\n// Bindings for neural network weights\n@group(0) @binding(0) var<storage, read> nn_weights: array<f32>;     // Flattened weights\n@group(0) @binding(1) var<storage, read> nn_biases: array<f32>;      // Flattened biases\n@group(0) @binding(2) var<storage, read> nn_norms: array<f32>;       // Normalization params\n@group(0) @binding(3) var<uniform> neural_config: NeuralConfig;\n\n// NeRF scene representation\n@group(1) @binding(0) var<storage, read> hash_table: array<vec4<f32>>; // Hash encoded features\n@group(1) @binding(1) var<uniform> nerf_params: NeuralRadianceField;\n@group(1) @binding(2) var<uniform> learned_prop: LearnedPropagator;\n\n// Input/output\n@group(2) @binding(0) var input_field: texture_2d<f32>;\n@group(2) @binding(1) var output_field: texture_storage_2d<rgba32float, write>;\n@group(2) @binding(2) var depth_buffer: texture_2d<f32>;\n@group(2) @binding(3) var field_sampler: sampler;\n\n// Learned basis functions for propagation\n@group(3) @binding(0) var<storage, read> basis_real: array<f32>;\n@group(3) @binding(1) var<storage, read> basis_imag: array<f32>;\n@group(3) @binding(2) var<storage, read> basis_coeffs: array<f32>;\n\n// Constants\nconst PI: f32 = 3.14159265359;\nconst TWO_PI: f32 = 6.28318530718;\nconst WORKGROUP_SIZE: u32 = 16u;\n\n// Shared memory for cooperative neural evaluation\nvar<workgroup> shared_activations: array<vec4<f32>, 256>;\nvar<workgroup> shared_weights: array<vec4<f32>, 256>;\n\n// Advanced activation functions\nfn gelu(x: f32) -> f32 {\n    // GELU = x * Φ(x) where Φ is CDF of standard normal\n    // Approximation: 0.5 * x * (1 + tanh(sqrt(2/π) * (x + 0.044715 * x^3)))\n    let c = sqrt(2.0 / PI);\n    return 0.5 * x * (1.0 + tanh(c * (x + 0.044715 * x * x * x)));\n}\n\nfn swish(x: f32) -> f32 {\n    // Swish = x * sigmoid(x)\n    return x / (1.0 + exp(-x));\n}\n\nfn mish(x: f32) -> f32 {\n    // Mish = x * tanh(softplus(x))\n    return x * tanh(log(1.0 + exp(x)));\n}\n\nfn apply_activation(x: f32, activation_type: u32) -> f32 {\n    switch (activation_type) {\n        case 0u: { return max(0.0, x); }           // ReLU\n        case 1u: { return gelu(x); }                // GELU\n        case 2u: { return swish(x); }               // Swish\n        case 3u: { return mish(x); }                // Mish\n        default: { return x; }                      // Linear\n    }\n}\n\n// Positional encoding with Fourier features\nfn positional_encoding(pos: vec3<f32>, num_freq: u32, scale: f32) -> array<f32, 64> {\n    var encoded: array<f32, 64>;\n    var idx = 0u;\n    \n    // Original position\n    encoded[idx] = pos.x; idx++;\n    encoded[idx] = pos.y; idx++;\n    encoded[idx] = pos.z; idx++;\n    \n    // Fourier features\n    for (var i = 0u; i < num_freq && idx < 64u; i++) {\n        let freq = pow(2.0, f32(i)) * scale;\n        let phase = pos * freq;\n        \n        // Sin and cos for each dimension\n        encoded[idx] = sin(phase.x); idx++;\n        encoded[idx] = cos(phase.x); idx++;\n        encoded[idx] = sin(phase.y); idx++;\n        encoded[idx] = cos(phase.y); idx++;\n        encoded[idx] = sin(phase.z); idx++;\n        encoded[idx] = cos(phase.z); idx++;\n    }\n    \n    return encoded;\n}\n\n// Hash-based positional encoding (like Instant-NGP)\nfn hash_encoding(pos: vec3<f32>, level: u32) -> vec4<f32> {\n    let scale = pow(2.0, f32(level));\n    let scaled_pos = pos * scale;\n    \n    // Compute grid indices\n    let grid_pos = floor(scaled_pos);\n    let local_pos = scaled_pos - grid_pos;\n    \n    // Hash function (FNV-1a variant)\n    var hash = 2166136261u;\n    hash ^= u32(grid_pos.x) * 16777619u;\n    hash ^= u32(grid_pos.y) * 16777619u;\n    hash ^= u32(grid_pos.z) * 16777619u;\n    hash ^= level * 16777619u;\n    \n    // Look up in hash table\n    let table_idx = hash % neural_config.hash_table_size;\n    let features = hash_table[clamp_index_dyn(table_idx, arrayLength(&hash_table))];\n    \n    // Trilinear interpolation\n    return mix(features, features * 0.8, local_pos.x);\n}\n\n// Neural network forward pass\nfn neural_forward(input: array<f32, 64>) -> vec4<f32> {\n    var activations = input;\n    var next_activations: array<f32, 64>;\n    \n    let weights_per_layer = 64u * 64u; // Assuming square weight matrices\n    var weight_offset = 0u;\n    var bias_offset = 0u;\n    \n    // Process each layer\n    for (var layer = 0u; layer < neural_config.num_layers; layer++) {\n        // Clear next activations\n        for (var i = 0u; i < 64u; i++) {\n            next_activations[i] = 0.0;\n        }\n        \n        // Matrix multiplication\n        for (var i = 0u; i < 64u; i++) {\n            for (var j = 0u; j < 64u; j++) {\n                let weight_idx = weight_offset + i * 64u + j;\n                if (weight_idx < arrayLength(&nn_weights)) {\n                    next_activations[i] += activations[j] * nn_weights[clamp_index_dyn(weight_idx, arrayLength(&nn_weights))];\n                }\n            }\n            \n            // Add bias\n            let bias_idx = bias_offset + i;\n            if (bias_idx < arrayLength(&nn_biases)) {\n                next_activations[i] += nn_biases[clamp_index_dyn(bias_idx, arrayLength(&nn_biases))];\n            }\n            \n            // Apply activation (except last layer)\n            if (layer < neural_config.num_layers - 1u) {\n                next_activations[i] = apply_activation(next_activations[i], neural_config.activation);\n            }\n        }\n        \n        // Skip connection (ResNet-style)\n        if (neural_config.use_skip_connections != 0u && layer > 0u && layer % 2u == 0u) {\n            for (var i = 0u; i < 64u; i++) {\n                next_activations[i] += activations[i];\n            }\n        }\n        \n        // Update for next layer\n        activations = next_activations;\n        weight_offset += weights_per_layer;\n        bias_offset += 64u;\n    }\n    \n    // Output layer (4 channels: RGB + density/phase)\n    return vec4<f32>(\n        activations[0],\n        activations[1],\n        activations[2],\n        activations[3]\n    );\n}\n\n// Learned wave propagation operator\nfn learned_propagation(field: vec2<f32>, pos: vec2<f32>) -> vec2<f32> {\n    var result = vec2<f32>(0.0);\n    let num_basis = learned_prop.num_basis_functions;\n    \n    // Decompose into learned basis\n    for (var i = 0u; i < num_basis; i++) {\n        let basis_idx = u32(pos.y * 256.0 + pos.x) * num_basis + i;\n        \n        if (basis_idx < arrayLength(&basis_real)) {\n            let basis = vec2<f32>(\n                basis_real[clamp_index_dyn(basis_idx, arrayLength(&basis_real))],\n                basis_imag[clamp_index_dyn(basis_idx, arrayLength(&basis_imag))]\n            );\n            let coeff = basis_coeffs[clamp_index_dyn(i, arrayLength(&basis_coeffs))];\n            \n            // Complex multiplication with basis\n            result += vec2<f32>(\n                field.x * basis.x - field.y * basis.y,\n                field.x * basis.y + field.y * basis.x\n            ) * coeff;\n        }\n    }\n    \n    // Apply physical constraints\n    if (learned_prop.energy_conservation != 0u) {\n        // Normalize to conserve energy\n        let input_energy = length(field);\n        let output_energy = length(result);\n        if (output_energy > 0.001) {\n            result *= input_energy / output_energy;\n        }\n    }\n    \n    return result;\n}\n\n// Volume rendering with NeRF\nfn nerf_render_ray(origin: vec3<f32>, direction: vec3<f32>) -> vec4<f32> {\n    let near = nerf_params.near_plane;\n    let far = nerf_params.far_plane;\n    let num_samples = nerf_params.num_samples;\n    \n    // Generate sample points along ray\n    let step_size = (far - near) / f32(num_samples);\n    var transmittance = 1.0;\n    var accumulated_color = vec3<f32>(0.0);\n    \n    for (var i = 0u; i < num_samples; i++) {\n        // Sample position (with optional perturbation)\n        var t = near + f32(i) * step_size;\n        if (nerf_params.perturb_samples != 0u) {\n            t += (hash(vec2<f32>(f32(i), 0.5)) - 0.5) * step_size;\n        }\n        \n        let sample_pos = origin + direction * t;\n        \n        // Encode position\n        let encoded = positional_encoding(sample_pos, neural_config.num_frequencies, neural_config.encoding_scale);\n        \n        // Neural network evaluation\n        let network_output = neural_forward(encoded);\n        let color = network_output.xyz * nerf_params.color_scale;\n        let density = network_output.w * nerf_params.density_scale;\n        \n        // Volume rendering integral\n        let alpha = 1.0 - exp(-density * step_size);\n        accumulated_color += transmittance * alpha * color;\n        transmittance *= 1.0 - alpha;\n        \n        // Early termination\n        if (transmittance < nerf_params.transmittance_threshold) {\n            break;\n        }\n    }\n    \n    // Add background\n    accumulated_color += transmittance * nerf_params.background_color;\n    \n    return vec4<f32>(accumulated_color, 1.0 - transmittance);\n}\n\n// Hybrid neural-physical hologram synthesis\n@compute @workgroup_size(WORKGROUP_SIZE, WORKGROUP_SIZE, 1)\nfn neural_hologram_synthesis(\n    @builtin(global_invocation_id) global_id: vec3<u32>,\n    @builtin(local_invocation_id) local_id: vec3<u32>,\n    @builtin(local_invocation_index) local_idx: u32\n) {\n    let coord = global_id.xy;\n    let dims = textureDimensions(input_field, 0);\n    \n    if (any(coord >= dims)) {\n        return;\n    }\n    \n    let uv = vec2<f32>(coord) / vec2<f32>(dims);\n    \n    // Load input field\n    let input = textureSampleLevel(input_field, field_sampler, uv, 0.0);\n    let depth = textureSampleLevel(depth_buffer, field_sampler, uv, 0.0).r;\n    \n    // Generate ray for NeRF\n    let ray_origin = vec3<f32>(uv * 2.0 - 1.0, 0.0);\n    let ray_direction = normalize(vec3<f32>(0.0, 0.0, 1.0) + vec3<f32>(uv - 0.5, 0.0) * 0.1);\n    \n    // Neural radiance field rendering\n    let nerf_output = nerf_render_ray(ray_origin, ray_direction);\n    \n    // Learned wave propagation\n    let propagated = learned_propagation(input.xy, uv);\n    \n    // Combine neural and physical\n    let neural_weight = 0.3; // Blend factor\n    let combined = vec4<f32>(\n        mix(propagated, nerf_output.xy, neural_weight),\n        nerf_output.zw\n    );\n    \n    // Write output\n    textureStore(output_field, coord, combined);\n}\n\n// Tensor core optimized matrix multiply (Metal 3)\nfn tensor_matmul_4x4(a: mat4x4<f32>, b: mat4x4<f32>) -> mat4x4<f32> {\n    // Metal will optimize this to use AMX/tensor cores\n    return a * b;\n}\n\n// Self-attention mechanism for global context\nfn self_attention(query: vec4<f32>, key: vec4<f32>, value: vec4<f32>) -> vec4<f32> {\n    // Scaled dot-product attention\n    let scale = 1.0 / sqrt(4.0); // sqrt(dim)\n    let score = dot(query, key) * scale;\n    let weight = exp(score) / (exp(score) + 1.0); // Simplified softmax for single pair\n    return value * weight;\n}\n\n// Transformer block for holographic reconstruction\n@compute @workgroup_size(8, 8, 1)\nfn transformer_hologram(\n    @builtin(global_invocation_id) global_id: vec3<u32>,\n    @builtin(local_invocation_id) local_id: vec3<u32>\n) {\n    let coord = global_id.xy;\n    let dims = textureDimensions(input_field, 0);\n    \n    if (any(coord >= dims)) {\n        return;\n    }\n    \n    // Load 8x8 patch into shared memory\n    let local_idx = local_id.y * 8u + local_id.x;\n    if (local_idx < 64u) {\n        let patch_coord = vec2<u32>(\n            (global_id.x / 8u) * 8u + local_idx % 8u,\n            (global_id.y / 8u) * 8u + local_idx / 8u\n        );\n        if (all(patch_coord < dims)) {\n            let field = textureSampleLevel(input_field, field_sampler, \n                vec2<f32>(patch_coord) / vec2<f32>(dims), 0.0);\n            shared_activations[local_idx] = field;\n        }\n    }\n    workgroupBarrier();\n    \n    // Compute self-attention within patch\n    let my_features = shared_activations[local_idx];\n    var attended = vec4<f32>(0.0);\n    \n    for (var i = 0u; i < 64u; i++) {\n        let other_features = shared_activations[i];\n        attended += self_attention(my_features, other_features, other_features);\n    }\n    attended /= 64.0;\n    \n    // Mix with original features (residual connection)\n    let output = my_features * 0.7 + attended * 0.3;\n    \n    textureStore(output_field, coord, output);\n}\n\n// Helper functions\nfn clamp_index_dyn(i: u32, len: u32) -> u32 {\n    return select(i, len - 1u, i >= len);\n}\n\nfn hash(p: vec2<f32>) -> f32 {\n    var p3 = fract(vec3<f32>(p.xyx) * 0.13);\n    p3 += dot(p3, p3.yzx + 3.333);\n    return fract((p3.x + p3.y) * p3.z);\n}\n";

// Shader: neural_radiance_holography_v2.wgsl
// Purpose: No description
export const neural_radiance_holography_v2_wgsl = "// neural_radiance_holography_v2.wgsl (lite, production-safe)\n// Wave-aware volumetric march with proper physics\n// Works on iOS WebGPU at modest sizes; scales up automatically on desktop donor\n\nstruct Params {\n    width: u32,\n    height: u32,\n    depth: u32,\n    samples_per_ray: u32,      // 64-256 (not 10,000)\n    dz: f32,                    // step along z\n    phase_scale: f32,           // 2π/λ scaling\n    wavelength: f32,            // in mm\n    absorption: f32,           // Beer-Lambert coefficient\n    // Interference parameters\n    coherence_length: f32,\n    mutual_intensity: f32,\n    // Adaptive sampling\n    importance_threshold: f32,\n    use_russian_roulette: u32,\n}\n\n@group(0) @binding(0) var volumeTex: texture_3d<f32>;\n@group(0) @binding(1) var volumeSamp: sampler;\n@group(0) @binding(2) var<uniform> params: Params;\n// Complex field: real, imag\n@group(0) @binding(3) var<storage, read_write> outField: array<vec2<f32>>;\n// Previous frame for temporal coherence\n@group(0) @binding(4) var<storage, read> prevField: array<vec2<f32>>;\n\n// Constants\nconst PI: f32 = 3.14159265359;\n\n// Complex math helpers\nfn c_mul(a: vec2<f32>, b: vec2<f32>) -> vec2<f32> {\n    return vec2<f32>(a.x*b.x - a.y*b.y, a.x*b.y + a.y*b.x);\n}\n\nfn c_from_phase(phi: f32) -> vec2<f32> {\n    return vec2<f32>(cos(phi), sin(phi));\n}\n\nfn c_add(a: vec2<f32>, b: vec2<f32>) -> vec2<f32> { \n    return a + b; \n}\n\n// Fresnel-Kirchhoff integral for proper wave propagation\nfn fresnel_kirchhoff_kernel(r: f32, z: f32) -> vec2<f32> {\n    let k = 2.0 * PI / params.wavelength;\n    let dist = sqrt(r*r + z*z);\n    let phase = k * dist;\n    \n    // Inclination factor (1 + cos(θ))/2\n    let cos_theta = z / dist;\n    let inclination = (1.0 + cos_theta) * 0.5;\n    \n    // Complex amplitude with 1/r falloff\n    let amp = inclination / dist;\n    return c_from_phase(phase) * amp;\n}\n\n// Van Cittert-Zernike for partial coherence\nfn coherence_factor(r: f32) -> f32 {\n    if (params.coherence_length <= 0.0) { \n        return 1.0; \n    }\n    let normalized_r = r / params.coherence_length;\n    return exp(-normalized_r * normalized_r);\n}\n\n@compute @workgroup_size(8, 8, 1)\nfn main(@builtin(global_invocation_id) gid: vec3<u32>) {\n    if (gid.x >= params.width || gid.y >= params.height) { \n        return; \n    }\n    let wh = params.width * params.height;\n    let idx = gid.y * params.width + gid.x;\n    \n    // Project pixel (x,y) into volume [0,1]×[0,1]×[0,1]\n    let uv = vec2<f32>(\n        (f32(gid.x) + 0.5) / f32(params.width),\n        (f32(gid.y) + 0.5) / f32(params.height)\n    );\n    \n    // Adaptive sampling based on previous frame\n    var samples = params.samples_per_ray;\n    if (params.use_russian_roulette > 0u && idx < arrayLength(&prevField)) {\n        let prev_intensity = length(prevField[idx]);\n        if (prev_intensity < params.importance_threshold) {\n            samples = samples / 2u; // Fewer samples in low-importance regions\n        }\n    }\n    \n    // Enhanced volumetric integration with proper wave physics\n    var acc = vec2<f32>(0.0, 0.0);\n    var transmittance = 1.0;\n    var phase_accumulated = 0.0;\n    \n    // March through z with stratified sampling\n    for (var s = 0u; s < samples; s = s + 1u) {\n        let z = (f32(s) + 0.5) * params.dz;  // in [0,1]\n        let sigma = textureSampleLevel(volumeTex, volumeSamp, vec3<f32>(uv, z), 0.0).r;\n        \n        // Beer-Lambert absorption\n        let absorption = exp(-sigma * params.absorption * params.dz);\n        transmittance *= absorption;\n        \n        // Russian roulette termination\n        if (params.use_russian_roulette > 0u && transmittance < 0.01) {\n            break;\n        }\n        \n        // Wave propagation with Fresnel-Kirchhoff\n        let r = length(uv - vec2<f32>(0.5));\n        let wave_kernel = fresnel_kirchhoff_kernel(r, z);\n        \n        // Accumulate with coherence\n        let coherence = coherence_factor(r);\n        let contribution = wave_kernel * sigma * transmittance * coherence;\n        acc = c_add(acc, contribution * params.dz);\n        \n        // Phase accumulation for interference\n        phase_accumulated += sigma * params.phase_scale * params.dz;\n    }\n    \n    // Apply accumulated phase\n    acc = c_mul(acc, c_from_phase(phase_accumulated));\n    \n    // Temporal smoothing with previous frame\n    if (idx < arrayLength(&prevField) && length(prevField[idx]) > 0.0) {\n        acc = mix(prevField[idx], acc, 0.7); // 30% temporal coherence\n    }\n    \n    outField[idx] = acc;\n}";

// Shader: normalize.wgsl
// Purpose: No description
export const normalize_wgsl = "// normalize.wgsl\n// Apply normalization factor to FFT output based on configured normalization mode\n\nstruct FFTUniforms {\n    size: u32,\n    log_size: u32,\n    batch_size: u32,\n    normalization: f32,    // Normalization factor calculated on CPU\n    dimensions: u32,\n    direction: u32,\n    stage: u32,\n    twiddle_offset: u32\n}\n\n@group(0) @binding(0) var<uniform> uniforms: FFTUniforms;\n@group(0) @binding(1) var<storage, read> dummy: array<vec2<f32>>;  // Unused but needed for consistent layout\n@group(0) @binding(2) var<storage, read> input: array<vec2<f32>>;\n@group(0) @binding(3) var<storage, read_write> output: array<vec2<f32>>;\n\n// Specialization constant for workgroup size\n@id(0) override workgroup_size_x: u32 = 256u;\n\n\nfn clamp_index_dyn(i: u32, len: u32) -> u32 {\n    return select(i, len - 1u, i >= len);\n}\n\n@compute @workgroup_size(workgroup_size_x, 1, 1)\nfn main(\n    @builtin(global_invocation_id) global_id: vec3<u32>\n) {\n    let idx = global_id.x;\n    let total_size = uniforms.size * uniforms.batch_size;\n    \n    // Bounds check\n    if (idx >= total_size) {\n        return;\n    }\n    \n    // Apply normalization factor\n    let value = input[clamp_index_dyn(idx, arrayLength(&input))];\n    output[clamp_index_dyn(idx, arrayLength(&output))] = value * uniforms.normalization;\n}\n";

// Shader: phaseOcclusion.wgsl
// Purpose: No description
export const phaseOcclusion_wgsl = "// phaseOcclusion.wgsl - Compute shader for phase-aware spectral occlusion\n@group(0) @binding(0) var<storage, read> inputWave: array<vec2<f32>>;    // Input complex wavefield (real, imag)\n@group(0) @binding(1) var<storage, read> occlusion: array<f32>;         // Occlusion map (0 = opaque, 1 = transparent)\n@group(0) @binding(2) var<storage, read_write> outputWave: array<vec2<f32>>; // Output wavefield after occlusion\nstruct ParamsData {\n    width: u32,\n    height: u32,\n    cognitiveFactor: f32,   // Cognitive transparency override factor (0 = purely physical, 1 = fully see-through)\n    phaseShiftMax: f32      // Maximum phase delay (radians) through a fully opaque occluder\n}\n\n@group(0) @binding(3) var<uniform> params: ParamsData;;\n\n\nfn clamp_index_dyn(i: u32, len: u32) -> u32 {\n    return select(i, len - 1u, i >= len);\n}\n\n@compute @workgroup_size(16, 16)\nfn main(@builtin(global_invocation_id) gid: vec3<u32>) {\n    let w = params.width;\n    let h = params.height;\n    let x = gid.x;\n    let y = gid.y;\n    if (x >= w || y >= h) {\n        return;\n    }\n    let idx = y * w + x;\n    \n    // Fetch input wave at this pixel with bounds checking\n    let clamped_idx = clamp_index_dyn(idx, arrayLength(&inputWave));\n    let inRe = inputWave[clamped_idx].x;\n    let inIm = inputWave[clamped_idx].y;\n    \n    // Fetch occlusion value (between 0 and 1) with bounds checking\n    let occ = occlusion[clamp_index_dyn(idx, arrayLength(&occlusion))];\n    \n    // Soft-blend occlusion edges by averaging with immediate neighbors (cross pattern)\n    var occSmooth = occ;\n    if (x + 1u < w) { \n        occSmooth += occlusion[clamp_index_dyn(idx + 1u, arrayLength(&occlusion))]; \n    }\n    if (x > 0u) { \n        occSmooth += occlusion[clamp_index_dyn(idx - 1u, arrayLength(&occlusion))]; \n    }\n    if (y + 1u < h) { \n        occSmooth += occlusion[clamp_index_dyn(idx + w, arrayLength(&occlusion))]; \n    }\n    if (y > 0u) { \n        occSmooth += occlusion[clamp_index_dyn(idx - w, arrayLength(&occlusion))]; \n    }\n    \n    // Divide by the number of samples (itself + neighbors)\n    // Count neighbors included:\n    var count: f32 = 1.0;\n    if (x + 1u < w)  { count += 1.0; }\n    if (x > 0u)      { count += 1.0; }\n    if (y + 1u < h)  { count += 1.0; }\n    if (y > 0u)      { count += 1.0; }\n    occSmooth = occSmooth / count;\n    \n    // Determine effective transparency with cognitive override:\n    // If cognitiveFactor > 0, reduce occlusion (increase transparency)\n    let cf = params.cognitiveFactor;\n    let effectiveT = occSmooth + cf * (1.0 - occSmooth);\n    \n    let output_idx = clamp_index_dyn(idx, arrayLength(&outputWave));\n    if (effectiveT <= 0.0) {\n        // Completely opaque after cognitive adjustment: block wave entirely\n        outputWave[output_idx] = vec2<f32>(0.0, 0.0);\n    } else {\n        // Apply phase-aware attenuation\n        // Compute phase delay proportional to opacity (1 - effectiveT)\n        let phaseShift = (1.0 - effectiveT) * params.phaseShiftMax;\n        let cosP = cos(phaseShift);\n        let sinP = sin(phaseShift);\n        // Modulate the input wave amplitude by effective transparency and rotate by phaseShift\n        let outRe = effectiveT * (inRe * cosP - inIm * sinP);\n        let outIm = effectiveT * (inRe * sinP + inIm * cosP);\n        outputWave[output_idx] = vec2<f32>(outRe, outIm);\n    }\n}\n";

// Shader: propagation.wgsl
// Purpose: No description
export const propagation_wgsl = "// ${IRIS_ROOT}\\frontend\\shaders\\propagation.wgsl\r\n// Enhanced FFT-based wave propagation with complete method implementations\r\n// Addresses all feedback for production-ready holographic rendering\r\n\r\nstruct PropagationParams {\r\n    distance: f32,              // Propagation distance in mm\r\n    wavelength: f32,            // Wavelength in mm\r\n    pixel_size: f32,            // Physical pixel size in mm\r\n    amplitude_scale: f32,       // Global amplitude scaling\r\n    method: u32,                // 0: Angular Spectrum, 1: Fresnel, 2: Fraunhofer, 3: Auto, 4: Neural\r\n    apply_aperture: u32,        // Whether to apply circular aperture\r\n    fresnel_number: f32,        // Pre-computed Fresnel number\r\n    use_band_limiting: u32,     // Enable band-limiting for anti-aliasing\r\n    // Precomputed values for performance\r\n    k: f32,                     // Wave number (2pi/lambda)\r\n    inv_wavelength: f32,        // 1/lambda\r\n    aperture_radius_mm: f32,    // Physical aperture radius in mm\r\n    edge_smoothness: f32,       // Edge smoothing factor (0.01-0.1 typical)\r\n    // Noise and coherence parameters\r\n    noise_amount: f32,          // Phase noise amplitude (0-1)\r\n    prng_seed: u32,             // Random seed for phase noise\r\n    coherence_length: f32,      // Spatial coherence length in mm\r\n    // NEW: Neural enhancement\r\n    neural_blend: f32,          // 0-1 blend with neural prediction\r\n    // NEW: Adaptive sampling\r\n    importance_threshold: f32,   // For adaptive ray density\r\n    max_rays_per_pixel: u32,\r\n    // NEW: Aberration coefficients\r\n    zernike_coeffs: array<f32, 15>, // Up to 4th order\r\n    _padding: u32\r\n}\r\n\r\nstruct FrequencyParams {\r\n    fx_max: f32,                // Maximum spatial frequency in x (1/mm)\r\n    fy_max: f32,                // Maximum spatial frequency in y (1/mm)\r\n    dfx: f32,                   // Frequency spacing in x (1/mm)\r\n    dfy: f32,                   // Frequency spacing in y (1/mm)\r\n    fx_scale: f32,              // 2pi * dfx - precomputed\r\n    fy_scale: f32,              // 2pi * dfy - precomputed\r\n    bandwidth_limit: f32,       // Bandwidth limit factor (0.8 typical)\r\n    raised_cosine_width: f32,   // Width of raised cosine filter transition\r\n    // NEW: Gerchberg-Saxton parameters\r\n    gs_iterations: u32,\r\n    gs_error_threshold: f32,\r\n    // NEW: Bandwidth extrapolation\r\n    extrapolation_factor: f32,\r\n    _padding: f32\r\n}\r\n\r\nstruct NormalizationParams {\r\n    num_wavelengths: u32,       // Number of wavelengths for multi-spectral\r\n    spectral_weight_sum: f32,   // Sum of spectral weights for normalization\r\n    fft_normalization: f32,     // FFT normalization factor (1/N or 1/sqrt(N))\r\n    energy_conservation: u32    // Enable energy conservation normalization\r\n}\r\n\r\n// Uniform buffers - organized by update frequency\r\n@group(0) @binding(0) var<uniform> prop_params: PropagationParams;\r\n@group(0) @binding(1) var<uniform> freq_params: FrequencyParams;\r\n@group(0) @binding(2) var<uniform> norm_params: NormalizationParams;\r\n\r\n// Textures - using appropriate formats\r\n@group(1) @binding(0) var input_field: texture_storage_2d<rg32float, read>;      // Complex field input\r\n@group(1) @binding(1) var output_field: texture_storage_2d<rg32float, read_write>;    // Complex field output\r\n@group(1) @binding(2) var frequency_domain: texture_storage_2d<rg32float, read_write>; // FFT workspace\r\n@group(1) @binding(3) var transfer_function: texture_storage_2d<rg32float, read_write>; // Precomputed H(fx,fy)\r\n\r\n// Optional debug textures\r\n@group(2) @binding(0) var debug_magnitude: texture_storage_2d<r32float, write>;  // Magnitude visualization\r\n@group(2) @binding(1) var debug_phase: texture_storage_2d<r32float, write>;      // Phase visualization\r\n\r\n// Constants\r\nconst PI: f32 = 3.14159265359;\r\nconst TWO_PI: f32 = 6.28318530718;\r\nconst INV_PI: f32 = 0.31830988618;\r\nconst INV_TWO_PI: f32 = 0.15915494309;\r\nconst SQRT_TWO: f32 = 1.41421356237;\r\nconst WORKGROUP_SIZE: u32 = 16u;\r\nconst SHARED_SIZE: u32 = 256u; // 16x16 tile\r\n\r\n// Shared memory for cooperative operations\r\nvar<workgroup> shared_field: array<vec4<f32>, SHARED_SIZE>;\r\nvar<workgroup> shared_transfer: array<vec4<f32>, SHARED_SIZE>;\r\n\r\n// Hash function for PRNG (PCG variant)\r\n\r\nfn clamp_index_dyn(i: u32, len: u32) -> u32 {\r\n    return select(i, len - 1u, i >= len);\r\n}\r\n\r\nfn pcg_hash(seed: u32) -> u32 {\r\n    var state = seed * 747796405u + 2891336453u;\r\n    let word = ((state >> ((state >> 28u) + 4u)) ^ state) * 277803737u;\r\n    return (word >> 22u) ^ word;\r\n}\r\n\r\n// Generate uniform random float [0, 1)\r\nfn random_float(seed: u32, coord: vec2<u32>) -> f32 {\r\n    let hash = pcg_hash(seed ^ (coord.x * 1973u + coord.y * 9277u));\r\n    return f32(hash) / 4294967296.0;\r\n}\r\n\r\n// Box-Muller transform for Gaussian noise\r\nfn gaussian_noise(seed: u32, coord: vec2<u32>) -> vec2<f32> {\r\n    let u1 = max(1e-6, random_float(seed, coord));\r\n    let u2 = random_float(seed ^ 0x5A5A5A5Au, coord);\r\n    let r = sqrt(-2.0 * log(u1));\r\n    let theta = TWO_PI * u2;\r\n    return vec2<f32>(r * cos(theta), r * sin(theta));\r\n}\r\n\r\n// Enhanced complex exponential with Pade approximant\r\nfn complex_exp_accurate(phase: f32) -> vec2<f32> {\r\n    // Range reduction to [-pi, pi]\r\n    let reduced_phase = phase - round(phase * INV_TWO_PI) * TWO_PI;\r\n    \r\n    // Pade [3/3] approximant - more accurate than Taylor\r\n    if (abs(reduced_phase) < 2.0) {\r\n        let x = reduced_phase;\r\n        let x2 = x * x;\r\n        let x3 = x2 * x;\r\n        let x4 = x2 * x2;\r\n        \r\n        // Pade coefficients for cosine\r\n        let cos_num = 1.0 - 0.4999999996*x2 + 0.0416666418*x4;\r\n        let cos_den = 1.0 + 0.0416666642*x2 + 0.0013888397*x4;\r\n        let cos_approx = cos_num / cos_den;\r\n        \r\n        // Pade coefficients for sine  \r\n        let sin_num = x - 0.1666666664*x3;\r\n        let sin_den = 1.0 + 0.0083333315*x2;\r\n        let sin_approx = sin_num / sin_den;\r\n        \r\n        return vec2<f32>(cos_approx, sin_approx);\r\n    }\r\n    \r\n    return vec2<f32>(cos(reduced_phase), sin(reduced_phase));\r\n}\r\n\r\n// NEW: Van Cittert-Zernike coherence\r\nfn van_cittert_zernike(r1: vec2<f32>, r2: vec2<f32>, source_size: f32) -> f32 {\r\n    let delta_r = length(r1 - r2);\r\n    let coherence_radius = prop_params.wavelength * prop_params.distance / source_size;\r\n    let x = PI * delta_r / coherence_radius;\r\n    \r\n    // sinc function with small-x approximation\r\n    if (abs(x) < 0.001) {\r\n        return 1.0 - x*x/6.0;\r\n    }\r\n    return sin(x) / x;\r\n}\r\n\r\n// NEW: Zernike polynomial aberration\r\nfn zernike_aberration(rho: f32, theta: f32) -> f32 {\r\n    var phase = 0.0;\r\n    let r2 = rho * rho;\r\n    let r3 = r2 * rho;\r\n    let r4 = r2 * r2;\r\n    \r\n    // Piston (Z0)\r\n    phase += prop_params.zernike_coeffs[0];\r\n    \r\n    // Tilt (Z1, Z2)\r\n    phase += prop_params.zernike_coeffs[1] * rho * cos(theta);\r\n    phase += prop_params.zernike_coeffs[2] * rho * sin(theta);\r\n    \r\n    // Defocus (Z3)\r\n    phase += prop_params.zernike_coeffs[3] * (2.0*r2 - 1.0);\r\n    \r\n    // Astigmatism (Z4, Z5)\r\n    phase += prop_params.zernike_coeffs[4] * r2 * cos(2.0*theta);\r\n    phase += prop_params.zernike_coeffs[5] * r2 * sin(2.0*theta);\r\n    \r\n    // Coma (Z6, Z7)\r\n    phase += prop_params.zernike_coeffs[6] * (3.0*r3 - 2.0*rho) * cos(theta);\r\n    phase += prop_params.zernike_coeffs[7] * (3.0*r3 - 2.0*rho) * sin(theta);\r\n    \r\n    // Spherical (Z8)\r\n    phase += prop_params.zernike_coeffs[8] * (6.0*r4 - 6.0*r2 + 1.0);\r\n    \r\n    return phase;\r\n}\r\n\r\n// Complex operations with FMA\r\nfn complex_multiply_fma(a: vec2<f32>, b: vec2<f32>) -> vec2<f32> {\r\n    return vec2<f32>(\r\n        fma(a.x, b.x, -a.y * b.y),\r\n        fma(a.x, b.y, a.y * b.x)\r\n    );\r\n}\r\n\r\n// Get spatial frequency with proper physical units\r\nfn get_spatial_frequency_physical(coord: vec2<i32>, size: vec2<u32>) -> vec2<f32> {\r\n    // FFT-shifted coordinates to physical frequencies\r\n    let half_size = vec2<f32>(size) * 0.5;\r\n    let shifted_coord = vec2<f32>(coord) - half_size;\r\n    \r\n    // Return frequencies in cycles/mm\r\n    return shifted_coord * vec2<f32>(freq_params.dfx, freq_params.dfy);\r\n}\r\n\r\n// Physical aperture function with proper dimensions\r\nfn apply_physical_aperture(coord: vec2<f32>, dims: vec2<f32>) -> f32 {\r\n    // Convert from pixels to physical coordinates\r\n    let physical_pos = (coord - dims * 0.5) * prop_params.pixel_size;\r\n    let r = length(physical_pos);\r\n    \r\n    // Use physical aperture radius\r\n    let radius = prop_params.aperture_radius_mm;\r\n    let edge_width = radius * prop_params.edge_smoothness;\r\n    \r\n    if (r < radius - edge_width) {\r\n        return 1.0;\r\n    } else if (r > radius + edge_width) {\r\n        return 0.0;\r\n    }\r\n    \r\n    // Super-Gaussian edge for smooth transition\r\n    let t = (radius - r) / (2.0 * edge_width) + 0.5;\r\n    let t_clamped = clamp(t, 0.0, 1.0);\r\n    \r\n    // Raised cosine edge\r\n    return 0.5 * (1.0 + cos(PI * (1.0 - t_clamped)));\r\n}\r\n\r\n// Raised cosine filter for band limiting\r\nfn raised_cosine_filter(freq: vec2<f32>) -> f32 {\r\n    let freq_mag = length(freq);\r\n    let cutoff = min(freq_params.fx_max, freq_params.fy_max) * freq_params.bandwidth_limit;\r\n    let transition_width = cutoff * freq_params.raised_cosine_width;\r\n    \r\n    if (freq_mag < cutoff - transition_width) {\r\n        return 1.0;\r\n    } else if (freq_mag > cutoff + transition_width) {\r\n        return 0.0;\r\n    }\r\n    \r\n    // Raised cosine transition\r\n    let t = (freq_mag - cutoff + transition_width) / (2.0 * transition_width);\r\n    return 0.5 * (1.0 + cos(PI * t));\r\n}\r\n\r\n// Angular Spectrum transfer function with evanescent wave handling\r\nfn angular_spectrum_transfer(fx: f32, fy: f32) -> vec2<f32> {\r\n    let k = prop_params.k;\r\n    let kx = TWO_PI * fx;  // Convert to rad/mm\r\n    let ky = TWO_PI * fy;\r\n    \r\n    let k_squared = k * k;\r\n    let kxy_squared = kx * kx + ky * ky;\r\n    let kz_squared = k_squared - kxy_squared;\r\n    \r\n    if (kz_squared <= 0.0) {\r\n        // Evanescent waves - exponential decay\r\n        let kz_imag = sqrt(-kz_squared);\r\n        let decay = exp(-kz_imag * prop_params.distance);\r\n        \r\n        // Cutoff for numerical stability\r\n        return vec2<f32>(select(0.0, decay, decay > 1e-8), 0.0);\r\n    }\r\n    \r\n    // Propagating waves\r\n    let kz = sqrt(kz_squared);\r\n    let phase = kz * prop_params.distance;\r\n    return complex_exp_accurate(phase);\r\n}\r\n\r\n// Fresnel transfer function (paraxial approximation)\r\nfn fresnel_transfer(fx: f32, fy: f32) -> vec2<f32> {\r\n    // H(fx,fy) = exp(j * pi * lambda * z * (fx^2 + fy^2))\r\n    let factor = PI * prop_params.wavelength * prop_params.distance;\r\n    let freq_squared = fx * fx + fy * fy;\r\n    let phase = factor * freq_squared;\r\n    \r\n    return complex_exp_accurate(phase);\r\n}\r\n\r\n// Fraunhofer transfer function (far-field)\r\nfn fraunhofer_transfer(fx: f32, fy: f32) -> vec2<f32> {\r\n    // Additional quadratic phase factor for far-field\r\n    let factor = -PI * prop_params.distance * prop_params.inv_wavelength;\r\n    let freq_squared = fx * fx + fy * fy;\r\n    let phase = factor * freq_squared;\r\n    \r\n    // Include Fresnel integral normalization\r\n    let fresnel_factor = complex_exp_accurate(PI * 0.25); // exp(jpi/4)\r\n    return complex_multiply_fma(complex_exp_accurate(phase), fresnel_factor);\r\n}\r\n\r\n// Compute transfer function with method selection\r\n@compute @workgroup_size(WORKGROUP_SIZE, WORKGROUP_SIZE, 1)\r\nfn compute_transfer_function(@builtin(global_invocation_id) global_id: vec3<u32>,\r\n                           @builtin(local_invocation_id) local_id: vec3<u32>) {\r\n    let coord = vec2<i32>(global_id.xy);\r\n    let dims = textureDimensions(transfer_function);\r\n    \r\n    if (any(coord >= vec2<i32>(dims))) {\r\n        return;\r\n    }\r\n    \r\n    // Get physical spatial frequency\r\n    let freq = get_spatial_frequency_physical(coord, dims);\r\n    \r\n    // Determine method (auto-select if method == 3)\r\n    var selected_method = prop_params.method;\r\n    if (selected_method == 3u) {\r\n        // Auto-select based on Fresnel number\r\n        if (prop_params.fresnel_number > 100.0) {\r\n            selected_method = 0u; // Angular Spectrum for near-field\r\n        } else if (prop_params.fresnel_number > 1.0) {\r\n            selected_method = 1u; // Fresnel for medium distances\r\n        } else {\r\n            selected_method = 2u; // Fraunhofer for far-field\r\n        }\r\n    }\r\n    \r\n    // Compute transfer function based on selected method\r\n    var transfer: vec2<f32>;\r\n    switch (selected_method) {\r\n        case 0u: {\r\n            transfer = angular_spectrum_transfer(freq.x, freq.y);\r\n        }\r\n        case 1u: {\r\n            transfer = fresnel_transfer(freq.x, freq.y);\r\n        }\r\n        case 2u: {\r\n            transfer = fraunhofer_transfer(freq.x, freq.y);\r\n        }\r\n        default: {\r\n            // Fallback to identity\r\n            transfer = vec2<f32>(1.0, 0.0);\r\n        }\r\n    }\r\n    \r\n    // Apply band limiting with raised cosine filter\r\n    if (prop_params.use_band_limiting != 0u) {\r\n        let band_filter = raised_cosine_filter(freq);\r\n        transfer *= band_filter;\r\n    }\r\n    \r\n    // Add phase noise for partial coherence simulation\r\n    if (prop_params.noise_amount > 0.0) {\r\n        let noise = gaussian_noise(prop_params.prng_seed, global_id.xy);\r\n        let phase_noise = noise.x * prop_params.noise_amount * PI;\r\n        let noise_phasor = complex_exp_accurate(phase_noise);\r\n        transfer = complex_multiply_fma(transfer, noise_phasor);\r\n    }\r\n    \r\n    // Store in shared memory for potential reuse with bounds checking\r\n    let local_idx = local_id.y * WORKGROUP_SIZE + local_id.x;\r\n    if (local_idx < SHARED_SIZE) {\r\n        shared_transfer[local_idx] = vec4<f32>(transfer, 0.0, 1.0);\r\n    }\r\n    \r\n    // Write to global memory\r\n    textureStore(transfer_function, coord, vec4<f32>(transfer, 0.0, 0.0));\r\n}\r\n\r\n// Main propagation kernel with proper normalization\r\n@compute @workgroup_size(WORKGROUP_SIZE, WORKGROUP_SIZE, 1)\r\nfn propagate(@builtin(global_invocation_id) global_id: vec3<u32>) {\r\n    let coord = vec2<i32>(global_id.xy);\r\n    let dims = textureDimensions(frequency_domain);\r\n    \r\n    if (any(coord >= vec2<i32>(dims))) {\r\n        return;\r\n    }\r\n    \r\n    // Read frequency domain field\r\n    let field_freq = textureLoad(frequency_domain, vec2<u32>(coord)).xy;\r\n    \r\n    // Read precomputed transfer function\r\n    let transfer = textureLoad(transfer_function, vec2<u32>(coord)).xy;\r\n    \r\n    // Apply transfer function\r\n    var propagated = complex_multiply_fma(field_freq, transfer);\r\n    \r\n    // Apply normalization\r\n    if (norm_params.energy_conservation != 0u) {\r\n        // Energy conservation: scale by sqrt of Jacobian for coordinate transform\r\n        let jacobian = prop_params.distance * prop_params.wavelength;\r\n        propagated *= sqrt(jacobian);\r\n    }\r\n    \r\n    // FFT normalization (forward transform uses 1/N, inverse uses 1)\r\n    propagated *= norm_params.fft_normalization;\r\n    \r\n    // Amplitude scaling\r\n    propagated *= prop_params.amplitude_scale;\r\n    \r\n    // Store result\r\n    textureStore(frequency_domain, vec2<u32>(coord), vec4<f32>(propagated, 0.0, 0.0));\r\n}\r\n\r\n// Post-processing with aperture and coherence effects\r\n@compute @workgroup_size(WORKGROUP_SIZE, WORKGROUP_SIZE, 1)\r\nfn post_process(@builtin(global_invocation_id) global_id: vec3<u32>) {\r\n    let coord = vec2<i32>(global_id.xy);\r\n    let dims = textureDimensions(output_field);\r\n    \r\n    if (any(coord >= vec2<i32>(dims))) {\r\n        return;\r\n    }\r\n    \r\n    // Read propagated field\r\n    var field = textureLoad(output_field, vec2<u32>(coord)).xy;\r\n    \r\n    // Apply physical aperture if requested\r\n    if (prop_params.apply_aperture != 0u) {\r\n        let aperture = apply_physical_aperture(vec2<f32>(coord), vec2<f32>(dims));\r\n        field *= aperture;\r\n    }\r\n    \r\n    // Simulate partial coherence with correlation function\r\n    if (prop_params.coherence_length > 0.0 && prop_params.coherence_length < 1000.0) {\r\n        let correlation_distance = prop_params.coherence_length / prop_params.pixel_size;\r\n        let coherence_kernel = exp(-length(vec2<f32>(coord) - vec2<f32>(dims) * 0.5) / correlation_distance);\r\n        field *= coherence_kernel;\r\n    }\r\n    \r\n    // Clamp for numerical stability\r\n    let mag = length(field);\r\n    if (mag > 100.0) {\r\n        field = field * (100.0 / mag);\r\n    }\r\n    \r\n    textureStore(output_field, vec2<u32>(coord), vec4<f32>(field, 0.0, 0.0));\r\n}\r\n\r\n// Multi-wavelength propagation with proper spectral weighting\r\n@group(2) @binding(2) var<storage, read> wavelengths: array<f32>;\r\n@group(2) @binding(3) var<storage, read> spectral_weights: array<f32>;\r\n@compute @workgroup_size(WORKGROUP_SIZE, WORKGROUP_SIZE, 1)\r\nfn propagate_multi_wavelength(@builtin(global_invocation_id) global_id: vec3<u32>) {\r\n    let coord = vec2<i32>(global_id.xy);\r\n    let dims = textureDimensions(frequency_domain);\r\n    \r\n    if (any(coord >= vec2<i32>(dims))) {\r\n        return;\r\n    }\r\n    \r\n    let num_wavelengths = norm_params.num_wavelengths;\r\n    var accumulated_field = vec2<f32>(0.0);\r\n    \r\n    // Get spatial frequency once\r\n    let freq = get_spatial_frequency_physical(coord, dims);\r\n    \r\n    // Unroll loop for small wavelength counts\r\n    if (num_wavelengths <= 4u) {\r\n        // Unrolled version for RGB or RGBA\r\n        for (var i = 0u; i < num_wavelengths; i++) {\r\n            let wavelength = wavelengths[clamp_index_dyn(i, arrayLength(&wavelengths))];\r\n            let weight = spectral_weights[clamp_index_dyn(i, arrayLength(&spectral_weights))];\r\n            let k = TWO_PI / wavelength;\r\n            \r\n            // Read frequency domain field for this wavelength channel\r\n            let field_freq = textureLoad(frequency_domain, vec2<u32>(coord)).xy;\r\n            \r\n            // Compute wavelength-specific transfer function\r\n            var transfer: vec2<f32>;\r\n            switch (prop_params.method) {\r\n                case 0u: {\r\n                    // Angular spectrum with wavelength-specific k\r\n                    let kx = TWO_PI * freq.x;\r\n                    let ky = TWO_PI * freq.y;\r\n                    let kz_squared = k * k - kx * kx - ky * ky;\r\n                    \r\n                    if (kz_squared > 0.0) {\r\n                        let kz = sqrt(kz_squared);\r\n                        let phase = kz * prop_params.distance;\r\n                        transfer = complex_exp_accurate(phase);\r\n                    } else {\r\n                        transfer = vec2<f32>(0.0);\r\n                    }\r\n                }\r\n                case 1u: {\r\n                    // Fresnel with wavelength\r\n                    let phase = PI * wavelength * prop_params.distance * dot(freq, freq);\r\n                    transfer = complex_exp_accurate(phase);\r\n                }\r\n                default: {\r\n                    transfer = vec2<f32>(1.0, 0.0);\r\n                }\r\n            }\r\n            \r\n            // Accumulate weighted contribution\r\n            accumulated_field += complex_multiply_fma(field_freq, transfer) * weight;\r\n        }\r\n    } else {\r\n        // General loop for many wavelengths\r\n        for (var i = 0u; i < num_wavelengths; i++) {\r\n            let wavelength = wavelengths[clamp_index_dyn(i, arrayLength(&wavelengths))];\r\n            let weight = spectral_weights[clamp_index_dyn(i, arrayLength(&spectral_weights))];\r\n            let k = TWO_PI / wavelength;\r\n            \r\n            // Read frequency domain field for this wavelength channel\r\n            let field_freq = textureLoad(frequency_domain, vec2<u32>(coord)).xy;\r\n            \r\n            // Compute wavelength-specific transfer function\r\n            var transfer: vec2<f32>;\r\n            switch (prop_params.method) {\r\n                case 0u: {\r\n                    // Angular spectrum with wavelength-specific k\r\n                    let kx = TWO_PI * freq.x;\r\n                    let ky = TWO_PI * freq.y;\r\n                    let kz_squared = k * k - kx * kx - ky * ky;\r\n                    \r\n                    if (kz_squared > 0.0) {\r\n                        let kz = sqrt(kz_squared);\r\n                        let phase = kz * prop_params.distance;\r\n                        transfer = complex_exp_accurate(phase);\r\n                    } else {\r\n                        transfer = vec2<f32>(0.0);\r\n                    }\r\n                }\r\n                case 1u: {\r\n                    // Fresnel with wavelength\r\n                    let phase = PI * wavelength * prop_params.distance * dot(freq, freq);\r\n                    transfer = complex_exp_accurate(phase);\r\n                }\r\n                default: {\r\n                    transfer = vec2<f32>(1.0, 0.0);\r\n                }\r\n            }\r\n            \r\n            // Accumulate weighted contribution\r\n            accumulated_field += complex_multiply_fma(field_freq, transfer) * weight;\r\n        }\r\n    }\r\n    \r\n    // Normalize by spectral weight sum\r\n    accumulated_field /= norm_params.spectral_weight_sum;\r\n    \r\n    textureStore(frequency_domain, vec2<u32>(coord), vec4<f32>(accumulated_field, 0.0, 0.0));\r\n}\r\n\r\n// Debug visualization kernels\r\n@compute @workgroup_size(WORKGROUP_SIZE, WORKGROUP_SIZE, 1)\r\nfn visualize_magnitude(@builtin(global_invocation_id) global_id: vec3<u32>) {\r\n    let coord = vec2<i32>(global_id.xy);\r\n    let dims = textureDimensions(output_field);\r\n    \r\n    if (any(coord >= vec2<i32>(dims))) {\r\n        return;\r\n    }\r\n    \r\n    let field = textureLoad(output_field, vec2<u32>(coord)).xy;\r\n    let magnitude = length(field);\r\n    \r\n    // Log scale for better dynamic range\r\n    let log_mag = log(1.0 + magnitude) / log(10.0);\r\n    \r\n    textureStore(debug_magnitude, vec2<u32>(coord), vec4<f32>(log_mag, 0.0, 0.0, 0.0));\r\n}\r\n\r\n@compute @workgroup_size(WORKGROUP_SIZE, WORKGROUP_SIZE, 1)\r\nfn visualize_phase(@builtin(global_invocation_id) global_id: vec3<u32>) {\r\n    let coord = vec2<i32>(global_id.xy);\r\n    let dims = textureDimensions(output_field);\r\n    \r\n    if (any(coord >= vec2<i32>(dims))) {\r\n        return;\r\n    }\r\n    \r\n    let field = textureLoad(output_field, vec2<u32>(coord)).xy;\r\n    let phase = atan2(field.y, field.x);\r\n    \r\n    // Normalize to [0, 1] for visualization\r\n    let normalized_phase = (phase + PI) * INV_TWO_PI;\r\n    \r\n    textureStore(debug_phase, vec2<u32>(coord), vec4<f32>(normalized_phase, 0.0, 0.0, 0.0));\r\n}\r\n\r\n// Integration point for multi-view synthesis\r\n// This kernel prepares the propagated field for view generation\r\n@group(2) @binding(4) var multiview_buffer: texture_storage_2d<rg32float, write>;\r\n\r\n@compute @workgroup_size(WORKGROUP_SIZE, WORKGROUP_SIZE, 1)\r\nfn prepare_for_multiview(@builtin(global_invocation_id) global_id: vec3<u32>) {\r\n    let coord = vec2<i32>(global_id.xy);\r\n    let dims = textureDimensions(output_field);\r\n    \r\n    if (any(coord >= vec2<i32>(dims))) {\r\n        return;\r\n    }\r\n    \r\n    // Read propagated field\r\n    let field = textureLoad(output_field, vec2<u32>(coord)).xy;\r\n    \r\n    // Apply any final transformations needed for multi-view\r\n    // This could include coordinate remapping, additional phase factors, etc.\r\n    var transformed_field = field;\r\n    \r\n    // Example: Add linear phase ramp for off-axis viewing\r\n    // const view_angle = 0.1; // radians\r\n    // let kx = prop_params.k * sin(view_angle);\r\n    // let x_pos = f32(coord.x) * prop_params.pixel_size;\r\n    // let phase_ramp = kx * x_pos;\r\n    // transformed_field = complex_multiply_fma(field, complex_exp_accurate(phase_ramp));\r\n    \r\n    // Write to multi-view buffer\r\n    textureStore(multiview_buffer, vec2<u32>(coord), vec4<f32>(transformed_field, 0.0, 0.0));\r\n}\r\n";

// Shader: quantum_superposition.wgsl
// Purpose: No description
export const quantum_superposition_wgsl = "// quantum_superposition.wgsl\n// Linear superposition with unitary mixing - pure math, no quantum hardware needed\n// Creates quantum-inspired holographic states\n\nstruct Params { \n    width: u32,\n    height: u32,\n    states: u32,        // Number of states to superpose\n    coherence: f32,     // Coherence between states (0-1)\n    phase_offset: f32,  // Global phase offset\n    entanglement: f32,  // Entanglement strength (0-1)\n}\n\n@group(0) @binding(0) var<uniform> p: Params;\n@group(0) @binding(1) var<storage, read> inStates: array<vec2<f32>>;   // [states * W*H]\n@group(0) @binding(2) var<storage, read> weights: array<vec2<f32>>;    // [states] complex amplitudes\n@group(0) @binding(3) var<storage, read_write> outField: array<vec2<f32>>;\n\n// Complex operations\nfn c_add(a: vec2<f32>, b: vec2<f32>) -> vec2<f32> { \n    return a + b; \n}\n\nfn c_mul(a: vec2<f32>, b: vec2<f32>) -> vec2<f32> {\n    return vec2<f32>(a.x*b.x - a.y*b.y, a.x*b.y + a.y*b.x);\n}\n\nfn c_conj(a: vec2<f32>) -> vec2<f32> {\n    return vec2<f32>(a.x, -a.y);\n}\n\nfn c_from_phase(phi: f32) -> vec2<f32> {\n    return vec2<f32>(cos(phi), sin(phi));\n}\n\n// Quantum-inspired entanglement operator\nfn entangle_states(state1: vec2<f32>, state2: vec2<f32>, strength: f32) -> vec2<f32> {\n    // Create Bell-like state: |ψ⟩ = α|00⟩ + β|11⟩\n    let bell_component = c_mul(state1, state2);\n    return mix(state1, bell_component, strength);\n}\n\n@compute @workgroup_size(8, 8, 1)\nfn main(@builtin(global_invocation_id) gid: vec3<u32>) {\n    if (gid.x >= p.width || gid.y >= p.height) { \n        return; \n    }\n    let wh = p.width * p.height;\n    let idx = gid.y * p.width + gid.x;\n    \n    var acc = vec2<f32>(0.0, 0.0);\n    var norm = 0.0;\n    \n    // Superpose all states with proper quantum amplitudes\n    for (var s = 0u; s < p.states; s = s + 1u) {\n        // Get complex weight for this state\n        var w = vec2<f32>(1.0, 0.0);\n        if (s < arrayLength(&weights)) {\n            w = weights[s];\n        }\n        \n        // Apply coherence decay\n        let coherence_factor = pow(p.coherence, f32(s));\n        w = w * coherence_factor;\n        \n        // Get the field for this state\n        let state_idx = s * wh + idx;\n        var f = vec2<f32>(0.0, 0.0);\n        if (state_idx < arrayLength(&inStates)) {\n            f = inStates[state_idx];\n        }\n        \n        // Apply phase evolution\n        let phase = p.phase_offset * f32(s);\n        f = c_mul(f, c_from_phase(phase));\n        \n        // Entangle with previous state if requested\n        if (s > 0u && p.entanglement > 0.0) {\n            let prev_idx = (s - 1u) * wh + idx;\n            if (prev_idx < arrayLength(&inStates)) {\n                let prev_state = inStates[prev_idx];\n                f = entangle_states(f, prev_state, p.entanglement);\n            }\n        }\n        \n        // Accumulate with weight\n        acc = c_add(acc, c_mul(w, f));\n        norm += length(w) * length(w);\n    }\n    \n    // Normalize to preserve unitarity\n    if (norm > 0.0) {\n        acc = acc / sqrt(norm);\n    }\n    \n    outField[idx] = acc;\n}\n\n// Create GHZ state (generalized entangled state)\n@compute @workgroup_size(8, 8, 1)\nfn create_ghz_state(@builtin(global_invocation_id) gid: vec3<u32>) {\n    if (gid.x >= p.width || gid.y >= p.height) { \n        return; \n    }\n    let idx = gid.y * p.width + gid.x;\n    \n    // GHZ state: |ψ⟩ = (|000...⟩ + |111...⟩)/√2\n    var ghz = vec2<f32>(0.0, 0.0);\n    let wh = p.width * p.height;\n    \n    // All zeros component\n    if (idx < arrayLength(&inStates)) {\n        ghz = inStates[idx];  // First state\n    }\n    \n    // All ones component\n    let last_state_idx = (p.states - 1u) * wh + idx;\n    if (last_state_idx < arrayLength(&inStates)) {\n        ghz = c_add(ghz, inStates[last_state_idx]);\n    }\n    \n    // Normalize\n    ghz = ghz * 0.70710678118; // 1/√2\n    \n    outField[idx] = ghz;\n}";

// Shader: roi_interest_map.wgsl
// Purpose: No description
export const roi_interest_map_wgsl = "// roi_interest_map.wgsl\n// Input: currField, prevField as complex vec2<f32> per pixel\n// Output: interestMap (f32) per pixel, 0..+\n// ENHANCED: Proper circular variance + shared memory for Sobel\n\nstruct Params {\n    width: u32,\n    height: u32,\n    pad0: u32,\n    pad1: u32,\n    w_grad: f32,\n    w_temp: f32,\n    w_phase: f32,\n    k_norm: f32,  // small stabilizer (e.g., 1e-3)\n}\n\n@group(0) @binding(0) var<uniform> P: Params;\n@group(0) @binding(1) var<storage, read> currField: array<vec2<f32>>;\n@group(0) @binding(2) var<storage, read> prevField: array<vec2<f32>>;\n@group(0) @binding(3) var<storage, read_write> interest: array<f32>;\n\n// Shared memory for 10x10 tile (8x8 + 1-pixel border)\nvar<workgroup> tile_curr: array<vec2<f32>, 100>;\nvar<workgroup> tile_prev: array<vec2<f32>, 100>;\n\nfn idx(x: i32, y: i32) -> u32 {\n    let xi = clamp(x, 0, i32(P.width) - 1);\n    let yi = clamp(y, 0, i32(P.height) - 1);\n    return u32(yi) * P.width + u32(xi);\n}\n\nfn loadTile(lx: u32, ly: u32, gx: i32, gy: i32) {\n    let id = idx(gx, gy);\n    let tile_idx = ly * 10u + lx;\n    tile_curr[tile_idx] = currField[id];\n    tile_prev[tile_idx] = prevField[id];\n}\n\n@compute @workgroup_size(8, 8, 1)\nfn main(\n    @builtin(global_invocation_id) gid: vec3<u32>,\n    @builtin(local_invocation_id) lid: vec3<u32>\n) {\n    if (gid.x >= P.width || gid.y >= P.height) { return; }\n    \n    let gx = i32(gid.x);\n    let gy = i32(gid.y);\n    \n    // Cooperative loading with 1-pixel halo\n    let lx = lid.x + 1u;\n    let ly = lid.y + 1u;\n    \n    // Load main pixel\n    loadTile(lx, ly, gx, gy);\n    \n    // Load borders\n    if (lid.x == 0u) {\n        loadTile(0u, ly, gx - 1, gy);      // Left border\n    }\n    if (lid.x == 7u) {\n        loadTile(9u, ly, gx + 1, gy);      // Right border\n    }\n    if (lid.y == 0u) {\n        loadTile(lx, 0u, gx, gy - 1);      // Top border\n    }\n    if (lid.y == 7u) {\n        loadTile(lx, 9u, gx, gy + 1);      // Bottom border\n    }\n    \n    // Load corners\n    if (lid.x == 0u && lid.y == 0u) { loadTile(0u, 0u, gx - 1, gy - 1); }\n    if (lid.x == 7u && lid.y == 0u) { loadTile(9u, 0u, gx + 1, gy - 1); }\n    if (lid.x == 0u && lid.y == 7u) { loadTile(0u, 9u, gx - 1, gy + 1); }\n    if (lid.x == 7u && lid.y == 7u) { loadTile(9u, 9u, gx + 1, gy + 1); }\n    \n    workgroupBarrier();\n    \n    // Now compute using shared memory\n    let c = tile_curr[ly * 10u + lx];\n    let p = tile_prev[ly * 10u + lx];\n    \n    // Temporal delta (magnitude change)\n    let temporal = abs(length(c) - length(p));\n    \n    // Sobel gradient on magnitude using shared memory\n    var gx_sobel = 0.0;\n    var gy_sobel = 0.0;\n    \n    for (var j = -1; j <= 1; j = j + 1) {\n        for (var i = -1; i <= 1; i = i + 1) {\n            let tile_idx = u32(i32(ly) + j) * 10u + u32(i32(lx) + i);\n            let mag = length(tile_curr[tile_idx]);\n            \n            // Sobel X kernel: [-1 0 1; -2 0 2; -1 0 1]\n            let wx = f32(i) * (1.0 + f32(abs(j) == 0));\n            gx_sobel += mag * wx;\n            \n            // Sobel Y kernel: [-1 -2 -1; 0 0 0; 1 2 1]\n            let wy = f32(j) * (1.0 + f32(abs(i) == 0));\n            gy_sobel += mag * wy;\n        }\n    }\n    \n    let gradient = sqrt(gx_sobel * gx_sobel + gy_sobel * gy_sobel);\n    \n    // ENHANCED: Circular variance using von Mises distribution\n    // Compute mean direction and concentration parameter\n    var sum_cos = 0.0;\n    var sum_sin = 0.0;\n    var sum_mag = 0.0;\n    \n    for (var j = -1; j <= 1; j = j + 1) {\n        for (var i = -1; i <= 1; i = i + 1) {\n            let tile_idx = u32(i32(ly) + j) * 10u + u32(i32(lx) + i);\n            let z = tile_curr[tile_idx];\n            let mag = length(z);\n            if (mag > 1e-6) {\n                let phase = atan2(z.y, z.x);\n                sum_cos += cos(phase) * mag;\n                sum_sin += sin(phase) * mag;\n                sum_mag += mag;\n            }\n        }\n    }\n    \n    // Mean resultant length (0 = high variance, 1 = low variance)\n    let R = sqrt(sum_cos * sum_cos + sum_sin * sum_sin) / max(sum_mag, 1e-6);\n    \n    // Circular variance: V = 1 - R\n    // But we want high values for high variance, so use 1 - R\n    let phasevar = 1.0 - R;\n    \n    // Angular deviation bonus: penalize rapid phase changes\n    let center_phase = atan2(c.y, c.x);\n    var phase_dev = 0.0;\n    for (var j = -1; j <= 1; j = j + 1) {\n        for (var i = -1; i <= 1; i = i + 1) {\n            if (i == 0 && j == 0) { continue; }\n            let tile_idx = u32(i32(ly) + j) * 10u + u32(i32(lx) + i);\n            let z = tile_curr[tile_idx];\n            if (length(z) > 1e-6) {\n                let neighbor_phase = atan2(z.y, z.x);\n                var diff = neighbor_phase - center_phase;\n                // Wrap to [-PI, PI]\n                diff = diff - round(diff / (2.0 * 3.14159265)) * 2.0 * 3.14159265;\n                phase_dev += abs(diff);\n            }\n        }\n    }\n    phase_dev /= 8.0;  // Average over 8 neighbors\n    \n    // Combine phase variance and deviation\n    let phase_metric = phasevar * 0.7 + (phase_dev / 3.14159265) * 0.3;\n    \n    // Soft normalization\n    let gN = gradient / (gradient + P.k_norm);\n    let tN = temporal / (temporal + P.k_norm);\n    \n    // Final interest score\n    let id = gid.y * P.width + gid.x;\n    interest[id] = P.w_grad * gN + P.w_temp * tN + P.w_phase * phase_metric;\n}";

// Shader: roi_map.wgsl
// Purpose: No description
export const roi_map_wgsl = "// roi_map.wgsl\n// Generates Region of Interest map for selective tile offloading\n// Combines gradient (Sobel), temporal delta, and phase variance metrics\n\nstruct ROIParams {\n    width: u32,\n    height: u32,\n    tile_size: u32,        // 2, 4, or 8 for reduction\n    temporal_weight: f32,  // Weight for temporal change\n    gradient_weight: f32,  // Weight for spatial gradient\n    phase_weight: f32,     // Weight for phase variance\n    threshold: f32,        // Energy threshold for \"interesting\"\n}\n\n@group(0) @binding(0) var<uniform> params: ROIParams;\n@group(0) @binding(1) var<storage, read> currentField: array<vec2<f32>>;\n@group(0) @binding(2) var<storage, read> previousField: array<vec2<f32>>;\n@group(0) @binding(3) var<storage, read_write> roiMap: array<f32>; // Energy per tile\n\n// Sobel kernels for gradient\nconst SOBEL_X = array<f32, 9>(-1.0, 0.0, 1.0, -2.0, 0.0, 2.0, -1.0, 0.0, 1.0);\nconst SOBEL_Y = array<f32, 9>(-1.0, -2.0, -1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 1.0);\n\nfn sample_field(field: ptr<storage, array<vec2<f32>>, read>, x: i32, y: i32) -> vec2<f32> {\n    let xi = clamp(x, 0, i32(params.width) - 1);\n    let yi = clamp(y, 0, i32(params.height) - 1);\n    let idx = u32(yi) * params.width + u32(xi);\n    if (idx < arrayLength(field)) {\n        return (*field)[idx];\n    }\n    return vec2<f32>(0.0, 0.0);\n}\n\nfn compute_gradient_energy(x: i32, y: i32) -> f32 {\n    var gx = 0.0;\n    var gy = 0.0;\n    var kernel_idx = 0;\n    \n    // Apply Sobel operator\n    for (var dy = -1; dy <= 1; dy++) {\n        for (var dx = -1; dx <= 1; dx++) {\n            let field = sample_field(&currentField, x + dx, y + dy);\n            let mag = length(field);\n            gx += mag * SOBEL_X[kernel_idx];\n            gy += mag * SOBEL_Y[kernel_idx];\n            kernel_idx++;\n        }\n    }\n    \n    return sqrt(gx * gx + gy * gy);\n}\n\nfn compute_temporal_delta(idx: u32) -> f32 {\n    if (idx >= arrayLength(&currentField) || idx >= arrayLength(&previousField)) {\n        return 0.0;\n    }\n    let curr = currentField[idx];\n    let prev = previousField[idx];\n    return length(curr - prev);\n}\n\nfn compute_phase_variance(x: i32, y: i32, tile_size: i32) -> f32 {\n    var mean_phase = 0.0;\n    var count = 0.0;\n    \n    // First pass: compute mean phase\n    for (var dy = 0; dy < tile_size; dy++) {\n        for (var dx = 0; dx < tile_size; dx++) {\n            let field = sample_field(&currentField, x + dx, y + dy);\n            mean_phase += atan2(field.y, field.x);\n            count += 1.0;\n        }\n    }\n    mean_phase /= count;\n    \n    // Second pass: compute variance\n    var variance = 0.0;\n    for (var dy = 0; dy < tile_size; dy++) {\n        for (var dx = 0; dx < tile_size; dx++) {\n            let field = sample_field(&currentField, x + dx, y + dy);\n            let phase = atan2(field.y, field.x);\n            let diff = phase - mean_phase;\n            variance += diff * diff;\n        }\n    }\n    \n    return sqrt(variance / count);\n}\n\n@compute @workgroup_size(8, 8, 1)\nfn main(@builtin(global_invocation_id) gid: vec3<u32>) {\n    let tiles_x = params.width / params.tile_size;\n    let tiles_y = params.height / params.tile_size;\n    \n    if (gid.x >= tiles_x || gid.y >= tiles_y) {\n        return;\n    }\n    \n    let tile_x = i32(gid.x * params.tile_size);\n    let tile_y = i32(gid.y * params.tile_size);\n    \n    var total_energy = 0.0;\n    \n    // Accumulate energy metrics over the tile\n    for (var dy = 0; dy < i32(params.tile_size); dy++) {\n        for (var dx = 0; dx < i32(params.tile_size); dx++) {\n            let x = tile_x + dx;\n            let y = tile_y + dy;\n            let idx = u32(y) * params.width + u32(x);\n            \n            // Gradient energy (Sobel)\n            let gradient = compute_gradient_energy(x, y);\n            \n            // Temporal delta\n            let temporal = compute_temporal_delta(idx);\n            \n            // Combine metrics\n            let pixel_energy = gradient * params.gradient_weight + \n                              temporal * params.temporal_weight;\n            total_energy += pixel_energy;\n        }\n    }\n    \n    // Add phase variance for the whole tile\n    let phase_var = compute_phase_variance(tile_x, tile_y, i32(params.tile_size));\n    total_energy += phase_var * params.phase_weight;\n    \n    // Normalize by tile area\n    total_energy /= f32(params.tile_size * params.tile_size);\n    \n    //";

// Shader: schrodinger_biharmonic.wgsl
// Purpose: No description
export const schrodinger_biharmonic_wgsl = "// schrodinger_biharmonic.wgsl\n// Proper 13-point stencil + shared memory optimization\n// 2-3x faster than recomputing Laplacians!\n\nstruct Params {\n    width: u32,\n    height: u32,\n    pad0: u32,\n    pad1: u32,\n    dt: f32,\n    alpha: f32,      // Kinetic term coefficient  \n    beta: f32,       // Dispersion coefficient\n    vscale: f32,     // Potential strength\n}\n\n@group(0) @binding(0) var<uniform> P: Params;\n@group(0) @binding(1) var<storage, read> inField: array<vec2<f32>>;\n@group(0) @binding(2) var<storage, read_write> outField: array<vec2<f32>>;\n@group(0) @binding(3) var potential: texture_2d<f32>;\n@group(0) @binding(4) var samp: sampler;\n\n// Shared memory for 12x12 tile (8x8 work + 2-pixel halo each side)\nvar<workgroup> tile: array<vec2<f32>, 144>; // 12x12\n\nfn loadTile(lx: u32, ly: u32, gx: i32, gy: i32) {\n    // Load with boundary clamping\n    let xi = clamp(gx, 0, i32(P.width) - 1);\n    let yi = clamp(gy, 0, i32(P.height) - 1);\n    let idx = u32(yi) * P.width + u32(xi);\n    tile[ly * 12u + lx] = inField[idx];\n}\n\n@compute @workgroup_size(8, 8, 1)\nfn main(\n    @builtin(global_invocation_id) gid: vec3<u32>,\n    @builtin(local_invocation_id) lid: vec3<u32>\n) {\n    if (gid.x >= P.width || gid.y >= P.height) { return; }\n    \n    let gx = i32(gid.x);\n    let gy = i32(gid.y);\n    \n    // Cooperative loading: each thread loads its main pixel + halos\n    let lx = lid.x + 2u;  // Offset by halo\n    let ly = lid.y + 2u;\n    \n    // Load main pixel\n    loadTile(lx, ly, gx, gy);\n    \n    // Load halos cooperatively (edges only)\n    if (lid.x < 2u) {\n        loadTile(lid.x, ly, gx - 2, gy);           // Left halo\n        loadTile(lid.x + 10u, ly, gx + 6, gy);     // Right halo\n    }\n    if (lid.y < 2u) {\n        loadTile(lx, lid.y, gx, gy - 2);           // Top halo\n        loadTile(lx, lid.y + 10u, gx, gy + 6);     // Bottom halo\n    }\n    if (lid.x < 2u && lid.y < 2u) {\n        loadTile(lid.x, lid.y, gx - 2, gy - 2);                    // Top-left corner\n        loadTile(lid.x + 10u, lid.y, gx + 6, gy - 2);             // Top-right corner\n        loadTile(lid.x, lid.y + 10u, gx - 2, gy + 6);             // Bottom-left corner\n        loadTile(lid.x + 10u, lid.y + 10u, gx + 6, gy + 6);       // Bottom-right corner\n    }\n    \n    workgroupBarrier();\n    \n    // Now compute using shared memory\n    let c = tile[ly * 12u + lx];\n    \n    // 5-point Laplacian (dx = 1)\n    let l1 = tile[ly * 12u + (lx - 1u)];\n    let r1 = tile[ly * 12u + (lx + 1u)];\n    let u1 = tile[(ly - 1u) * 12u + lx];\n    let d1 = tile[(ly + 1u) * 12u + lx];\n    let lap = (l1 + r1 + u1 + d1) - 4.0 * c;\n    \n    // 13-point Biharmonic stencil (more accurate than Lap of Lap!)\n    // Stencil pattern:\n    //       1\n    //    2 -8  2\n    // 1 -8 20 -8 1\n    //    2 -8  2\n    //       1\n    \n    let l2 = tile[ly * 12u + (lx - 2u)];\n    let r2 = tile[ly * 12u + (lx + 2u)];\n    let u2 = tile[(ly - 2u) * 12u + lx];\n    let d2 = tile[(ly + 2u) * 12u + lx];\n    \n    let ul = tile[(ly - 1u) * 12u + (lx - 1u)];\n    let ur = tile[(ly - 1u) * 12u + (lx + 1u)];\n    let dl = tile[(ly + 1u) * 12u + (lx - 1u)];\n    let dr = tile[(ly + 1u) * 12u + (lx + 1u)];\n    \n    let bih = 20.0 * c \n            - 8.0 * (l1 + r1 + u1 + d1)\n            + 2.0 * (ul + ur + dl + dr)\n            + (l2 + r2 + u2 + d2);\n    \n    // Sample potential\n    let uv = vec2<f32>((f32(gid.x) + 0.5) / f32(P.width), \n                       (f32(gid.y) + 0.5) / f32(P.height));\n    let V = textureSampleLevel(potential, samp, uv, 0.0).r * P.vscale;\n    \n    // Hamiltonian: H = -alpha*Lap + beta*Bih + V\n    let H_psi = -P.alpha * lap + P.beta * bih + V * c;\n    \n    // Time evolution: i*dPsi/dt = H*Psi\n    // => dPsi/dt = -i*H*Psi = (H_psi.y, -H_psi.x)\n    let dPsi_dt = vec2<f32>(H_psi.y, -H_psi.x);\n    \n    // Explicit Euler step (use small dt!)\n    let idx = gid.y * P.width + gid.x;\n    outField[idx] = c + P.dt * dPsi_dt;\n}";

// Shader: schrodinger_cranknicolson.wgsl
// Purpose: No description
export const schrodinger_cranknicolson_wgsl = "// schrodinger_cranknicolson.wgsl  \n// Semi-implicit Crank-Nicolson: UNCONDITIONALLY STABLE!\n// Can use dt = 0.5 instead of 0.05!\n\nstruct Params {\n    width: u32,\n    height: u32,\n    iterations: u32,    // Jacobi iterations (5-10 typical)\n    pad0: u32,\n    dt: f32,\n    alpha: f32,\n    beta: f32,\n    omega: f32,        // Over-relaxation factor (1.0-1.8)\n}\n\n@group(0) @binding(0) var<uniform> P: Params;\n@group(0) @binding(1) var<storage, read> inField: array<vec2<f32>>;\n@group(0) @binding(2) var<storage, read_write> tempField: array<vec2<f32>>;  // For iteration\n@group(0) @binding(3) var<storage, read_write> outField: array<vec2<f32>>;\n\nfn idx(x: i32, y: i32) -> u32 {\n    let xi = clamp(x, 0, i32(P.width) - 1);\n    let yi = clamp(y, 0, i32(P.height) - 1);\n    return u32(yi) * P.width + u32(xi);\n}\n\nfn applyH(field: ptr<storage, array<vec2<f32>>, read_write>, x: i32, y: i32) -> vec2<f32> {\n    let c = (*field)[idx(x, y)];\n    \n    // 5-point Laplacian\n    let l = (*field)[idx(x - 1, y)];\n    let r = (*field)[idx(x + 1, y)];\n    let u = (*field)[idx(x, y - 1)];\n    let d = (*field)[idx(x, y + 1)];\n    let lap = (l + r + u + d) - 4.0 * c;\n    \n    // 13-point Biharmonic (simplified for semi-implicit)\n    let l2 = (*field)[idx(x - 2, y)];\n    let r2 = (*field)[idx(x + 2, y)];\n    let u2 = (*field)[idx(x, y - 2)];\n    let d2 = (*field)[idx(x, y + 2)];\n    let bih = 12.0 * c - 4.0 * (l + r + u + d) + (l2 + r2 + u2 + d2);\n    \n    // H*psi = -alpha*lap + beta*bih (ignoring potential for stability)\n    return -P.alpha * lap + P.beta * bih;\n}\n\n@compute @workgroup_size(8, 8, 1)\nfn initialize(@builtin(global_invocation_id) gid: vec3<u32>) {\n    if (gid.x >= P.width || gid.y >= P.height) { return; }\n    let id = gid.y * P.width + gid.x;\n    \n    // Start with explicit Euler guess\n    let x = i32(gid.x);\n    let y = i32(gid.y);\n    let c = inField[id];\n    let H_psi = applyH(&inField, x, y);\n    \n    // i*dPsi/dt = H*Psi => dPsi = -i*H*Psi*dt\n    let dPsi = vec2<f32>(H_psi.y, -H_psi.x) * P.dt;\n    tempField[id] = c + dPsi * 0.5;  // Half-step for Crank-Nicolson\n}\n\n@compute @workgroup_size(8, 8, 1)  \nfn jacobi_iterate(@builtin(global_invocation_id) gid: vec3<u32>) {\n    if (gid.x >= P.width || gid.y >= P.height) { return; }\n    let id = gid.y * P.width + gid.x;\n    let x = i32(gid.x);\n    let y = i32(gid.y);\n    \n    // Crank-Nicolson: (I + dt*H/2)*psi_new = (I - dt*H/2)*psi_old\n    // Rearranged for Jacobi iteration\n    \n    let psi_old = inField[id];\n    let H_old = applyH(&inField, x, y);\n    let rhs = psi_old - vec2<f32>(H_old.y, -H_old.x) * P.dt * 0.5;\n    \n    // Current guess\n    let psi_curr = tempField[id];\n    let H_curr = applyH(&tempField, x, y);\n    \n    // Jacobi update with over-relaxation\n    let residual = rhs - (psi_curr + vec2<f32>(H_curr.y, -H_curr.x) * P.dt * 0.5);\n    let psi_new = psi_curr + residual * P.omega;\n    \n    outField[id] = psi_new;\n}\n\n@compute @workgroup_size(8, 8, 1)\nfn swap_buffers(@builtin(global_invocation_id) gid: vec3<u32>) {\n    if (gid.x >= P.width || gid.y >= P.height) { return; }\n    let id = gid.y * P.width + gid.x;\n    tempField[id] = outField[id];\n}";

// Shader: schrodinger_kspace_multiply.wgsl
// Purpose: No description
export const schrodinger_kspace_multiply_wgsl = "// schrodinger_kspace_multiply.wgsl\n// PLATINUM Edition: K-space evolution with anisotropic dispersion\n// - Support for direction-dependent dispersion\n// - Band limiting for anti-aliasing\n// - Nonlinear corrections\n\nstruct Params {\n    width: u32;\n    height: u32;\n    pad0: u32;\n    pad1: u32;\n    dt: f32;\n    alpha: f32;          // Isotropic kinetic coefficient\n    beta: f32;           // Isotropic biharmonic coefficient\n    dx: f32;             // Spatial resolution x\n    dy: f32;             // Spatial resolution y\n    // ENHANCED: Anisotropic dispersion\n    alpha_x: f32;        // Direction-dependent kinetic\n    alpha_y: f32;\n    beta_x: f32;         // Direction-dependent biharmonic\n    beta_y: f32;\n    // Nonlinear corrections\n    nonlinear_strength: f32;  // For |ψ|²ψ term in k-space\n    band_limit: f32;          // Cutoff frequency (0.5 = Nyquist)\n    filter_order: f32;        // Sharpness of band limiting\n    use_anisotropic: u32;     // 0: isotropic, 1: anisotropic\n}\n\n@group(0) @binding(0) var<uniform> P: Params;\n@group(0) @binding(1) var<storage, read_write> fieldK: array<vec2<f32>>;\n@group(0) @binding(2) var<storage, read> density: array<f32>; // Optional: |ψ|² for nonlinear term\n\nconst PI = 3.14159265359;\nconst TWO_PI = 6.28318530718;\n\n// Convert array index to k-space coordinate\nfn kcoord(i: u32, n: u32, d: f32) -> f32 {\n    let ii = i32(i);\n    let nn = i32(n);\n    // Standard FFT indexing: positive frequencies first, then negative\n    let iw = select(ii, ii - nn, ii > nn / 2);\n    return TWO_PI * (f32(iw) / (f32(n) * d));\n}\n\n// Enhanced k-coordinate with Nyquist handling\nfn kcoord_enhanced(i: u32, n: u32, d: f32) -> f32 {\n    let ii = f32(i);\n    let nn = f32(n);\n    \n    // Handle Nyquist frequency specially for even n\n    if (i == n / 2u && (n & 1u) == 0u) {\n        return PI / d;  // Nyquist frequency\n    }\n    \n    // Standard mapping\n    let k_index = select(ii, ii - nn, ii > nn * 0.5);\n    return TWO_PI * k_index / (nn * d);\n}\n\n// Band limiting filter (smoother than hard cutoff)\nfn band_limit_filter(k_mag: f32, cutoff: f32, order: f32) -> f32 {\n    let k_normalized = k_mag / (PI / min(P.dx, P.dy));  // Normalize to Nyquist\n    \n    if (k_normalized <= cutoff) {\n        return 1.0;\n    }\n    \n    if (order < 0.5) {\n        // Hard cutoff\n        return 0.0;\n    }\n    \n    // Smooth cutoff using super-Gaussian\n    let excess = (k_normalized - cutoff) / (1.0 - cutoff);\n    return exp(-pow(excess * 2.0, order));\n}\n\n// Complex operations\nfn complex_multiply(a: vec2<f32>, b: vec2<f32>) -> vec2<f32> {\n    return vec2<f32>(\n        a.x * b.x - a.y * b.y,\n        a.x * b.y + a.y * b.x\n    );\n}\n\nfn complex_exp_stable(phase: f32) -> vec2<f32> {\n    // Stability for large phase values\n    let reduced = phase - floor(phase / TWO_PI) * TWO_PI;\n    \n    // Use Taylor series for small angles (better accuracy)\n    if (abs(reduced) < 0.1) {\n        let p2 = reduced * reduced;\n        let p3 = p2 * reduced;\n        let p4 = p2 * p2;\n        let p5 = p4 * reduced;\n        \n        let cos_approx = 1.0 - p2 * 0.5 + p4 * 0.041666667;\n        let sin_approx = reduced - p3 * 0.166666667 + p5 * 0.008333333;\n        \n        return vec2<f32>(cos_approx, sin_approx);\n    }\n    \n    return vec2<f32>(cos(reduced), sin(reduced));\n}\n\n@compute @workgroup_size(8, 8, 1)\nfn main(@builtin(global_invocation_id) gid: vec3<u32>) {\n    if (gid.x >= P.width || gid.y >= P.height) { return; }\n    \n    let id = gid.y * P.width + gid.x;\n    \n    // Get k-space coordinates\n    let kx = kcoord_enhanced(gid.x, P.width, P.dx);\n    let ky = kcoord_enhanced(gid.y, P.height, P.dy);\n    \n    // Calculate dispersion based on mode\n    var phase: f32;\n    \n    if (P.use_anisotropic == 1u) {\n        // Anisotropic dispersion\n        let kx2 = kx * kx;\n        let ky2 = ky * ky;\n        let kx4 = kx2 * kx2;\n        let ky4 = ky2 * ky2;\n        \n        // Direction-dependent coefficients\n        let kinetic_term = P.alpha_x * kx2 + P.alpha_y * ky2;\n        let biharmonic_term = P.beta_x * kx4 + P.beta_y * ky4;\n        \n        // Cross terms for full anisotropy\n        let cross_term = 2.0 * sqrt(P.beta_x * P.beta_y) * kx2 * ky2;\n        \n        phase = P.dt * (kinetic_term - biharmonic_term - cross_term * 0.5);\n    } else {\n        // Isotropic dispersion (standard)\n        let k2 = kx * kx + ky * ky;\n        let k4 = k2 * k2;\n        phase = P.dt * (P.alpha * k2 - P.beta * k4);\n    }\n    \n    // Add nonlinear correction if available\n    if (P.nonlinear_strength > 0.0 && id < arrayLength(&density)) {\n        let rho = density[id];\n        phase += P.dt * P.nonlinear_strength * rho;\n    }\n    \n    // Apply band limiting\n    let k_mag = sqrt(kx * kx + ky * ky);\n    let filter = band_limit_filter(k_mag, P.band_limit, P.filter_order);\n    \n    // Load field value\n    let psi_k = fieldK[id];\n    \n    // Apply evolution operator\n    let evolution = complex_exp_stable(-phase);  // Note: negative for correct sign\n    var result = complex_multiply(psi_k, evolution);\n    \n    // Apply band limit filter\n    result *= filter;\n    \n    // Store result\n    fieldK[id] = result;\n}\n\n// ENHANCED: Specialized version for radially symmetric dispersion\n@compute @workgroup_size(8, 8, 1)\nfn apply_radial_dispersion(\n    @builtin(global_invocation_id) gid: vec3<u32>\n) {\n    if (gid.x >= P.width || gid.y >= P.height) { return; }\n    \n    let id = gid.y * P.width + gid.x;\n    \n    // Get k-space coordinates\n    let kx = kcoord_enhanced(gid.x, P.width, P.dx);\n    let ky = kcoord_enhanced(gid.y, P.height, P.dy);\n    let k2 = kx * kx + ky * ky;\n    let k = sqrt(k2);\n    \n    // Radial dispersion relation (can be more complex)\n    // Example: ω(k) = α*k² - β*k⁴ + γ*k³ (odd power for asymmetry)\n    let omega = P.alpha * k2 - P.beta * k2 * k2;\n    \n    // Phase velocity correction for radial symmetry\n    let phase = -P.dt * omega;\n    \n    // Apply with band limiting\n    let filter = band_limit_filter(k, P.band_limit, P.filter_order);\n    let evolution = complex_exp_stable(phase);\n    \n    let psi_k = fieldK[id];\n    fieldK[id] = complex_multiply(psi_k, evolution) * filter;\n}";

// Shader: schrodinger_phase_multiply.wgsl
// Purpose: No description
export const schrodinger_phase_multiply_wgsl = "// schrodinger_phase_multiply.wgsl\n// PLATINUM Edition: Phase multiplication with absorbing boundaries and APO\n// - Support for complex potentials (absorption)\n// - Airy function absorbing boundaries\n// - Perfectly matched layer (PML) option\n\nstruct Params {\n    width: u32;\n    height: u32;\n    pad0: u32;\n    pad1: u32;\n    dt_half: f32;\n    vscale: f32;\n    useMask: u32;         // 0/1 for absorbing mask\n    maskStrength: f32;    // 0..1 damping strength\n    // ENHANCED: Additional boundary options\n    boundary_type: u32;   // 0: none, 1: mask, 2: PML, 3: Airy\n    pml_width: f32;       // Width of PML region in pixels\n    pml_strength: f32;    // PML absorption coefficient\n    airy_scale: f32;      // Airy function scaling\n}\n\n@group(0) @binding(0) var<uniform> P: Params;\n@group(0) @binding(1) var<storage, read_write> field: array<vec2<f32>>;\n@group(0) @binding(2) var potentialTex: texture_2d<f32>;\n@group(0) @binding(3) var samp: sampler;\n\n// Complex multiplication\nfn complex_multiply(a: vec2<f32>, b: vec2<f32>) -> vec2<f32> {\n    return vec2<f32>(\n        a.x * b.x - a.y * b.y,\n        a.x * b.y + a.y * b.x\n    );\n}\n\n// Complex exponential with accuracy improvements\nfn complex_exp_accurate(theta: f32) -> vec2<f32> {\n    // Range reduction for better accuracy\n    let reduced_theta = theta - floor(theta / (2.0 * 3.14159265359)) * 2.0 * 3.14159265359;\n    return vec2<f32>(cos(reduced_theta), sin(reduced_theta));\n}\n\n// Airy function absorbing boundary (approximate)\nfn airy_absorbing(dist_from_edge: f32, scale: f32) -> f32 {\n    // Approximation of Ai(x) decay for x > 0\n    let x = max(0.0, -dist_from_edge / scale);\n    if (x < 0.1) { return 1.0; }\n    \n    // Asymptotic approximation: Ai(x) ~ exp(-2/3 * x^(3/2)) / (2 * sqrt(pi) * x^(1/4))\n    let x_pow = pow(x, 1.5);\n    return exp(-0.666667 * x_pow) / (2.0 * sqrt(3.14159265359 * pow(x, 0.25)));\n}\n\n// Perfectly Matched Layer (PML) absorption\nfn pml_sigma(dist_from_edge: f32, width: f32, strength: f32) -> f32 {\n    if (dist_from_edge >= width) { return 0.0; }\n    \n    let x = (width - dist_from_edge) / width;  // 0 at edge, 1 at inner boundary\n    // Quadratic profile for smooth absorption\n    return strength * x * x;\n}\n\n// Super-Gaussian window for smooth edges\nfn super_gaussian(r: f32, order: f32) -> f32 {\n    return exp(-pow(r, order));\n}\n\n@compute @workgroup_size(8, 8, 1)\nfn main(@builtin(global_invocation_id) gid: vec3<u32>) {\n    if (gid.x >= P.width || gid.y >= P.height) { return; }\n    \n    let id = gid.y * P.width + gid.x;\n    let uv = vec2<f32>(\n        (f32(gid.x) + 0.5) / f32(P.width),\n        (f32(gid.y) + 0.5) / f32(P.height)\n    );\n    \n    // Sample potential (can be complex for absorption)\n    let pot_sample = textureSampleLevel(potentialTex, samp, uv, 0.0);\n    let V_real = pot_sample.r * P.vscale;\n    let V_imag = pot_sample.g * P.vscale;  // Imaginary part for absorption\n    \n    // Load field value\n    var psi = field[id];\n    \n    // Apply potential evolution: exp(-i * (V_r - i*V_i) * dt/2)\n    // = exp(-i * V_r * dt/2) * exp(-V_i * dt/2)\n    let phase = -V_real * P.dt_half;\n    let damping = exp(-V_imag * P.dt_half);\n    \n    let rotation = complex_exp_accurate(phase);\n    psi = complex_multiply(psi, rotation) * damping;\n    \n    // Apply boundary conditions based on type\n    var boundary_factor = 1.0;\n    \n    if (P.boundary_type > 0u) {\n        // Calculate distance from edges\n        let fx = f32(gid.x);\n        let fy = f32(gid.y);\n        let dist_left = fx;\n        let dist_right = f32(P.width - 1u) - fx;\n        let dist_top = fy;\n        let dist_bottom = f32(P.height - 1u) - fy;\n        let min_dist = min(min(dist_left, dist_right), min(dist_top, dist_bottom));\n        \n        switch (P.boundary_type) {\n            case 1u: { // Simple mask from texture alpha\n                let mask = clamp(pot_sample.a, 0.0, 1.0);\n                boundary_factor = mix(1.0, mask, P.maskStrength);\n            }\n            case 2u: { // PML\n                let sigma = pml_sigma(min_dist, P.pml_width, P.pml_strength);\n                boundary_factor = exp(-sigma * P.dt_half);\n            }\n            case 3u: { // Airy function\n                boundary_factor = airy_absorbing(min_dist, P.airy_scale);\n            }\n            default: {}\n        }\n    }\n    \n    // Apply boundary absorption\n    psi *= boundary_factor;\n    \n    // Store result\n    field[id] = psi;\n}\n\n// ENHANCED: Variant for split potential (real and imaginary parts separate)\n@compute @workgroup_size(8, 8, 1)\nfn apply_split_potential(\n    @builtin(global_invocation_id) gid: vec3<u32>\n) {\n    if (gid.x >= P.width || gid.y >= P.height) { return; }\n    \n    let id = gid.y * P.width + gid.x;\n    \n    // For cases where V_real and V_imag are in separate textures\n    // This allows for higher precision or different resolutions\n    let uv = vec2<f32>(\n        (f32(gid.x) + 0.5) / f32(P.width),\n        (f32(gid.y) + 0.5) / f32(P.height)\n    );\n    \n    // Red channel: real potential, Green channel: imaginary potential\n    let V_complex = textureSampleLevel(potentialTex, samp, uv, 0.0).rg * P.vscale;\n    \n    // Apply split-operator method more accurately\n    let psi = field[id];\n    \n    // First apply real part rotation\n    let phase_real = -V_complex.x * P.dt_half;\n    let rot_real = complex_exp_accurate(phase_real);\n    var result = complex_multiply(psi, rot_real);\n    \n    // Then apply imaginary part damping\n    let damping = exp(-V_complex.y * P.dt_half);\n    result *= damping;\n    \n    field[id] = result;\n}";

// Shader: schrodinger_splitstep.wgsl
// Purpose: No description
export const schrodinger_splitstep_wgsl = "// schrodinger_splitstep.wgsl\n// Split-Step Fourier Method: MAXIMUM STABILITY!\n// Can use dt = 1.0 or even larger!\n// Requires FFT passes between steps\n\nstruct Params {\n    width: u32,\n    height: u32,\n    is_forward_fft: u32,   // 1 for FFT, 0 for IFFT\n    pad0: u32,\n    dt: f32,\n    alpha: f32,            // Kinetic coefficient\n    beta: f32,             // Dispersion coefficient  \n    k_max: f32,            // Maximum k-vector magnitude\n}\n\n@group(0) @binding(0) var<uniform> P: Params;\n@group(0) @binding(1) var<storage, read> inField: array<vec2<f32>>;\n@group(0) @binding(2) var<storage, read_write> outField: array<vec2<f32>>;\n@group(0) @binding(3) var potential: texture_2d<f32>;\n@group(0) @binding(4) var samp: sampler;\n\n// Complex multiplication\nfn c_mul(a: vec2<f32>, b: vec2<f32>) -> vec2<f32> {\n    return vec2<f32>(a.x * b.x - a.y * b.y, a.x * b.y + a.y * b.x);\n}\n\n// Complex exponential\nfn c_exp(phase: f32) -> vec2<f32> {\n    return vec2<f32>(cos(phase), sin(phase));\n}\n\n// Step 1: Apply potential in position space (half step)\n@compute @workgroup_size(8, 8, 1)\nfn apply_potential_half(@builtin(global_invocation_id) gid: vec3<u32>) {\n    if (gid.x >= P.width || gid.y >= P.height) { return; }\n    let id = gid.y * P.width + gid.x;\n    \n    // Sample potential\n    let uv = vec2<f32>((f32(gid.x) + 0.5) / f32(P.width),\n                       (f32(gid.y) + 0.5) / f32(P.height));\n    let V = textureSampleLevel(potential, samp, uv, 0.0).r;\n    \n    // Apply exp(-i*V*dt/2)\n    let phase = -V * P.dt * 0.5;\n    let propagator = c_exp(phase);\n    \n    outField[id] = c_mul(inField[id], propagator);\n}\n\n// Step 2: Apply kinetic + dispersion in k-space (full step)\n@compute @workgroup_size(8, 8, 1)\nfn apply_kinetic_full(@builtin(global_invocation_id) gid: vec3<u32>) {\n    if (gid.x >= P.width || gid.y >= P.height) { return; }\n    let id = gid.y * P.width + gid.x;\n    \n    // Get k-space coordinates (assumes FFT shift)\n    let kx_idx = select(f32(gid.x), f32(gid.x) - f32(P.width), gid.x >= P.width / 2u);\n    let ky_idx = select(f32(gid.y), f32(gid.y) - f32(P.height), gid.y >= P.height / 2u);\n    \n    // Normalize to [-π, π]\n    let kx = kx_idx * 2.0 * 3.14159265 / f32(P.width);\n    let ky = ky_idx * 2.0 * 3.14159265 / f32(P.height);\n    let k2 = kx * kx + ky * ky;\n    let k4 = k2 * k2;\n    \n    // Dispersion relation: E(k) = α*k² + β*k⁴\n    let energy = P.alpha * k2 + P.beta * k4;\n    \n    // Apply exp(-i*E*dt) in k-space\n    let phase = -energy * P.dt;\n    let propagator = c_exp(phase);\n    \n    // Band limiting: suppress high frequencies\n    let k_mag = sqrt(k2);\n    let suppress = select(1.0, 0.0, k_mag > P.k_max);\n    \n    outField[id] = c_mul(inField[id], propagator) * suppress;\n}\n\n// Step 3: Apply potential again (half step) - same as step 1\n@compute @workgroup_size(8, 8, 1)\nfn apply_potential_half_final(@builtin(global_invocation_id) gid: vec3<u32>) {\n    if (gid.x >= P.width || gid.y >= P.height) { return; }\n    let id = gid.y * P.width + gid.x;\n    \n    let uv = vec2<f32>((f32(gid.x) + 0.5) / f32(P.width),\n                       (f32(gid.y) + 0.5) / f32(P.height));\n    let V = textureSampleLevel(potential, samp, uv, 0.0).r;\n    \n    let phase = -V * P.dt * 0.5;\n    let propagator = c_exp(phase);\n    \n    outField[id] = c_mul(inField[id], propagator);\n}\n\n// Helper: Apply absorbing boundary conditions (sponge layer)\n@compute @workgroup_size(8, 8, 1)\nfn apply_absorbing_boundary(@builtin(global_invocation_id) gid: vec3<u32>) {\n    if (gid.x >= P.width || gid.y >= P.height) { return; }\n    let id = gid.y * P.width + gid.x;\n    \n    // Distance from edges\n    let margin = 16.0;  // Width of absorbing layer\n    let dx = min(f32(gid.x), f32(P.width - 1u - gid.x));\n    let dy = min(f32(gid.y), f32(P.height - 1u - gid.y));\n    let d = min(dx, dy);\n    \n    // Smooth absorption using tanh profile\n    let absorption = select(1.0, 0.5 * (1.0 + tanh((d - margin) / 4.0)), d < margin);\n    \n    outField[id] = inField[id] * absorption;\n}";

// Shader: temporal_neural_propagation.wgsl
// Purpose: No description
export const temporal_neural_propagation_wgsl = "// temporal_neural_propagation.wgsl\n// Time-dependent Schrödinger equation with learned dynamics\n// Predicts future wave states using physics + neural corrections\n\nstruct Params {\n    width: u32,\n    height: u32,\n    dt: f32,              // Time step\n    dx: f32,              // Spatial resolution\n    // Wave equation parameters\n    c: f32,               // Wave speed (c = λν)\n    dispersion: f32,      // Dispersion coefficient\n    damping: f32,         // Damping factor\n    // Neural prediction weights (learned)\n    a0: f32,              // Current frame weight\n    a1: f32,              // Previous frame weight\n    a2: f32,              // Two frames ago weight\n    lap_scale: f32,       // Laplacian influence\n    biharmonic_scale: f32, // ∇⁴ influence for dispersion\n}\n\n@group(0) @binding(0) var<uniform> p: Params;\n@group(0) @binding(1) var<storage, read> prevField: array<vec2<f32>>;\n@group(0) @binding(2) var<storage, read> currField: array<vec2<f32>>;\n@group(0) @binding(3) var<storage, read_write> nextField: array<vec2<f32>>;\n// Neural correction from learned operator\n@group(0) @binding(4) var<storage, read> neuralCorrection: array<vec2<f32>>;\n\n// Constants\nconst PI: f32 = 3.14159265359;\n\n// Safe array access with clamping\nfn at(buf: ptr<storage, array<vec2<f32>>, read>, x: i32, y: i32) -> vec2<f32> {\n    let xi = clamp(x, 0, i32(p.width) - 1);\n    let yi = clamp(y, 0, i32(p.height) - 1);\n    let idx = u32(yi) * p.width + u32(xi);\n    if (idx < arrayLength(buf)) {\n        return (*buf)[idx];\n    }\n    return vec2<f32>(0.0, 0.0);\n}\n\n// Complex multiplication\nfn c_mul(a: vec2<f32>, b: vec2<f32>) -> vec2<f32> {\n    return vec2<f32>(a.x*b.x - a.y*b.y, a.x*b.y + a.y*b.x);\n}\n\n@compute @workgroup_size(8, 8, 1)\nfn main(@builtin(global_invocation_id) gid: vec3<u32>) {\n    if (gid.x >= p.width || gid.y >= p.height) { \n        return; \n    }\n    let x = i32(gid.x);\n    let y = i32(gid.y);\n    let idx = gid.y * p.width + gid.x;\n    \n    // Current and previous values\n    let c = at(&currField, x, y);\n    let p_prev = at(&prevField, x, y);\n    \n    // Compute Laplacian (∇²) - 5-point stencil\n    let l = at(&currField, x-1, y);\n    let r = at(&currField, x+1, y);\n    let u = at(&currField, x, y-1);\n    let d = at(&currField, x, y+1);\n    let lap = (l + r + u + d - 4.0 * c) / (p.dx * p.dx);\n    \n    // Compute Biharmonic (∇⁴) for dispersion - 13-point stencil\n    let ll = at(&currField, x-2, y);\n    let rr = at(&currField, x+2, y);\n    let uu = at(&currField, x, y-2);\n    let dd = at(&currField, x, y+2);\n    let ul = at(&currField, x-1, y-1);\n    let ur = at(&currField, x+1, y-1);\n    let dl = at(&currField, x-1, y+1);\n    let dr = at(&currField, x+1, y+1);\n    \n    let biharmonic = (ll + rr + uu + dd \n                     - 4.0*(l + r + u + d) \n                     + 12.0*c \n                     + 2.0*(ul + ur + dl + dr)) / (p.dx * p.dx * p.dx * p.dx);\n    \n    // Time-dependent Schrödinger equation with dispersion\n    // i∂ψ/∂t = -∇²ψ/(2m) + V(x)ψ + dispersion∇⁴ψ\n    let i_unit = vec2<f32>(0.0, 1.0);\n    \n    // Wave propagation term (kinetic energy)\n    var wave_term = lap * p.c * p.c;\n    \n    // Dispersion term (for chromatic effects)\n    wave_term = wave_term - biharmonic * p.dispersion;\n    \n    // Time evolution using improved Euler method\n    // ψ(t+dt) = ψ(t) + i*H*ψ(t)*dt\n    var n = c + c_mul(i_unit, wave_term) * p.dt;\n    \n    // Add damping for stability (dissipation)\n    n = n * (1.0 - p.damping * p.dt);\n    \n    // Neural correction (learned residual)\n    if (idx < arrayLength(&neuralCorrection)) {\n        n = n + neuralCorrection[idx] * 0.1; // Small correction\n    }\n    \n    // AR(2) recurrence for temporal coherence\n    n = n * p.a0 + p_prev * p.a1 + lap * p.lap_scale;\n    \n    // Ensure unitarity (preserve probability)\n    let mag = length(n);\n    if (mag > 0.0) {\n        n = n / mag; // Normalize\n    }\n    \n    nextField[idx] = n;\n}\n\n// Predict multiple frames ahead using learned dynamics\n@compute @workgroup_size(8, 8, 1)\nfn predict_future(@builtin(global_invocation_id) gid: vec3<u32>) {\n    if (gid.x >= p.width || gid.y >= p.height) { \n        return; \n    }\n    let idx = gid.y * p.width + gid.x;\n    \n    // Load current state\n    var state = vec2<f32>(0.0, 0.0);\n    var prev_state = vec2<f32>(0.0, 0.0);\n    \n    if (idx < arrayLength(&currField)) {\n        state = currField[idx];\n    }\n    if (idx < arrayLength(&prevField)) {\n        prev_state = prevField[idx];\n    }\n    \n    // Predict N frames ahead using learned dynamics\n    let future_steps = 10u;\n    for (var t = 0u; t < future_steps; t = t + 1u) {\n        // Simplified evolution for speed\n        let prediction = state * p.a0 + prev_state * p.a1;\n        prev_state = state;\n        state = prediction;\n        \n        // Maintain unitarity\n        let mag = length(state);\n        if (mag > 0.0) {\n            state = state / mag;\n        }\n    }\n    \n    nextField[idx] = state;\n}";

// Shader: topologicalOverlay.wgsl
// Purpose: No description
export const topologicalOverlay_wgsl = "// topologicalOverlay.wgsl\n// Shader for rendering topological charge overlays and BPS field visualization\n// Part of the TORI WebGPU rendering pipeline\n\nstruct VertexOutput {\n    @builtin(position) position: vec4<f32>,\n    @location(0) uv: vec2<f32>,\n    @location(1) worldPos: vec3<f32>,\n}\n\nstruct UniformData {\n    viewMatrix: mat4x4<f32>,\n    projMatrix: mat4x4<f32>,\n    modelMatrix: mat4x4<f32>,\n    time: f32,\n    chargeScale: f32,\n    phaseOffset: f32,\n    displayMode: u32,  // 0: charge density, 1: phase, 2: energy, 3: coherence\n}\n\nstruct ChargeData {\n    position: vec4<f32>,\n    charge: f32,\n    phase: f32,\n    energy: f32,\n    coherence: f32,\n    damping: f32,  // Phase sponge damping factor\n}\n\n@group(0) @binding(0) var<uniform> uniforms: UniformData;\n@group(0) @binding(1) var<storage, read_write> charges: array<ChargeData>;\n@group(0) @binding(2) var<storage, read> chargeCount: u32;\n@group(1) @binding(0) var baseTexture: texture_2d<f32>;\n@group(1) @binding(1) var textureSampler: sampler;\n\n// Vertex shader for full-screen quad\n\nfn clamp_index_dyn(i: u32, len: u32) -> u32 {\n    return select(i, len - 1u, i >= len);\n}\n\n@vertex\nfn vs_main(@builtin(vertex_index) vertexIndex: u32) -> VertexOutput {\n    var output: VertexOutput;\n    \n    // Generate full-screen triangle\n    let x = f32((vertexIndex << 1u) & 2u);\n    let y = f32(vertexIndex & 2u);\n    \n    output.position = vec4<f32>(x * 2.0 - 1.0, y * 2.0 - 1.0, 0.0, 1.0);\n    output.uv = vec2<f32>(x, 1.0 - y);\n    \n    // Calculate world position\n    let invViewProj = uniforms.projMatrix * uniforms.viewMatrix;\n    output.worldPos = (uniforms.modelMatrix * vec4<f32>(x * 2.0 - 1.0, y * 2.0 - 1.0, 0.0, 1.0)).xyz;\n    \n    return output;\n}\n\n// Helper function to calculate topological charge density at a point\nfn calculateChargeDensity(worldPos: vec3<f32>) -> f32 {\n    var totalCharge = 0.0;\n    let count = min(chargeCount, 1000u); // Safety limit\n    \n    for (var i = 0u; i < count; i = i + 1u) {\n        let charge_idx = clamp_index_dyn(i, arrayLength(&charges));\n        let charge = charges[charge_idx];\n        let distance = length(worldPos - charge.position.xyz);\n        \n        // Gaussian falloff for charge influence\n        let sigma = uniforms.chargeScale;\n        let influence = exp(-distance * distance / (2.0 * sigma * sigma));\n        \n        // Apply phase sponge damping\n        let dampedCharge = charge.charge * charge.damping;\n        totalCharge += dampedCharge * influence;\n    }\n    \n    return totalCharge;\n}\n\n// Helper function to calculate phase field\nfn calculatePhaseField(worldPos: vec3<f32>) -> f32 {\n    var totalPhase = 0.0;\n    var totalWeight = 0.0;\n    let count = min(chargeCount, 1000u);\n    \n    for (var i = 0u; i < count; i = i + 1u) {\n        let charge_idx = clamp_index_dyn(i, arrayLength(&charges));\n        let charge = charges[charge_idx];\n        let distance = length(worldPos - charge.position.xyz);\n        \n        // Phase interpolation with distance weighting\n        let weight = 1.0 / (1.0 + distance * distance);\n        totalPhase += charge.phase * weight * charge.damping;\n        totalWeight += weight;\n    }\n    \n    if (totalWeight > 0.0) {\n        totalPhase = totalPhase / totalWeight;\n    }\n    \n    // Add time-based phase evolution\n    return totalPhase + uniforms.phaseOffset + uniforms.time * 0.1;\n}\n\n// Helper function to calculate energy density\nfn calculateEnergyDensity(worldPos: vec3<f32>) -> f32 {\n    var totalEnergy = 0.0;\n    let count = min(chargeCount, 1000u);\n    \n    for (var i = 0u; i < count; i = i + 1u) {\n        let charge_idx = clamp_index_dyn(i, arrayLength(&charges));\n        let charge = charges[charge_idx];\n        let distance = length(worldPos - charge.position.xyz);\n        \n        // Energy falls off as 1/r^2 (coulomb-like)\n        if (distance > 0.001) {\n            let falloff = 1.0 / (distance * distance);\n            totalEnergy += abs(charge.energy) * falloff * charge.damping;\n        }\n    }\n    \n    return min(totalEnergy, 10.0); // Clamp for visualization\n}\n\n// Helper function to calculate phase coherence\nfn calculateCoherence(worldPos: vec3<f32>) -> f32 {\n    var complexSum = vec2<f32>(0.0, 0.0);\n    var count = 0u;\n    let maxCount = min(chargeCount, 1000u);\n    \n    for (var i = 0u; i < maxCount; i = i + 1u) {\n        let charge_idx = clamp_index_dyn(i, arrayLength(&charges));\n        let charge = charges[charge_idx];\n        let distance = length(worldPos - charge.position.xyz);\n        \n        if (distance < uniforms.chargeScale * 3.0) {\n            // Complex order parameter\n            complexSum += vec2<f32>(\n                cos(charge.phase) * charge.coherence,\n                sin(charge.phase) * charge.coherence\n            ) * charge.damping;\n            count = count + 1u;\n        }\n    }\n    \n    if (count > 0u) {\n        return length(complexSum) / f32(count);\n    }\n    return 0.0;\n}\n\n// Convert charge value to color\nfn chargeToColor(charge: f32) -> vec3<f32> {\n    // Red for positive, blue for negative, intensity based on magnitude\n    if (charge > 0.0) {\n        return vec3<f32>(charge, 0.0, 0.0);\n    } else {\n        return vec3<f32>(0.0, 0.0, -charge);\n    }\n}\n\n// Convert phase to color using HSV\nfn phaseToColor(phase: f32) -> vec3<f32> {\n    let h = (phase / (2.0 * 3.14159265359) + 1.0) * 0.5; // Normalize to [0, 1]\n    const s = 1.0;\n    const v = 1.0;\n    \n    // HSV to RGB conversion\n    let c = v * s;\n    let x = c * (1.0 - abs((h * 6.0) % 2.0 - 1.0));\n    let m = v - c;\n    \n    var rgb: vec3<f32>;\n    let h6 = h * 6.0;\n    \n    if (h6 < 1.0) {\n        rgb = vec3<f32>(c, x, 0.0);\n    } else if (h6 < 2.0) {\n        rgb = vec3<f32>(x, c, 0.0);\n    } else if (h6 < 3.0) {\n        rgb = vec3<f32>(0.0, c, x);\n    } else if (h6 < 4.0) {\n        rgb = vec3<f32>(0.0, x, c);\n    } else if (h6 < 5.0) {\n        rgb = vec3<f32>(x, 0.0, c);\n    } else {\n        rgb = vec3<f32>(c, 0.0, x);\n    }\n    \n    return rgb + vec3<f32>(m, m, m);\n}\n\n// Energy density to heat map color\nfn energyToColor(energy: f32) -> vec3<f32> {\n    let t = clamp(energy / 5.0, 0.0, 1.0);\n    \n    // Heat map: black -> blue -> cyan -> green -> yellow -> red\n    if (t < 0.2) {\n        let s = t / 0.2;\n        return vec3<f32>(0.0, 0.0, s);\n    } else if (t < 0.4) {\n        let s = (t - 0.2) / 0.2;\n        return vec3<f32>(0.0, s, 1.0);\n    } else if (t < 0.6) {\n        let s = (t - 0.4) / 0.2;\n        return vec3<f32>(0.0, 1.0, 1.0 - s);\n    } else if (t < 0.8) {\n        let s = (t - 0.6) / 0.2;\n        return vec3<f32>(s, 1.0, 0.0);\n    } else {\n        let s = (t - 0.8) / 0.2;\n        return vec3<f32>(1.0, 1.0 - s, 0.0);\n    }\n}\n\n// Coherence to grayscale\nfn coherenceToColor(coherence: f32) -> vec3<f32> {\n    let c = clamp(coherence, 0.0, 1.0);\n    return vec3<f32>(c, c, c);\n}\n\n// Fragment shader for topological overlay\n@fragment\nfn fs_main(input: VertexOutput) -> @location(0) vec4<f32> {\n    // Sample base texture\n    let baseColor = textureSample(baseTexture, textureSampler, input.uv);\n    \n    var overlayColor: vec3<f32>;\n    var overlayAlpha: f32;\n    \n    // Calculate field value based on display mode\n    switch (uniforms.displayMode) {\n        case 0u: { // Charge density\n            let charge = calculateChargeDensity(input.worldPos);\n            overlayColor = chargeToColor(charge);\n            overlayAlpha = min(abs(charge), 1.0) * 0.7;\n        }\n        case 1u: { // Phase field\n            let phase = calculatePhaseField(input.worldPos);\n            overlayColor = phaseToColor(phase);\n            overlayAlpha = 0.5;\n        }\n        case 2u: { // Energy density\n            let energy = calculateEnergyDensity(input.worldPos);\n            overlayColor = energyToColor(energy);\n            overlayAlpha = min(energy / 2.0, 1.0) * 0.6;\n        }\n        case 3u: { // Phase coherence\n            let coherence = calculateCoherence(input.worldPos);\n            overlayColor = coherenceToColor(coherence);\n            overlayAlpha = coherence * 0.8;\n        }\n        default: {\n            overlayColor = vec3<f32>(1.0, 0.0, 1.0); // Magenta for unknown mode\n            overlayAlpha = 0.5;\n        }\n    }\n    \n    // Blend overlay with base texture\n    let finalColor = mix(baseColor.rgb, overlayColor, overlayAlpha);\n    \n    return vec4<f32>(finalColor, baseColor.a);\n}\n\n// Compute shader for updating charge positions and phases\n@compute @workgroup_size(64, 1, 1)\nfn cs_update_charges(\n    @builtin(global_invocation_id) global_id: vec3<u32>\n) {\n    let index = global_id.x;\n    if (index >= chargeCount) {\n        return;\n    }\n    \n    let charge_idx = clamp_index_dyn(index, arrayLength(&charges));\n    var charge = charges[charge_idx];\n    \n    // Update phase with natural frequency\n    charge.phase = charge.phase + 0.01 * uniforms.time;\n    \n    // Normalize phase to [-pi, pi]\n    while (charge.phase > 3.14159265359) {\n        charge.phase = charge.phase - 2.0 * 3.14159265359;\n    }\n    while (charge.phase < -3.14159265359) {\n        charge.phase = charge.phase + 2.0 * 3.14159265359;\n    }\n    \n    // Update energy based on BPS saturation condition E = |Q|\n    charge.energy = abs(charge.charge);\n    \n    // Update coherence based on neighboring charges\n    var neighborPhases = 0.0;\n    var neighborCount = 0u;\n    \n    for (var i = 0u; i < min(chargeCount, 100u); i = i + 1u) {\n        if (i != index) {\n            let other_idx = clamp_index_dyn(i, arrayLength(&charges));\n            let other = charges[other_idx];\n            let distance = length(charge.position.xyz - other.position.xyz);\n            \n            if (distance < uniforms.chargeScale * 2.0) {\n                neighborPhases = neighborPhases + other.phase;\n                neighborCount = neighborCount + 1u;\n            }\n        }\n    }\n    \n    if (neighborCount > 0u) {\n        let avgPhase = neighborPhases / f32(neighborCount);\n        let phaseDiff = abs(charge.phase - avgPhase);\n        charge.coherence = cos(phaseDiff * 0.5); // High coherence when phases align\n    } else {\n        charge.coherence = 1.0; // Perfect coherence when isolated\n    }\n    \n    // Store updated charge\n    charges[charge_idx] = charge;\n}\n";

// Shader: transpose.wgsl
// Purpose: No description
export const transpose_wgsl = "// transpose.wgsl\n// Matrix transpose for 2D FFT using shared memory tiles with bank conflict avoidance\n// Optimized for coalesced memory access patterns\n\nstruct FFTUniforms {\n    size: u32,\n    log_size: u32,\n    batch_size: u32,\n    normalization: f32,\n    dimensions: u32,\n    direction: u32,\n    stage: u32,\n    _padding: u32\n}\n\n@group(0) @binding(0) var<uniform> uniforms: FFTUniforms;\n@group(0) @binding(2) var<storage, read> input: array<vec2<f32>>;\n@group(0) @binding(3) var<storage, read_write> output: array<vec2<f32>>;\n\n// Tile configuration\nconst TILE_SIZE: u32 = 16u;\n// Add padding to avoid bank conflicts on shared memory\nconst TILE_DIM: u32 = TILE_SIZE + 1u;\nconst TILE_ARRAY_SIZE: u32 = TILE_DIM * TILE_SIZE;\n\n// Shared memory with padding to avoid bank conflicts\nvar<workgroup> tile: array<vec2<f32>, TILE_ARRAY_SIZE>;\n\n\nfn clamp_index_dyn(i: u32, len: u32) -> u32 {\n    return select(i, len - 1u, i >= len);\n}\n\n@compute @workgroup_size(TILE_SIZE, TILE_SIZE, 1)\nfn main(\n    @builtin(local_invocation_id) local_id: vec3<u32>,\n    @builtin(workgroup_id) workgroup_id: vec3<u32>,\n    @builtin(global_invocation_id) global_id: vec3<u32>\n) {\n    let size = uniforms.size;\n    let batch_idx = workgroup_id.z;\n    let batch_offset = batch_idx * size * size;\n    \n    // Calculate tile coordinates\n    let tile_x = workgroup_id.x * TILE_SIZE;\n    let tile_y = workgroup_id.y * TILE_SIZE;\n    \n    // Global coordinates for this thread\n    let global_x = tile_x + local_id.x;\n    let global_y = tile_y + local_id.y;\n    \n    // Load tile into shared memory with bounds checking\n    // Use padded indexing to avoid bank conflicts\n    let local_idx = local_id.y * TILE_DIM + local_id.x;\n    \n    if (global_x < size && global_y < size && local_idx < TILE_ARRAY_SIZE) {\n        let idx = batch_offset + global_y * size + global_x;\n        tile[local_idx] = input[clamp_index_dyn(idx, arrayLength(&input))];\n    } else if (local_idx < TILE_ARRAY_SIZE) {\n        // Initialize out-of-bounds elements to zero\n        tile[local_idx] = vec2<f32>(0.0, 0.0);\n    }\n    \n    workgroupBarrier();\n    \n    // Calculate transposed coordinates\n    let transposed_x = tile_y + local_id.x;\n    let transposed_y = tile_x + local_id.y;\n    \n    // Write transposed tile with bounds checking\n    if (transposed_x < size && transposed_y < size) {\n        let transposed_idx = batch_offset + transposed_y * size + transposed_x;\n        // Read from shared memory with transposed local indices\n        // Note the swapped indices for transpose\n        let transposed_local = local_id.x * TILE_DIM + local_id.y;\n        if (transposed_local < TILE_ARRAY_SIZE) {\n            output[clamp_index_dyn(transposed_idx, arrayLength(&output))] = tile[transposed_local];\n        }\n    }\n}\n\n// Alternative implementation for non-square matrices or different tile sizes\n@compute @workgroup_size(TILE_SIZE, TILE_SIZE, 1)\nfn transpose_rect(\n    @builtin(local_invocation_id) local_id: vec3<u32>,\n    @builtin(workgroup_id) workgroup_id: vec3<u32>\n) {\n    // For rectangular matrices, adjust tile loading strategy\n    let width = uniforms.size;  // Assume width\n    let height = uniforms.size; // Could be different for rect matrices\n    let batch_idx = workgroup_id.z;\n    let batch_offset = batch_idx * width * height;\n    \n    // Load phase - coalesced reads\n    let tile_x = workgroup_id.x * TILE_SIZE;\n    let tile_y = workgroup_id.y * TILE_SIZE;\n    \n    for (var i = 0u; i < TILE_SIZE; i += 1u) {\n        let global_x = tile_x + local_id.x;\n        let global_y = tile_y + i;\n        \n        if (global_x < width && global_y < height) {\n            let idx = batch_offset + global_y * width + global_x;\n            let shared_idx = i * TILE_DIM + local_id.x;\n            if (shared_idx < TILE_ARRAY_SIZE) {\n                tile[shared_idx] = input[clamp_index_dyn(idx, arrayLength(&input))];\n            }\n        }\n    }\n    \n    workgroupBarrier();\n    \n    // Store phase - coalesced writes\n    for (var i = 0u; i < TILE_SIZE; i += 1u) {\n        let transposed_x = tile_y + i;\n        let transposed_y = tile_x + local_id.x;\n        \n        if (transposed_x < height && transposed_y < width) {\n            let transposed_idx = batch_offset + transposed_y * height + transposed_x;\n            let shared_idx = local_id.x * TILE_DIM + i;\n            if (shared_idx < TILE_ARRAY_SIZE) {\n                output[clamp_index_dyn(transposed_idx, arrayLength(&output))] = tile[shared_idx];\n            }\n        }\n    }\n}\n\n// In-place transpose for square matrices (requires careful synchronization)\n@compute @workgroup_size(TILE_SIZE, 1, 1)\nfn transpose_inplace(\n    @builtin(global_invocation_id) global_id: vec3<u32>\n) {\n    let size = uniforms.size;\n    let batch_idx = global_id.z;\n    let batch_offset = batch_idx * size * size;\n    \n    // Process upper triangle only to avoid double swapping\n    let row = global_id.x;\n    if (row >= size) { return; }\n    \n    for (var col = row + 1u; col < size; col++) {\n        let idx1 = batch_offset + row * size + col;\n        let idx2 = batch_offset + col * size + row;\n        \n        // Swap elements with bounds checking\n        let clamped_idx1 = clamp_index_dyn(idx1, arrayLength(&input));\n        let clamped_idx2 = clamp_index_dyn(idx2, arrayLength(&input));\n        let temp = input[clamped_idx1];\n        output[clamp_index_dyn(idx1, arrayLength(&output))] = input[clamped_idx2];\n        output[clamp_index_dyn(idx2, arrayLength(&output))] = temp;\n    }\n}\n\n// Documentation:\n// Bank conflicts occur when multiple threads in a warp access the same\n// memory bank simultaneously. Adding padding (TILE_DIM = TILE_SIZE + 1)\n// ensures that consecutive threads access different banks.\n//\n// Performance tips:\n// - TILE_SIZE should be a multiple of warp size (typically 32)\n// - Smaller tiles (16x16) often perform better than larger ones\n// - Padding eliminates bank conflicts at the cost of slightly more shared memory\n";

// Shader: velocityField.wgsl
// Purpose: No description
export const velocityField_wgsl = "// ${IRIS_ROOT}\\frontend\\shaders\\velocityField.wgsl\r\n// Enhanced compute shader for phase velocity field visualization with optimizations\r\n\r\nstruct WavefieldParams {\r\n    phase_modulation: f32,\r\n    coherence: f32,\r\n    time: f32,\r\n    scale: f32,\r\n    phases: array<vec4<f32>, 4>,  // 16 floats packed as 4 vec4s\r\n    spatial_freqs: array<vec4<f32>, 16>  // 32 vec2s packed as 16 vec4s\r\n}\r\n\r\nstruct VelocityFieldParams {\r\n    scale_factor: f32,\r\n    time_step: f32,\r\n    viscosity: f32,\r\n    vorticity_strength: f32,\r\n    damping_factor: f32,\r\n    max_speed: f32,\r\n    coherence_blend: f32,\r\n    vortex_falloff: f32\r\n}\r\n\r\n@group(0) @binding(0) var<uniform> wavefield_params: WavefieldParams;\r\n@group(0) @binding(1) var<uniform> velocity_params: VelocityFieldParams;\r\n@group(0) @binding(2) var wavefield_texture: texture_2d<f32>;\r\n@group(0) @binding(3) var velocity_out: texture_storage_2d<rg32float, read_write>;\r\n@group(0) @binding(4) var sampler_linear: sampler;\r\n@group(0) @binding(5) var<storage, read_write> particles: array<vec4<f32>>;\r\n@group(0) @binding(6) var flow_vis_out: texture_storage_2d<rgba8unorm, write>;\r\n\r\n// Pre-computed constants\r\nconst PI: f32 = 3.14159265359;\r\nconst TWO_PI: f32 = 6.28318530718;\r\nconst INV_PI: f32 = 0.31830988618;\r\nconst INV_TWO_PI: f32 = 0.15915494309;\r\nconst HALF_PI: f32 = 1.57079632679;\r\nconst SHARED_SIZE: u32 = 100u; // 10x10 tile\r\n\r\n// Workgroup shared memory for caching texture reads\r\nvar<workgroup> shared_wavefield: array<vec4<f32>, SHARED_SIZE>;\r\n\r\n// Fast phase unwrapping using bit manipulation\r\n\r\nfn clamp_index_dyn(i: u32, len: u32) -> u32 {\r\n    return select(i, len - 1u, i >= len);\r\n}\r\n\r\nfn fast_unwrap_phase(phase_diff: f32) -> f32 {\r\n    // Optimized phase unwrapping without branches\r\n    let wrapped = phase_diff + PI;\r\n    let cycles = floor(wrapped * INV_TWO_PI);\r\n    return phase_diff - cycles * TWO_PI;\r\n}\r\n\r\n// Optimized atan2 approximation for performance\r\nfn fast_atan2(y: f32, x: f32) -> f32 {\r\n    let abs_y = abs(y);\r\n    let abs_x = abs(x);\r\n    let a = min(abs_x, abs_y) / max(abs_x, abs_y);\r\n    let s = a * a;\r\n    \r\n    // Polynomial approximation\r\n    var r = ((-0.0464964749 * s + 0.15931422) * s - 0.327622764) * s * a + a;\r\n    \r\n    if (abs_y > abs_x) {\r\n        r = HALF_PI - r;\r\n    }\r\n    \r\n    if (x < 0.0) {\r\n        r = PI - r;\r\n    }\r\n    \r\n    return select(-r, r, y >= 0.0);\r\n}\r\n\r\n// Load wavefield data into shared memory\r\nfn load_shared_memory(local_id: vec2<u32>, workgroup_id: vec2<u32>, dims: vec2<u32>) {\r\n    let tile_start = workgroup_id.xy * 8u;\r\n    let shared_idx = local_id.y * 10u + local_id.x;\r\n    \r\n    // Each thread loads multiple values to fill the 10x10 tile\r\n    if (local_id.x < 10u && local_id.y < 10u && shared_idx < SHARED_SIZE) {\r\n        let global_coord = vec2<i32>(tile_start) + vec2<i32>(local_id) - vec2<i32>(1);\r\n        \r\n        // Clamp to texture boundaries\r\n        let clamped_coord = clamp(global_coord, vec2<i32>(0), vec2<i32>(dims) - vec2<i32>(1));\r\n        shared_wavefield[shared_idx] = textureLoad(wavefield_texture, clamped_coord, 0);\r\n    }\r\n    \r\n    workgroupBarrier();\r\n}\r\n\r\n// Compute phase gradient using shared memory\r\nfn compute_phase_gradient_shared(local_id: vec2<u32>) -> vec2<f32> {\r\n    let idx = (local_id.y + 1u) * 10u + (local_id.x + 1u);\r\n    \r\n    // Bounds check for shared memory\r\n    if (idx >= SHARED_SIZE || idx < 1u || idx >= SHARED_SIZE - 1u) {\r\n        return vec2<f32>(0.0);\r\n    }\r\n    \r\n    // Check bounds for all needed indices\r\n    let idx_left = idx - 1u;\r\n    let idx_right = idx + 1u;\r\n    let idx_down = idx - 10u;\r\n    let idx_up = idx + 10u;\r\n    \r\n    if (idx_up >= SHARED_SIZE) {\r\n        return vec2<f32>(0.0);\r\n    }\r\n    \r\n    // Get values from shared memory with bounds checking\r\n    let center = shared_wavefield[clamp_index_dyn(idx, SHARED_SIZE)].xy;\r\n    let left = shared_wavefield[clamp_index_dyn(idx_left, SHARED_SIZE)].xy;\r\n    let right = shared_wavefield[clamp_index_dyn(idx_right, SHARED_SIZE)].xy;\r\n    let down = shared_wavefield[clamp_index_dyn(idx_down, SHARED_SIZE)].xy;\r\n    let up = shared_wavefield[clamp_index_dyn(idx_up, SHARED_SIZE)].xy;\r\n    \r\n    // Use fast atan2 for phase computation\r\n    let phase_center = fast_atan2(center.y, center.x);\r\n    let phase_left = fast_atan2(left.y, left.x);\r\n    let phase_right = fast_atan2(right.y, right.x);\r\n    let phase_down = fast_atan2(down.y, down.x);\r\n    let phase_up = fast_atan2(up.y, up.x);\r\n    \r\n    // Optimized phase unwrapping\r\n    let dx = fast_unwrap_phase(phase_right - phase_left);\r\n    let dy = fast_unwrap_phase(phase_up - phase_down);\r\n    \r\n    return vec2<f32>(dx, dy) * 0.5;\r\n}\r\n\r\n// Vectorized theoretical velocity computation\r\nfn compute_theoretical_velocity_optimized(pos: vec2<f32>) -> vec2<f32> {\r\n    var velocity = vec2<f32>(0.0);\r\n    var total_weight = 0.0;\r\n    \r\n    // Process spatial frequencies in groups of 4 for better vectorization\r\n    for (var i = 0u; i < 32u; i += 4u) {\r\n        // Load 4 spatial frequencies at once from packed vec4 array\r\n        // Each vec4 contains 2 vec2s (xy=first vec2, zw=second vec2)\r\n        let packed_idx0 = clamp_index_dyn(i / 2u, 16u);\r\n        let packed_idx1 = clamp_index_dyn((i + 2u) / 2u, 16u);\r\n        let packed0 = wavefield_params.spatial_freqs[packed_idx0];\r\n        let packed1 = wavefield_params.spatial_freqs[packed_idx1];\r\n        \r\n        let k0 = vec2<f32>(packed0.xy);\r\n        let k1 = vec2<f32>(packed0.zw);\r\n        let k2 = vec2<f32>(packed1.xy);\r\n        let k3 = vec2<f32>(packed1.zw);\r\n        \r\n        // Compute magnitudes\r\n        let k_mag0 = length(k0);\r\n        let k_mag1 = length(k1);\r\n        let k_mag2 = length(k2);\r\n        let k_mag3 = length(k3);\r\n        \r\n        // Early termination check\r\n        if (k_mag0 < 0.001 && k_mag1 < 0.001 && k_mag2 < 0.001 && k_mag3 < 0.001) {\r\n            continue;\r\n        }\r\n        \r\n        // Vectorized computation\r\n        let scale = velocity_params.scale_factor;\r\n        let coherence = wavefield_params.coherence;\r\n        \r\n        // Process each valid frequency\r\n        if (k_mag0 >= 0.001) {\r\n            let omega0 = k_mag0 * scale;\r\n            let phase_vel0 = omega0 / (k_mag0 * k_mag0);\r\n            let weight0 = exp(-f32(i) * 0.1) * coherence;\r\n            velocity += k0 * phase_vel0 * weight0;\r\n            total_weight += weight0;\r\n        }\r\n        \r\n        if (k_mag1 >= 0.001) {\r\n            let omega1 = k_mag1 * scale;\r\n            let phase_vel1 = omega1 / (k_mag1 * k_mag1);\r\n            let weight1 = exp(-f32(i + 1u) * 0.1) * coherence;\r\n            velocity += k1 * phase_vel1 * weight1;\r\n            total_weight += weight1;\r\n        }\r\n        \r\n        if (k_mag2 >= 0.001) {\r\n            let omega2 = k_mag2 * scale;\r\n            let phase_vel2 = omega2 / (k_mag2 * k_mag2);\r\n            let weight2 = exp(-f32(i + 2u) * 0.1) * coherence;\r\n            velocity += k2 * phase_vel2 * weight2;\r\n            total_weight += weight2;\r\n        }\r\n        \r\n        if (k_mag3 >= 0.001) {\r\n            let omega3 = k_mag3 * scale;\r\n            let phase_vel3 = omega3 / (k_mag3 * k_mag3);\r\n            let weight3 = exp(-f32(i + 3u) * 0.1) * coherence;\r\n            velocity += k3 * phase_vel3 * weight3;\r\n            total_weight += weight3;\r\n        }\r\n    }\r\n    \r\n    return select(vec2<f32>(0.0), velocity / total_weight, total_weight > 0.0);\r\n}\r\n\r\n// Optimized vorticity with precomputed values\r\nfn add_vorticity_optimized(pos: vec2<f32>, base_velocity: vec2<f32>) -> vec2<f32> {\r\n    var vorticity = vec2<f32>(0.0);\r\n    let falloff = velocity_params.vortex_falloff;\r\n    let strength = velocity_params.vorticity_strength;\r\n    \r\n    // Unroll loop for better performance\r\n    for (var i = 0u; i < 4u; i++) {\r\n        let phase_idx = clamp_index_dyn(i / 4u, 4u);\r\n        let phase_component = i % 4u;\r\n        let phase = wavefield_params.phases[phase_idx][phase_component];\r\n        let angle = phase + f32(i) * HALF_PI;\r\n        \r\n        // Precompute trigonometric values\r\n        let cos_angle = cos(angle);\r\n        let sin_angle = sin(angle);\r\n        let center = vec2<f32>(0.5 + 0.3 * cos_angle, 0.5 + 0.3 * sin_angle);\r\n        \r\n        let r = pos - center;\r\n        let r_squared = dot(r, r);\r\n        \r\n        // Use squared distance to avoid sqrt\r\n        if (r_squared > 0.000001 && r_squared < 0.09) { // 0.09 = 0.3^2\r\n            let r_mag = sqrt(r_squared);\r\n            let inv_r_mag = 1.0 / r_mag;\r\n            \r\n            // Tangential velocity for vortex\r\n            let tangent = vec2<f32>(-r.y, r.x) * inv_r_mag;\r\n            let vortex_strength = exp(-r_mag * falloff) * strength;\r\n            vorticity += tangent * vortex_strength;\r\n        }\r\n    }\r\n    \r\n    return base_velocity + vorticity;\r\n}\r\n\r\n// Optimized viscosity using separable filter\r\nfn apply_viscosity_separable(velocity: vec2<f32>, coord: vec2<i32>, local_id: vec2<u32>) -> vec2<f32> {\r\n    if (velocity_params.viscosity < 0.001) {\r\n        return velocity;\r\n    }\r\n    \r\n    let idx = (local_id.y + 1u) * 10u + (local_id.x + 1u);\r\n    \r\n    // Bounds check\r\n    if (idx >= SHARED_SIZE || idx < 1u || idx >= SHARED_SIZE - 1u || idx < 10u || idx >= SHARED_SIZE - 10u) {\r\n        return velocity;\r\n    }\r\n    \r\n    // Horizontal pass with bounds checking\r\n    var h_sum = vec2<f32>(0.0);\r\n    h_sum += shared_wavefield[clamp_index_dyn(idx - 1u, SHARED_SIZE)].xy * 0.25;\r\n    h_sum += shared_wavefield[clamp_index_dyn(idx, SHARED_SIZE)].xy * 0.5;\r\n    h_sum += shared_wavefield[clamp_index_dyn(idx + 1u, SHARED_SIZE)].xy * 0.25;\r\n    \r\n    // Vertical pass with bounds checking\r\n    var v_sum = vec2<f32>(0.0);\r\n    v_sum += shared_wavefield[clamp_index_dyn(idx - 10u, SHARED_SIZE)].xy * 0.25;\r\n    v_sum += shared_wavefield[clamp_index_dyn(idx, SHARED_SIZE)].xy * 0.5;\r\n    v_sum += shared_wavefield[clamp_index_dyn(idx + 10u, SHARED_SIZE)].xy * 0.25;\r\n    \r\n    // Combine and apply viscosity\r\n    let smoothed = (h_sum + v_sum) * 0.5;\r\n    return mix(velocity, smoothed, velocity_params.viscosity);\r\n}\r\n\r\n@compute @workgroup_size(8, 8, 1)\r\nfn main(@builtin(global_invocation_id) global_id: vec3<u32>,\r\n        @builtin(local_invocation_id) local_id: vec3<u32>,\r\n        @builtin(workgroup_id) workgroup_id: vec3<u32>) {\r\n    let coord = vec2<i32>(global_id.xy);\r\n    let dims = textureDimensions(velocity_out);\r\n    \r\n    // Early exit for out-of-bounds threads\r\n    if (any(coord >= vec2<i32>(dims))) {\r\n        return;\r\n    }\r\n    \r\n    // Load shared memory\r\n    load_shared_memory(local_id.xy, workgroup_id.xy, dims);\r\n    \r\n    let uv = vec2<f32>(coord) / vec2<f32>(dims);\r\n    \r\n    // Compute velocities using optimized functions\r\n    let phase_grad = compute_phase_gradient_shared(local_id.xy);\r\n    let measured_velocity = -phase_grad * velocity_params.scale_factor;\r\n    let theoretical_velocity = compute_theoretical_velocity_optimized(uv);\r\n    \r\n    // Optimized blending\r\n    let blend_factor = velocity_params.coherence_blend * wavefield_params.coherence;\r\n    var velocity = mix(theoretical_velocity, measured_velocity, blend_factor);\r\n    \r\n    // Add vorticity\r\n    velocity = add_vorticity_optimized(uv, velocity);\r\n    \r\n    // Apply viscosity using shared memory\r\n    velocity = apply_viscosity_separable(velocity, coord, local_id.xy);\r\n    \r\n    // Apply damping\r\n    velocity *= exp(-velocity_params.time_step * velocity_params.damping_factor);\r\n    \r\n    // Clamp velocity magnitude\r\n    let speed_squared = dot(velocity, velocity);\r\n    let max_speed_squared = velocity_params.max_speed * velocity_params.max_speed;\r\n    if (speed_squared > max_speed_squared) {\r\n        velocity *= sqrt(max_speed_squared / speed_squared);\r\n    }\r\n    \r\n    // Store result\r\n    textureStore(velocity_out, coord, vec4<f32>(velocity, 0.0, 0.0));\r\n}\r\n\r\n// Enhanced particle advection with better integration\r\n@compute @workgroup_size(128, 1, 1)\r\nfn advect_particles(@builtin(global_invocation_id) global_id: vec3<u32>) {\r\n    let idx = global_id.x;\r\n    let num_particles = arrayLength(&particles);\r\n    \r\n    if (idx >= num_particles) {\r\n        return;\r\n    }\r\n    \r\n    // Load particle data with bounds checking\r\n    let clamped_idx = clamp_index_dyn(idx, num_particles);\r\n    var particle = particles[clamped_idx];\r\n    let pos = particle.xy;\r\n    let old_vel = particle.zw;\r\n    \r\n    // Bicubic interpolation for smoother velocity field sampling\r\n    let dims = vec2<f32>(textureDimensions(velocity_out));\r\n    let tex_coord = pos * dims;\r\n    let base_coord = floor(tex_coord);\r\n    let frac = tex_coord - base_coord;\r\n    \r\n    // Sample 4x4 grid for bicubic interpolation\r\n    var velocity_sum = vec2<f32>(0.0);\r\n    var weight_sum = 0.0;\r\n    \r\n    for (var dy = -1; dy <= 2; dy++) {\r\n        for (var dx = -1; dx <= 2; dx++) {\r\n            let sample_coord = vec2<i32>(base_coord) + vec2<i32>(dx, dy);\r\n            let clamped = clamp(sample_coord, vec2<i32>(0), vec2<i32>(dims) - vec2<i32>(1));\r\n            \r\n            let sample_vel = textureLoad(velocity_out, clamped).xy;\r\n            \r\n            // Bicubic weight\r\n            let dist_x = abs(f32(dx) - frac.x);\r\n            let dist_y = abs(f32(dy) - frac.y);\r\n            let weight_x = max(0.0, 1.0 - dist_x);\r\n            let weight_y = max(0.0, 1.0 - dist_y);\r\n            let weight = weight_x * weight_y;\r\n            \r\n            velocity_sum += sample_vel * weight;\r\n            weight_sum += weight;\r\n        }\r\n    }\r\n    \r\n    let field_velocity = velocity_sum / max(weight_sum, 0.001);\r\n    \r\n    // Improved velocity blending with momentum\r\n    const momentum = 0.85;\r\n    let new_vel = old_vel * momentum + field_velocity * (1.0 - momentum);\r\n    \r\n    // RK4 integration for better accuracy\r\n    let dt = velocity_params.time_step;\r\n    \r\n    // k1\r\n    let k1_vel = new_vel;\r\n    let k1_pos = pos + k1_vel * dt * 0.5;\r\n    \r\n    // k2\r\n    let k2_coord = clamp(k1_pos * dims, vec2<f32>(0.0), dims - vec2<f32>(1.0));\r\n    let k2_vel = textureLoad(velocity_out, vec2<i32>(k2_coord)).xy;\r\n    let k2_pos = pos + k2_vel * dt * 0.5;\r\n    \r\n    // k3\r\n    let k3_coord = clamp(k2_pos * dims, vec2<f32>(0.0), dims - vec2<f32>(1.0));\r\n    let k3_vel = textureLoad(velocity_out, vec2<i32>(k3_coord)).xy;\r\n    let k3_pos = pos + k3_vel * dt;\r\n    \r\n    // k4\r\n    let k4_coord = clamp(k3_pos * dims, vec2<f32>(0.0), dims - vec2<f32>(1.0));\r\n    let k4_vel = textureLoad(velocity_out, vec2<i32>(k4_coord)).xy;\r\n    \r\n    // Combine\r\n    let final_vel = (k1_vel + 2.0 * k2_vel + 2.0 * k3_vel + k4_vel) / 6.0;\r\n    var new_pos = pos + final_vel * dt;\r\n    \r\n    // Toroidal wrapping for continuous flow\r\n    new_pos = fract(new_pos + vec2<f32>(1.0));\r\n    \r\n    // Store updated particle with bounds checking\r\n    particles[clamped_idx] = vec4<f32>(new_pos, new_vel);\r\n}\r\n\r\n// Enhanced visualization with gradient magnitude\r\n@compute @workgroup_size(8, 8, 1)\r\nfn visualize_flow(@builtin(global_invocation_id) global_id: vec3<u32>) {\r\n    let coord = vec2<i32>(global_id.xy);\r\n    let dims = textureDimensions(flow_vis_out);\r\n    \r\n    if (any(coord >= vec2<i32>(dims))) {\r\n        return;\r\n    }\r\n    \r\n    // Load velocity\r\n    let velocity = textureLoad(velocity_out, coord).xy;\r\n    let magnitude = length(velocity);\r\n    \r\n    // Compute divergence and curl for additional visualization\r\n    let left = textureLoad(velocity_out, coord + vec2<i32>(-1, 0)).xy;\r\n    let right = textureLoad(velocity_out, coord + vec2<i32>(1, 0)).xy;\r\n    let down = textureLoad(velocity_out, coord + vec2<i32>(0, -1)).xy;\r\n    let up = textureLoad(velocity_out, coord + vec2<i32>(0, 1)).xy;\r\n    \r\n    let divergence = (right.x - left.x + up.y - down.y) * 0.5;\r\n    let curl = (right.y - left.y - up.x + down.x) * 0.5;\r\n    \r\n    // HSV to RGB conversion for better visualization\r\n    let hue = atan2(velocity.y, velocity.x) * INV_TWO_PI + 0.5;\r\n    let saturation = clamp(magnitude / velocity_params.max_speed, 0.0, 1.0);\r\n    const value = 1.0;\r\n    \r\n    // Convert HSV to RGB\r\n    let c = value * saturation;\r\n    let x = c * (1.0 - abs((hue * 6.0) % 2.0 - 1.0));\r\n    let m = value - c;\r\n    \r\n    var rgb: vec3<f32>;\r\n    let h_segment = i32(hue * 6.0);\r\n    switch (h_segment) {\r\n        case 0: { rgb = vec3<f32>(c, x, 0.0); }\r\n        case 1: { rgb = vec3<f32>(x, c, 0.0); }\r\n        case 2: { rgb = vec3<f32>(0.0, c, x); }\r\n        case 3: { rgb = vec3<f32>(0.0, x, c); }\r\n        case 4: { rgb = vec3<f32>(x, 0.0, c); }\r\n        default: { rgb = vec3<f32>(c, 0.0, x); }\r\n    }\r\n    \r\n    rgb = rgb + vec3<f32>(m);\r\n    \r\n    // Add divergence/curl visualization in alpha channel\r\n    let div_curl_vis = clamp(abs(divergence) + abs(curl) * 0.5, 0.0, 1.0);\r\n    \r\n    textureStore(flow_vis_out, coord, vec4<f32>(rgb, div_curl_vis));\r\n}\r\n";

// Shader: wavefieldEncoder.wgsl
// Purpose: No description
export const wavefieldEncoder_wgsl = "// ${IRIS_ROOT}\\frontend\\shaders\\wavefieldEncoder.wgsl\r\n// Enhanced wavefield encoder with unified array sizes and optimizations\r\n\r\n// Unified constant for oscillator count\r\nconst MAX_OSCILLATORS: u32 = 32u;\r\nconst WORKGROUP_SIZE: u32 = 8u;\r\nconst PI: f32 = 3.14159265359;\r\nconst TWO_PI: f32 = 6.28318530718;\r\n\r\n// Override for runtime configuration\r\noverride HOLOGRAM_SIZE: u32 = 1024u;\r\n\r\nstruct WavefieldParams {\r\n    phase_modulation: f32,\r\n    coherence: f32,\r\n    time: f32,\r\n    scale: f32,\r\n    phases: array<f32, MAX_OSCILLATORS>,\r\n    spatial_freqs: array<vec2<f32>, MAX_OSCILLATORS>,\r\n    amplitudes: array<f32, MAX_OSCILLATORS>  // Pre-computed on CPU\r\n}\r\n\r\nstruct OscillatorData {\r\n    psi_phase: f32,\r\n    phase_coherence: f32,\r\n    coupling_strength: f32,\r\n    dominant_frequency: f32,\r\n    phases: array<f32, MAX_OSCILLATORS>,\r\n    spatial_freqs: array<vec2<f32>, MAX_OSCILLATORS>,\r\n    amplitudes: array<f32, MAX_OSCILLATORS>  // Pre-computed amplitudes\r\n}\r\n\r\nstruct PropagationParams {\r\n    wavelength: f32,\r\n    z_offset: f32,\r\n    amplitude_scale: f32,\r\n    phase_noise: f32\r\n}\r\n\r\nstruct QualitySettings {\r\n    resolution_scale: f32,\r\n    sample_count: u32,\r\n    enable_chromatic: u32,\r\n    enable_volumetric: u32\r\n}\r\n\r\n@group(0) @binding(0) var<storage, read> wavefield_params: WavefieldParams;\r\n@group(0) @binding(1) var depth_tex: texture_storage_2d<r32float, read>;\r\n@group(0) @binding(2) var wavefield_out: texture_storage_2d<rg32float, write>;\r\n@group(0) @binding(3) var noise_tex: texture_2d<f32>;  // Pre-computed noise texture\r\n\r\n@group(1) @binding(0) var<storage, read> osc_data: OscillatorData;\r\n@group(1) @binding(1) var<uniform> prop_params: PropagationParams;\r\n@group(1) @binding(2) var<uniform> quality: QualitySettings;\r\n@group(1) @binding(3) var color_tex: texture_2d<f32>;\r\n@group(1) @binding(4) var color_sampler: sampler;\r\n\r\n// Shared memory for oscillator data (loaded once per workgroup)\r\nvar<workgroup> shared_spatial_freqs: array<vec2<f32>, MAX_OSCILLATORS>;\r\nvar<workgroup> shared_phases: array<f32, MAX_OSCILLATORS>;\r\nvar<workgroup> shared_amplitudes: array<f32, MAX_OSCILLATORS>;\r\n\r\n// Complex number operations\r\n\r\nfn clamp_index_dyn(i: u32, len: u32) -> u32 {\r\n    return select(i, len - 1u, i >= len);\r\n}\r\n\r\nfn complex_multiply(a: vec2<f32>, b: vec2<f32>) -> vec2<f32> {\r\n    return vec2<f32>(\r\n        a.x * b.x - a.y * b.y,\r\n        a.x * b.y + a.y * b.x\r\n    );\r\n}\r\n\r\nfn complex_exp(phase: f32) -> vec2<f32> {\r\n    return vec2<f32>(cos(phase), sin(phase));\r\n}\r\n\r\n// Hash function for position-based effects\r\nfn hash(p: vec2<f32>) -> f32 {\r\n    var p3 = fract(vec3<f32>(p.xyx) * 0.13);\r\n    p3 += dot(p3, p3.yzx + 3.333);\r\n    return fract((p3.x + p3.y) * p3.z);\r\n}\r\n\r\n// Convert depth to phase delay\r\nfn depth_to_phase(depth: f32, wavelength: f32, dispersion: f32) -> f32 {\r\n    let k = TWO_PI / wavelength;\r\n    let actual_depth = depth * 500.0;  // Map 0-1 to 0-500mm\r\n    let dispersed_k = k * (1.0 + dispersion * 0.1);\r\n    return dispersed_k * actual_depth;\r\n}\r\n\r\n// Load shared data once per workgroup\r\nfn load_shared_data(local_id: vec3<u32>) {\r\n    let thread_idx = local_id.y * WORKGROUP_SIZE + local_id.x;\r\n    let stride = WORKGROUP_SIZE * WORKGROUP_SIZE;\r\n    \r\n    // Each thread loads a portion of the data\r\n    for (var i = thread_idx; i < MAX_OSCILLATORS; i += stride) {\r\n        let clamped_i = clamp_index_dyn(i, MAX_OSCILLATORS);\r\n        shared_spatial_freqs[clamped_i] = wavefield_params.spatial_freqs[clamped_i];\r\n        shared_phases[clamped_i] = wavefield_params.phases[clamped_i];\r\n        shared_amplitudes[clamped_i] = wavefield_params.amplitudes[clamped_i];\r\n    }\r\n    \r\n    workgroupBarrier();\r\n}\r\n\r\n// Optimized interference computation using shared memory\r\nfn compute_interference_fast(pos: vec2<f32>, time: f32) -> vec2<f32> {\r\n    var field = vec2<f32>(0.0, 0.0);\r\n    \r\n    // Unrolled loop for better performance (process 4 at a time)\r\n    for (var i = 0u; i < MAX_OSCILLATORS; i += 4u) {\r\n        // Make sure we don't go out of bounds\r\n        let idx0 = clamp_index_dyn(i, MAX_OSCILLATORS);\r\n        let idx1 = clamp_index_dyn(i + 1u, MAX_OSCILLATORS);\r\n        let idx2 = clamp_index_dyn(i + 2u, MAX_OSCILLATORS);\r\n        let idx3 = clamp_index_dyn(i + 3u, MAX_OSCILLATORS);\r\n        \r\n        // Process 4 oscillators in parallel\r\n        let freq0 = shared_spatial_freqs[idx0];\r\n        let freq1 = shared_spatial_freqs[idx1];\r\n        let freq2 = shared_spatial_freqs[idx2];\r\n        let freq3 = shared_spatial_freqs[idx3];\r\n        \r\n        let phase0 = shared_phases[idx0];\r\n        let phase1 = shared_phases[idx1];\r\n        let phase2 = shared_phases[idx2];\r\n        let phase3 = shared_phases[idx3];\r\n        \r\n        let amp0 = shared_amplitudes[idx0];\r\n        let amp1 = shared_amplitudes[idx1];\r\n        let amp2 = shared_amplitudes[idx2];\r\n        let amp3 = shared_amplitudes[idx3];\r\n        \r\n        // Compute all dot products\r\n        let k_dot_r0 = dot(freq0, pos);\r\n        let k_dot_r1 = dot(freq1, pos);\r\n        let k_dot_r2 = dot(freq2, pos);\r\n        let k_dot_r3 = dot(freq3, pos);\r\n        \r\n        // Add time evolution\r\n        let t_scale = time * 0.1;\r\n        \r\n        // Accumulate contributions (branchless)\r\n        field += amp0 * complex_exp(k_dot_r0 + phase0 + t_scale * length(freq0));\r\n        field += amp1 * complex_exp(k_dot_r1 + phase1 + t_scale * length(freq1));\r\n        field += amp2 * complex_exp(k_dot_r2 + phase2 + t_scale * length(freq2));\r\n        field += amp3 * complex_exp(k_dot_r3 + phase3 + t_scale * length(freq3));\r\n    }\r\n    \r\n    return field;\r\n}\r\n\r\n// Simplified coherence modulation using pre-computed noise\r\nfn apply_coherence_modulation_fast(phase: f32, coherence: f32, noise_value: f32) -> f32 {\r\n    let noise_strength = (1.0 - coherence) * prop_params.phase_noise;\r\n    let phase_noise = (noise_value - 0.5) * TWO_PI * noise_strength;\r\n    let sharpness = mix(0.7, 1.3, coherence);\r\n    return phase * sharpness + phase_noise;\r\n}\r\n\r\n// Super-Gaussian aperture\r\nfn super_gaussian_aperture(pos: vec2<f32>, sigma: f32, order: f32) -> f32 {\r\n    let center = vec2<f32>(0.5, 0.5);\r\n    let r = length(pos - center) / sigma;\r\n    return exp(-pow(r, order));\r\n}\r\n\r\n// Optimized chromatic dispersion\r\nfn apply_chromatic_dispersion_fast(field: vec2<f32>, channel: u32) -> vec2<f32> {\r\n    if (quality.enable_chromatic == 0u) {\r\n        return field;\r\n    }\r\n    \r\n    // Pre-computed dispersion factors\r\n    const dispersion_factors = array<f32, 3>(\r\n        0.9,   // Red: 700nm\r\n        1.0,   // Green: 550nm  \r\n        1.1    // Blue: 450nm\r\n    );\r\n    \r\n    let dispersion = dispersion_factors[clamp_index_dyn(channel % 3u, 3u)];\r\n    let phase_idx = clamp_index_dyn((channel + 4u) * 2u, MAX_OSCILLATORS);\r\n    let phase_shift = osc_data.phases[phase_idx] * 0.05 * dispersion;\r\n    \r\n    return complex_multiply(field, complex_exp(phase_shift));\r\n}\r\n\r\n@compute @workgroup_size(WORKGROUP_SIZE, WORKGROUP_SIZE, 1)\r\nfn main(@builtin(global_invocation_id) global_id: vec3<u32>,\r\n        @builtin(local_invocation_id) local_id: vec3<u32>) {\r\n    // Load shared data once per workgroup\r\n    load_shared_data(local_id);\r\n    \r\n    let coord = global_id.xy;\r\n    let dims = vec2<u32>(HOLOGRAM_SIZE, HOLOGRAM_SIZE);\r\n    \r\n    if (coord.x >= dims.x || coord.y >= dims.y) {\r\n        return;\r\n    }\r\n    \r\n    let uv = vec2<f32>(coord) / vec2<f32>(dims);\r\n    \r\n    // Sample inputs\r\n    let depth = textureLoad(depth_tex, coord).r;\r\n    let noise_value = textureLoad(noise_tex, coord, 0).r;\r\n    let color = textureSampleLevel(color_tex, color_sampler, uv, 0.0);\r\n    let luminance = dot(color.rgb, vec3<f32>(0.299, 0.587, 0.114));\r\n    \r\n    // === Core computation ===\r\n    \r\n    // 1. Base amplitude\r\n    let base_amplitude = prop_params.amplitude_scale * \r\n                        mix(luminance, 1.0, 0.5) * \r\n                        mix(0.6, 1.0, wavefield_params.coherence);\r\n    \r\n    // 2. Phase from depth\r\n    var phase = depth_to_phase(depth, prop_params.wavelength, \r\n                              f32(coord.x % 3u) - 1.0);\r\n    phase += wavefield_params.phase_modulation;\r\n    \r\n    // 3. Fast interference computation\r\n    let interference = compute_interference_fast(uv, wavefield_params.time);\r\n    \r\n    // 4. Apply modulations\r\n    let interference_strength = osc_data.coupling_strength * 0.5;\r\n    phase += atan2(interference.y, interference.x) * interference_strength;\r\n    phase = apply_coherence_modulation_fast(phase, wavefield_params.coherence, noise_value);\r\n    \r\n    // 5. Aperture\r\n    let aperture = super_gaussian_aperture(uv, 0.45, 4.0);\r\n    let amplitude = base_amplitude * aperture * wavefield_params.scale;\r\n    \r\n    // 6. Generate field\r\n    phase = phase - floor(phase / TWO_PI) * TWO_PI;\r\n    var field = amplitude * complex_exp(phase) + interference * interference_strength;\r\n    \r\n    // 7. Reference beam\r\n    let ref_angle = PI / 6.0;\r\n    let ref_phase = TWO_PI * (uv.x * sin(ref_angle) + uv.y * cos(ref_angle)) / prop_params.wavelength;\r\n    field += 0.5 * complex_exp(ref_phase);\r\n    \r\n    // 8. Time effects\r\n    let pulse = 1.0 + 0.1 * sin(osc_data.psi_phase * 4.0 + wavefield_params.time) * \r\n                osc_data.phase_coherence;\r\n    field *= pulse;\r\n    \r\n    // 9. Chromatic dispersion\r\n    field = apply_chromatic_dispersion_fast(field, coord.x);\r\n    \r\n    // Store result\r\n    textureStore(wavefield_out, coord, vec4<f32>(field, 0.0, 0.0));\r\n}\r\n\r\n// Simplified test pattern generator\r\n@compute @workgroup_size(WORKGROUP_SIZE, WORKGROUP_SIZE, 1)\r\nfn generate_test_pattern(@builtin(global_invocation_id) global_id: vec3<u32>) {\r\n    let coord = global_id.xy;\r\n    let dims = vec2<u32>(HOLOGRAM_SIZE, HOLOGRAM_SIZE);\r\n    \r\n    if (coord.x >= dims.x || coord.y >= dims.y) {\r\n        return;\r\n    }\r\n    \r\n    let uv = vec2<f32>(coord) / vec2<f32>(dims);\r\n    let center = vec2<f32>(0.5, 0.5);\r\n    \r\n    // Animated point\r\n    let time = wavefield_params.time;\r\n    let point_pos = center + 0.2 * vec2<f32>(\r\n        sin(time + osc_data.psi_phase),\r\n        cos(time * 0.7)\r\n    );\r\n    \r\n    let r = distance(uv, point_pos);\r\n    let k = TWO_PI / prop_params.wavelength;\r\n    let phase = k * r * 1000.0 + osc_data.psi_phase * 2.0;\r\n    let amplitude = exp(-r * 5.0) * wavefield_params.coherence;\r\n    \r\n    let field = amplitude * complex_exp(phase);\r\n    let ref_phase = TWO_PI * uv.x * 5.0;\r\n    let reference = 0.3 * complex_exp(ref_phase);\r\n    \r\n    textureStore(wavefield_out, coord, vec4<f32>(field + reference, 0.0, 0.0));\r\n}\r\n";

// Shader: wavefieldEncoder_optimized.wgsl
// Purpose: No description
export const wavefieldEncoder_optimized_wgsl = "// ${IRIS_ROOT}\\frontend\\shaders\\wavefieldEncoder_optimized.wgsl\r\n// Enhanced wavefield encoder with unified array sizes and optimizations\r\n\r\n// Unified constant for oscillator count\r\nconst MAX_OSCILLATORS: u32 = 32u;\r\nconst WORKGROUP_SIZE: u32 = 8u;\r\nconst PI: f32 = 3.14159265359;\r\nconst TWO_PI: f32 = 6.28318530718;\r\n\r\n// Override for runtime configuration\r\noverride HOLOGRAM_SIZE: u32 = 1024u;\r\n\r\nstruct WavefieldParams {\r\n    phase_modulation: f32,\r\n    coherence: f32,\r\n    time: f32,\r\n    scale: f32,\r\n    phases: array<f32, MAX_OSCILLATORS>,\r\n    spatial_freqs: array<vec2<f32>, MAX_OSCILLATORS>,\r\n    amplitudes: array<f32, MAX_OSCILLATORS>  // Pre-computed on CPU\r\n}\r\n\r\nstruct OscillatorData {\r\n    psi_phase: f32,\r\n    phase_coherence: f32,\r\n    coupling_strength: f32,\r\n    dominant_frequency: f32,\r\n    phases: array<f32, MAX_OSCILLATORS>,\r\n    spatial_freqs: array<vec2<f32>, MAX_OSCILLATORS>,\r\n    amplitudes: array<f32, MAX_OSCILLATORS>  // Pre-computed amplitudes\r\n}\r\n\r\nstruct PropagationParams {\r\n    wavelength: f32,\r\n    z_offset: f32,\r\n    amplitude_scale: f32,\r\n    phase_noise: f32\r\n}\r\n\r\nstruct QualitySettings {\r\n    resolution_scale: f32,\r\n    sample_count: u32,\r\n    enable_chromatic: u32,\r\n    enable_volumetric: u32\r\n}\r\n\r\n@group(0) @binding(0) var<storage, read> wavefield_params: WavefieldParams;\r\n@group(0) @binding(1) var depth_tex: texture_storage_2d<r32float, read>;\r\n@group(0) @binding(2) var wavefield_out: texture_storage_2d<rg32float, write>;\r\n@group(0) @binding(3) var noise_tex: texture_2d<f32>;  // Pre-computed noise texture\r\n\r\n@group(1) @binding(0) var<storage, read> osc_data: OscillatorData;\r\n@group(1) @binding(1) var<storage, read> prop_params: PropagationParams;\r\n@group(1) @binding(2) var<storage, read> quality: QualitySettings;\r\n@group(1) @binding(3) var color_tex: texture_2d<f32>;\r\n@group(1) @binding(4) var color_sampler: sampler;\r\n\r\n// Shared memory for oscillator data (loaded once per workgroup)\r\nvar<workgroup> shared_spatial_freqs: array<vec2<f32>, MAX_OSCILLATORS>;\r\nvar<workgroup> shared_phases: array<f32, MAX_OSCILLATORS>;\r\nvar<workgroup> shared_amplitudes: array<f32, MAX_OSCILLATORS>;\r\n\r\n// Complex number operations\r\n\r\nfn clamp_index_dyn(i: u32, len: u32) -> u32 {\r\n    return select(i, len - 1u, i >= len);\r\n}\r\n\r\nfn complex_multiply(a: vec2<f32>, b: vec2<f32>) -> vec2<f32> {\r\n    return vec2<f32>(\r\n        a.x * b.x - a.y * b.y,\r\n        a.x * b.y + a.y * b.x\r\n    );\r\n}\r\n\r\nfn complex_exp(phase: f32) -> vec2<f32> {\r\n    return vec2<f32>(cos(phase), sin(phase));\r\n}\r\n\r\n// Hash function for position-based effects\r\nfn hash(p: vec2<f32>) -> f32 {\r\n    var p3 = fract(vec3<f32>(p.xyx) * 0.13);\r\n    p3 += dot(p3, p3.yzx + 3.333);\r\n    return fract((p3.x + p3.y) * p3.z);\r\n}\r\n\r\n// Convert depth to phase delay\r\nfn depth_to_phase(depth: f32, wavelength: f32, dispersion: f32) -> f32 {\r\n    let k = TWO_PI / wavelength;\r\n    let actual_depth = depth * 500.0;  // Map 0-1 to 0-500mm\r\n    let dispersed_k = k * (1.0 + dispersion * 0.1);\r\n    return dispersed_k * actual_depth;\r\n}\r\n\r\n// Load shared data once per workgroup\r\nfn load_shared_data(local_id: vec3<u32>) {\r\n    let thread_idx = local_id.y * WORKGROUP_SIZE + local_id.x;\r\n    let stride = WORKGROUP_SIZE * WORKGROUP_SIZE;\r\n    \r\n    // Each thread loads a portion of the data\r\n    for (var i = thread_idx; i < MAX_OSCILLATORS; i += stride) {\r\n        let clamped_i = clamp_index_dyn(i, MAX_OSCILLATORS);\r\n        shared_spatial_freqs[clamped_i] = wavefield_params.spatial_freqs[clamped_i];\r\n        shared_phases[clamped_i] = wavefield_params.phases[clamped_i];\r\n        shared_amplitudes[clamped_i] = wavefield_params.amplitudes[clamped_i];\r\n    }\r\n    \r\n    workgroupBarrier();\r\n}\r\n\r\n// Optimized interference computation using shared memory\r\nfn compute_interference_fast(pos: vec2<f32>, time: f32) -> vec2<f32> {\r\n    var field = vec2<f32>(0.0, 0.0);\r\n    \r\n    // Unrolled loop for better performance (process 4 at a time)\r\n    for (var i = 0u; i < MAX_OSCILLATORS; i += 4u) {\r\n        // Make sure we don't go out of bounds\r\n        let idx0 = clamp_index_dyn(i, MAX_OSCILLATORS);\r\n        let idx1 = clamp_index_dyn(i + 1u, MAX_OSCILLATORS);\r\n        let idx2 = clamp_index_dyn(i + 2u, MAX_OSCILLATORS);\r\n        let idx3 = clamp_index_dyn(i + 3u, MAX_OSCILLATORS);\r\n        \r\n        // Process 4 oscillators in parallel\r\n        let freq0 = shared_spatial_freqs[idx0];\r\n        let freq1 = shared_spatial_freqs[idx1];\r\n        let freq2 = shared_spatial_freqs[idx2];\r\n        let freq3 = shared_spatial_freqs[idx3];\r\n        \r\n        let phase0 = shared_phases[idx0];\r\n        let phase1 = shared_phases[idx1];\r\n        let phase2 = shared_phases[idx2];\r\n        let phase3 = shared_phases[idx3];\r\n        \r\n        let amp0 = shared_amplitudes[idx0];\r\n        let amp1 = shared_amplitudes[idx1];\r\n        let amp2 = shared_amplitudes[idx2];\r\n        let amp3 = shared_amplitudes[idx3];\r\n        \r\n        // Compute all dot products\r\n        let k_dot_r0 = dot(freq0, pos);\r\n        let k_dot_r1 = dot(freq1, pos);\r\n        let k_dot_r2 = dot(freq2, pos);\r\n        let k_dot_r3 = dot(freq3, pos);\r\n        \r\n        // Add time evolution\r\n        let t_scale = time * 0.1;\r\n        \r\n        // Accumulate contributions (branchless)\r\n        field += amp0 * complex_exp(k_dot_r0 + phase0 + t_scale * length(freq0));\r\n        field += amp1 * complex_exp(k_dot_r1 + phase1 + t_scale * length(freq1));\r\n        field += amp2 * complex_exp(k_dot_r2 + phase2 + t_scale * length(freq2));\r\n        field += amp3 * complex_exp(k_dot_r3 + phase3 + t_scale * length(freq3));\r\n    }\r\n    \r\n    return field;\r\n}\r\n\r\n// Simplified coherence modulation using pre-computed noise\r\nfn apply_coherence_modulation_fast(phase: f32, coherence: f32, noise_value: f32) -> f32 {\r\n    let noise_strength = (1.0 - coherence) * prop_params.phase_noise;\r\n    let phase_noise = (noise_value - 0.5) * TWO_PI * noise_strength;\r\n    let sharpness = mix(0.7, 1.3, coherence);\r\n    return phase * sharpness + phase_noise;\r\n}\r\n\r\n// Super-Gaussian aperture\r\nfn super_gaussian_aperture(pos: vec2<f32>, sigma: f32, order: f32) -> f32 {\r\n    let center = vec2<f32>(0.5, 0.5);\r\n    let r = length(pos - center) / sigma;\r\n    return exp(-pow(r, order));\r\n}\r\n\r\n// Optimized chromatic dispersion\r\nfn apply_chromatic_dispersion_fast(field: vec2<f32>, channel: u32) -> vec2<f32> {\r\n    if (quality.enable_chromatic == 0u) {\r\n        return field;\r\n    }\r\n    \r\n    // Pre-computed dispersion factors\r\n    const dispersion_factors = array<f32, 3>(\r\n        0.9,   // Red: 700nm\r\n        1.0,   // Green: 550nm  \r\n        1.1    // Blue: 450nm\r\n    );\r\n    \r\n    let dispersion = dispersion_factors[clamp_index_dyn(channel % 3u, 3u)];\r\n    let phase_idx = clamp_index_dyn((channel + 4u) * 2u, MAX_OSCILLATORS);\r\n    let phase_shift = osc_data.phases[phase_idx] * 0.05 * dispersion;\r\n    \r\n    return complex_multiply(field, complex_exp(phase_shift));\r\n}\r\n\r\n@compute @workgroup_size(WORKGROUP_SIZE, WORKGROUP_SIZE, 1)\r\nfn main(@builtin(global_invocation_id) global_id: vec3<u32>,\r\n        @builtin(local_invocation_id) local_id: vec3<u32>) {\r\n    // Load shared data once per workgroup\r\n    load_shared_data(local_id);\r\n    \r\n    let coord = global_id.xy;\r\n    let dims = vec2<u32>(HOLOGRAM_SIZE, HOLOGRAM_SIZE);\r\n    \r\n    if (coord.x >= dims.x || coord.y >= dims.y) {\r\n        return;\r\n    }\r\n    \r\n    let uv = vec2<f32>(coord) / vec2<f32>(dims);\r\n    \r\n    // Sample inputs\r\n    let depth = textureLoad(depth_tex, coord).r;\r\n    let noise_value = textureLoad(noise_tex, coord, 0).r;\r\n    let color = textureSampleLevel(color_tex, color_sampler, uv, 0.0);\r\n    let luminance = dot(color.rgb, vec3<f32>(0.299, 0.587, 0.114));\r\n    \r\n    // === Core computation ===\r\n    \r\n    // 1. Base amplitude\r\n    let base_amplitude = prop_params.amplitude_scale * \r\n                        mix(luminance, 1.0, 0.5) * \r\n                        mix(0.6, 1.0, wavefield_params.coherence);\r\n    \r\n    // 2. Phase from depth\r\n    var phase = depth_to_phase(depth, prop_params.wavelength, \r\n                              f32(coord.x % 3u) - 1.0);\r\n    phase += wavefield_params.phase_modulation;\r\n    \r\n    // 3. Fast interference computation\r\n    let interference = compute_interference_fast(uv, wavefield_params.time);\r\n    \r\n    // 4. Apply modulations\r\n    let interference_strength = osc_data.coupling_strength * 0.5;\r\n    phase += atan2(interference.y, interference.x) * interference_strength;\r\n    phase = apply_coherence_modulation_fast(phase, wavefield_params.coherence, noise_value);\r\n    \r\n    // 5. Aperture\r\n    let aperture = super_gaussian_aperture(uv, 0.45, 4.0);\r\n    let amplitude = base_amplitude * aperture * wavefield_params.scale;\r\n    \r\n    // 6. Generate field\r\n    phase = phase - floor(phase / TWO_PI) * TWO_PI;\r\n    var field = amplitude * complex_exp(phase) + interference * interference_strength;\r\n    \r\n    // 7. Reference beam\r\n    let ref_angle = PI / 6.0;\r\n    let ref_phase = TWO_PI * (uv.x * sin(ref_angle) + uv.y * cos(ref_angle)) / prop_params.wavelength;\r\n    field += 0.5 * complex_exp(ref_phase);\r\n    \r\n    // 8. Time effects\r\n    let pulse = 1.0 + 0.1 * sin(osc_data.psi_phase * 4.0 + wavefield_params.time) * \r\n                osc_data.phase_coherence;\r\n    field *= pulse;\r\n    \r\n    // 9. Chromatic dispersion\r\n    field = apply_chromatic_dispersion_fast(field, coord.x);\r\n    \r\n    // Store result\r\n    textureStore(wavefield_out, coord, vec4<f32>(field, 0.0, 0.0));\r\n}\r\n\r\n// Simplified test pattern generator\r\n@compute @workgroup_size(WORKGROUP_SIZE, WORKGROUP_SIZE, 1)\r\nfn generate_test_pattern(@builtin(global_invocation_id) global_id: vec3<u32>) {\r\n    let coord = global_id.xy;\r\n    let dims = vec2<u32>(HOLOGRAM_SIZE, HOLOGRAM_SIZE);\r\n    \r\n    if (coord.x >= dims.x || coord.y >= dims.y) {\r\n        return;\r\n    }\r\n    \r\n    let uv = vec2<f32>(coord) / vec2<f32>(dims);\r\n    let center = vec2<f32>(0.5, 0.5);\r\n    \r\n    // Animated point\r\n    let time = wavefield_params.time;\r\n    let point_pos = center + 0.2 * vec2<f32>(\r\n        sin(time + osc_data.psi_phase),\r\n        cos(time * 0.7)\r\n    );\r\n    \r\n    let r = distance(uv, point_pos);\r\n    let k = TWO_PI / prop_params.wavelength;\r\n    let phase = k * r * 1000.0 + osc_data.psi_phase * 2.0;\r\n    let amplitude = exp(-r * 5.0) * wavefield_params.coherence;\r\n    \r\n    let field = amplitude * complex_exp(phase);\r\n    let ref_phase = TWO_PI * uv.x * 5.0;\r\n    let reference = 0.3 * complex_exp(ref_phase);\r\n    \r\n    textureStore(wavefield_out, coord, vec4<f32>(field + reference, 0.0, 0.0));\r\n}\r\n";

/**
 * Shader sources object with all loaded shaders
 */
export const shaderSources = {
  adaptive_optics_correction_wgsl,
  avatarShader_wgsl,
  bitReversal_wgsl,
  butterflyStage_wgsl,
  fftShift_wgsl,
  hybridWavefieldBlend_wgsl,
  learned_wave_operator_wgsl,
  lenticularInterlace_wgsl,
  lightFieldComposer_wgsl,
  multiDepthWaveSynth_wgsl,
  multiViewSynthesis_wgsl,
  neuralHolography_wgsl,
  neural_radiance_holography_v2_wgsl,
  normalize_wgsl,
  phaseOcclusion_wgsl,
  propagation_wgsl,
  quantum_superposition_wgsl,
  roi_interest_map_wgsl,
  roi_map_wgsl,
  schrodinger_biharmonic_wgsl,
  schrodinger_cranknicolson_wgsl,
  schrodinger_kspace_multiply_wgsl,
  schrodinger_phase_multiply_wgsl,
  schrodinger_splitstep_wgsl,
  temporal_neural_propagation_wgsl,
  topologicalOverlay_wgsl,
  transpose_wgsl,
  velocityField_wgsl,
  wavefieldEncoder_wgsl,
  wavefieldEncoder_optimized_wgsl
} as const;

/**
 * Shader metadata for runtime introspection
 */
export const shaderMetadata = [
  {
    "name": "adaptive_optics_correction.wgsl",
    "variable": "adaptive_optics_correction_wgsl",
    "purpose": "No description"
  },
  {
    "name": "avatarShader.wgsl",
    "variable": "avatarShader_wgsl",
    "purpose": "No description"
  },
  {
    "name": "bitReversal.wgsl",
    "variable": "bitReversal_wgsl",
    "purpose": "No description"
  },
  {
    "name": "butterflyStage.wgsl",
    "variable": "butterflyStage_wgsl",
    "purpose": "No description"
  },
  {
    "name": "fftShift.wgsl",
    "variable": "fftShift_wgsl",
    "purpose": "No description"
  },
  {
    "name": "hybridWavefieldBlend.wgsl",
    "variable": "hybridWavefieldBlend_wgsl",
    "purpose": "No description"
  },
  {
    "name": "learned_wave_operator.wgsl",
    "variable": "learned_wave_operator_wgsl",
    "purpose": "No description"
  },
  {
    "name": "lenticularInterlace.wgsl",
    "variable": "lenticularInterlace_wgsl",
    "purpose": "No description"
  },
  {
    "name": "lightFieldComposer.wgsl",
    "variable": "lightFieldComposer_wgsl",
    "purpose": "No description"
  },
  {
    "name": "multiDepthWaveSynth.wgsl",
    "variable": "multiDepthWaveSynth_wgsl",
    "purpose": "No description"
  },
  {
    "name": "multiViewSynthesis.wgsl",
    "variable": "multiViewSynthesis_wgsl",
    "purpose": "No description"
  },
  {
    "name": "neuralHolography.wgsl",
    "variable": "neuralHolography_wgsl",
    "purpose": "No description"
  },
  {
    "name": "neural_radiance_holography_v2.wgsl",
    "variable": "neural_radiance_holography_v2_wgsl",
    "purpose": "No description"
  },
  {
    "name": "normalize.wgsl",
    "variable": "normalize_wgsl",
    "purpose": "No description"
  },
  {
    "name": "phaseOcclusion.wgsl",
    "variable": "phaseOcclusion_wgsl",
    "purpose": "No description"
  },
  {
    "name": "propagation.wgsl",
    "variable": "propagation_wgsl",
    "purpose": "No description"
  },
  {
    "name": "quantum_superposition.wgsl",
    "variable": "quantum_superposition_wgsl",
    "purpose": "No description"
  },
  {
    "name": "roi_interest_map.wgsl",
    "variable": "roi_interest_map_wgsl",
    "purpose": "No description"
  },
  {
    "name": "roi_map.wgsl",
    "variable": "roi_map_wgsl",
    "purpose": "No description"
  },
  {
    "name": "schrodinger_biharmonic.wgsl",
    "variable": "schrodinger_biharmonic_wgsl",
    "purpose": "No description"
  },
  {
    "name": "schrodinger_cranknicolson.wgsl",
    "variable": "schrodinger_cranknicolson_wgsl",
    "purpose": "No description"
  },
  {
    "name": "schrodinger_kspace_multiply.wgsl",
    "variable": "schrodinger_kspace_multiply_wgsl",
    "purpose": "No description"
  },
  {
    "name": "schrodinger_phase_multiply.wgsl",
    "variable": "schrodinger_phase_multiply_wgsl",
    "purpose": "No description"
  },
  {
    "name": "schrodinger_splitstep.wgsl",
    "variable": "schrodinger_splitstep_wgsl",
    "purpose": "No description"
  },
  {
    "name": "temporal_neural_propagation.wgsl",
    "variable": "temporal_neural_propagation_wgsl",
    "purpose": "No description"
  },
  {
    "name": "topologicalOverlay.wgsl",
    "variable": "topologicalOverlay_wgsl",
    "purpose": "No description"
  },
  {
    "name": "transpose.wgsl",
    "variable": "transpose_wgsl",
    "purpose": "No description"
  },
  {
    "name": "velocityField.wgsl",
    "variable": "velocityField_wgsl",
    "purpose": "No description"
  },
  {
    "name": "wavefieldEncoder.wgsl",
    "variable": "wavefieldEncoder_wgsl",
    "purpose": "No description"
  },
  {
    "name": "wavefieldEncoder_optimized.wgsl",
    "variable": "wavefieldEncoder_optimized_wgsl",
    "purpose": "No description"
  }
];

/**
 * Get shader source by name
 */
export function getShader(name: keyof typeof shaderSources): string {
  return shaderSources[name];
}

// Default export
export default shaderSources;
